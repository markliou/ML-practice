{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 12:36:31.194986: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-07 12:36:31.238784: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras as k\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 12:36:34.207382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.213396: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.213434: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.217085: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.217129: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.217142: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.343485: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.343547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.343555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-07 12:36:34.343578: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-07 12:36:34.343606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def sample_model():\n",
    "    x = k.layers.Input(shape=(784,))\n",
    "    l1 = k.layers.Dense(128, activation='tanh', kernel_initializer = k.initializers.Orthogonal)(x)\n",
    "    l2 = k.layers.Dense(128, activation='tanh', kernel_initializer = k.initializers.Orthogonal)(l1)\n",
    "    # for i in range(20):\n",
    "    #     l2 = k.layers.Dense(128, activation='tanh', kernel_initializer = k.initializers.Orthogonal)(l2)\n",
    "    out = k.layers.Dense(10, activation='softmax')(l2)\n",
    "    model = k.models.Model(inputs=x, outputs=out)\n",
    "    return model\n",
    "\n",
    "model = sample_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give a try for keras model saveing and reload\n",
    "# keras3 使用 .keras作為附檔名，且儲存了模型的yaml。這波要測試是否可以不用透過宣告模型計算圖，\n",
    "# 直接讀取.keras就能運作\n",
    "\n",
    "model.save(\"sample.keras\")\n",
    "reload_model = k.models.load_model(\"sample.keras\")\n",
    "# model.summary()\n",
    "# reload_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "batch_size = 32\n",
    "(x_train, y_train), (x_test, y_test) = k.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\")\n",
    "x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\")\n",
    "y_train = k.utils.to_categorical(y_train)\n",
    "y_test = k.utils.to_categorical(y_test)\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).repeat()\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "train_dataset_iter = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss calling in fit() will use (y_true, y_pred, sample_weight) as input, and return a scalar loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss class in keras use the API of (y_true, y_pred)\n",
    "loss_fn = k.losses.CategoricalCrossentropy(from_logits=False)\n",
    "@tf.function(jit_compile=True)\n",
    "def fitness(y_true, x):\n",
    "    y_pred = model(x)\n",
    "    return loss_fn(y_true, y_pred)\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def datasetFetchingScaling(x):\n",
    "    return(x * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712493396.524518    8973 service.cc:145] XLA service 0xba709c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1712493396.524582    8973 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2024-04-07 12:36:36.547658: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-07 12:36:36.656888: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712493398.050000    9126 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_328', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493398.094312    9129 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_223', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493399.431703    9133 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_119', 264 bytes spill stores, 264 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493399.492992    9126 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_328', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493399.492997    9129 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_223', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493399.557438    9131 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_223', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493400.215091    9119 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_119', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493400.248423    9132 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_119', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "I0000 00:00:1712493401.481628    8973 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current step:0   current loss:2.615798234939575\n",
      "current step:100   current loss:0.6835372447967529\n",
      "current step:200   current loss:0.8390721082687378\n",
      "current step:300   current loss:0.6336258053779602\n",
      "current step:400   current loss:0.8730320930480957\n",
      "current step:500   current loss:0.8628070950508118\n",
      "current step:600   current loss:0.6682157516479492\n",
      "current step:700   current loss:0.7548342347145081\n",
      "current step:800   current loss:0.6961177587509155\n",
      "current step:900   current loss:0.45296549797058105\n",
      "current step:1000   current loss:0.3378300964832306\n",
      "current step:1100   current loss:0.4919658303260803\n",
      "current step:1200   current loss:0.2941170334815979\n",
      "current step:1300   current loss:0.8104578256607056\n",
      "current step:1400   current loss:0.5528333783149719\n",
      "current step:1500   current loss:0.30541741847991943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1712493405.485700    9255 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_119', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current step:1600   current loss:0.30119192600250244\n",
      "current step:1700   current loss:0.365885853767395\n",
      "current step:1800   current loss:0.24973663687705994\n",
      "current step:1900   current loss:0.19191081821918488\n",
      "current step:2000   current loss:0.571785032749176\n",
      "current step:2100   current loss:0.30105483531951904\n",
      "current step:2200   current loss:0.34788793325424194\n",
      "current step:2300   current loss:0.5956392288208008\n",
      "current step:2400   current loss:0.5195046067237854\n",
      "current step:2500   current loss:0.5485208630561829\n",
      "current step:2600   current loss:0.7195578813552856\n",
      "current step:2700   current loss:0.318217933177948\n",
      "current step:2800   current loss:0.24832923710346222\n",
      "current step:2900   current loss:0.21371279656887054\n",
      "current step:3000   current loss:0.4638533592224121\n",
      "current step:3100   current loss:0.2016141414642334\n",
      "current step:3200   current loss:0.24083098769187927\n",
      "current step:3300   current loss:0.28476962447166443\n",
      "current step:3400   current loss:0.22235609591007233\n",
      "current step:3500   current loss:0.45640891790390015\n",
      "current step:3600   current loss:0.2511225640773773\n",
      "current step:3700   current loss:0.4267863631248474\n",
      "current step:3800   current loss:0.5019450187683105\n",
      "current step:3900   current loss:0.2236262708902359\n",
      "current step:4000   current loss:0.3253878355026245\n",
      "current step:4100   current loss:0.41847607493400574\n",
      "current step:4200   current loss:0.6160765290260315\n",
      "current step:4300   current loss:0.1988387107849121\n",
      "current step:4400   current loss:0.24100568890571594\n",
      "current step:4500   current loss:0.22172485291957855\n",
      "current step:4600   current loss:0.20599183440208435\n",
      "current step:4700   current loss:0.27595943212509155\n",
      "current step:4800   current loss:0.2165551632642746\n",
      "current step:4900   current loss:0.46526384353637695\n",
      "current step:5000   current loss:0.24401164054870605\n",
      "current step:5100   current loss:0.2834186851978302\n",
      "current step:5200   current loss:0.31076717376708984\n",
      "current step:5300   current loss:0.24092793464660645\n",
      "current step:5400   current loss:0.09146817028522491\n",
      "current step:5500   current loss:0.44548267126083374\n",
      "current step:5600   current loss:0.6367272138595581\n",
      "current step:5700   current loss:0.27241069078445435\n",
      "current step:5800   current loss:0.30935025215148926\n",
      "current step:5900   current loss:0.3134015202522278\n",
      "current step:6000   current loss:0.4624635577201843\n",
      "current step:6100   current loss:0.2998077869415283\n",
      "current step:6200   current loss:0.4079780578613281\n",
      "current step:6300   current loss:0.28006258606910706\n",
      "current step:6400   current loss:0.41179150342941284\n",
      "current step:6500   current loss:0.3215753734111786\n",
      "current step:6600   current loss:0.2564176917076111\n",
      "current step:6700   current loss:0.26542389392852783\n",
      "current step:6800   current loss:0.3674090802669525\n",
      "current step:6900   current loss:0.1810179352760315\n",
      "current step:7000   current loss:0.26102524995803833\n",
      "current step:7100   current loss:0.12226113677024841\n",
      "current step:7200   current loss:0.13860838115215302\n",
      "current step:7300   current loss:0.30339449644088745\n",
      "current step:7400   current loss:0.27731701731681824\n",
      "current step:7500   current loss:0.12063716351985931\n",
      "current step:7600   current loss:0.7580199241638184\n",
      "current step:7700   current loss:0.46199923753738403\n",
      "current step:7800   current loss:0.36575645208358765\n",
      "current step:7900   current loss:0.11273819208145142\n",
      "current step:8000   current loss:0.4418547749519348\n",
      "current step:8100   current loss:0.2976851463317871\n",
      "current step:8200   current loss:0.22622564435005188\n",
      "current step:8300   current loss:0.5071656703948975\n",
      "current step:8400   current loss:0.2212805449962616\n",
      "current step:8500   current loss:0.2965793013572693\n",
      "current step:8600   current loss:0.10658538341522217\n",
      "current step:8700   current loss:0.33733105659484863\n",
      "current step:8800   current loss:0.2461036592721939\n",
      "current step:8900   current loss:0.17660483717918396\n",
      "current step:9000   current loss:0.10149548947811127\n",
      "current step:9100   current loss:0.18779483437538147\n",
      "current step:9200   current loss:0.15471599996089935\n",
      "current step:9300   current loss:0.1656617820262909\n",
      "current step:9400   current loss:0.2746122479438782\n",
      "current step:9500   current loss:0.32840731739997864\n",
      "current step:9600   current loss:0.33497172594070435\n",
      "current step:9700   current loss:0.2651605010032654\n",
      "current step:9800   current loss:0.40740540623664856\n",
      "current step:9900   current loss:0.34206315875053406\n",
      "current step:10000   current loss:0.12898476421833038\n",
      "current step:10100   current loss:0.14774447679519653\n",
      "current step:10200   current loss:0.2030634880065918\n",
      "current step:10300   current loss:0.24946454167366028\n",
      "current step:10400   current loss:0.34124186635017395\n",
      "current step:10500   current loss:0.04091065004467964\n",
      "current step:10600   current loss:0.2855754494667053\n",
      "current step:10700   current loss:0.441781222820282\n",
      "current step:10800   current loss:0.7216238379478455\n",
      "current step:10900   current loss:0.04387684911489487\n",
      "current step:11000   current loss:0.11412559449672699\n",
      "current step:11100   current loss:0.2170015275478363\n",
      "current step:11200   current loss:0.18830600380897522\n",
      "current step:11300   current loss:0.07174424827098846\n",
      "current step:11400   current loss:0.30917465686798096\n",
      "current step:11500   current loss:0.027876820415258408\n",
      "current step:11600   current loss:0.3364158868789673\n",
      "current step:11700   current loss:0.35907551646232605\n",
      "current step:11800   current loss:0.2975333333015442\n",
      "current step:11900   current loss:0.3409068286418915\n",
      "current step:12000   current loss:0.15023136138916016\n",
      "current step:12100   current loss:0.4706268310546875\n",
      "current step:12200   current loss:0.17722083628177643\n",
      "current step:12300   current loss:0.2402239739894867\n",
      "current step:12400   current loss:0.28848886489868164\n",
      "current step:12500   current loss:0.4635535478591919\n",
      "current step:12600   current loss:0.08980260789394379\n",
      "current step:12700   current loss:0.23539826273918152\n",
      "current step:12800   current loss:0.18116848170757294\n",
      "current step:12900   current loss:0.16632145643234253\n",
      "current step:13000   current loss:0.6476428508758545\n",
      "current step:13100   current loss:0.20395854115486145\n",
      "current step:13200   current loss:0.10939455032348633\n",
      "current step:13300   current loss:0.25699108839035034\n",
      "current step:13400   current loss:0.26308906078338623\n",
      "current step:13500   current loss:0.245401531457901\n",
      "current step:13600   current loss:0.19272209703922272\n",
      "current step:13700   current loss:0.12855738401412964\n",
      "current step:13800   current loss:0.12933234870433807\n",
      "current step:13900   current loss:0.042975690215826035\n",
      "current step:14000   current loss:0.0946095883846283\n",
      "current step:14100   current loss:0.22640609741210938\n",
      "current step:14200   current loss:0.2675870656967163\n",
      "current step:14300   current loss:0.2494245320558548\n",
      "current step:14400   current loss:0.1703665554523468\n",
      "current step:14500   current loss:0.15357419848442078\n",
      "current step:14600   current loss:0.445708692073822\n",
      "current step:14700   current loss:0.1071590930223465\n",
      "current step:14800   current loss:0.09137509018182755\n",
      "current step:14900   current loss:0.09199465066194534\n",
      "current step:15000   current loss:0.26007896661758423\n",
      "current step:15100   current loss:0.3167926073074341\n",
      "current step:15200   current loss:0.19644293189048767\n",
      "current step:15300   current loss:0.5046465396881104\n",
      "current step:15400   current loss:0.09713635593652725\n",
      "current step:15500   current loss:0.45917096734046936\n",
      "current step:15600   current loss:0.264678031206131\n",
      "current step:15700   current loss:0.04209960997104645\n",
      "current step:15800   current loss:0.22028711438179016\n",
      "current step:15900   current loss:0.13555461168289185\n",
      "current step:16000   current loss:0.5042863488197327\n",
      "current step:16100   current loss:0.01459669042378664\n",
      "current step:16200   current loss:0.39011484384536743\n",
      "current step:16300   current loss:0.09055037796497345\n",
      "current step:16400   current loss:0.044915467500686646\n",
      "current step:16500   current loss:0.07354264706373215\n",
      "current step:16600   current loss:0.23780786991119385\n",
      "current step:16700   current loss:0.20559574663639069\n",
      "current step:16800   current loss:0.11182577162981033\n",
      "current step:16900   current loss:0.41992729902267456\n",
      "current step:17000   current loss:0.12232737243175507\n",
      "current step:17100   current loss:0.34731513261795044\n",
      "current step:17200   current loss:0.07878777384757996\n",
      "current step:17300   current loss:0.17681469023227692\n",
      "current step:17400   current loss:0.13441000878810883\n",
      "current step:17500   current loss:0.2541951835155487\n",
      "current step:17600   current loss:0.28867992758750916\n",
      "current step:17700   current loss:0.06352262198925018\n",
      "current step:17800   current loss:0.17774958908557892\n",
      "current step:17900   current loss:0.1528196483850479\n",
      "current step:18000   current loss:0.29083091020584106\n",
      "current step:18100   current loss:0.11938155442476273\n",
      "current step:18200   current loss:0.3720383644104004\n",
      "current step:18300   current loss:0.3359084725379944\n",
      "current step:18400   current loss:0.1930951625108719\n",
      "current step:18500   current loss:0.1836363673210144\n",
      "current step:18600   current loss:0.2662009000778198\n",
      "current step:18700   current loss:0.2500975728034973\n",
      "current step:18800   current loss:0.3031649589538574\n",
      "current step:18900   current loss:0.08811076730489731\n",
      "current step:19000   current loss:0.5128059983253479\n",
      "current step:19100   current loss:0.2730959951877594\n",
      "current step:19200   current loss:0.23467828333377838\n",
      "current step:19300   current loss:0.159837543964386\n",
      "current step:19400   current loss:0.26508963108062744\n",
      "current step:19500   current loss:0.26178014278411865\n",
      "current step:19600   current loss:0.17947912216186523\n",
      "current step:19700   current loss:0.22573834657669067\n",
      "current step:19800   current loss:0.09324578940868378\n",
      "current step:19900   current loss:0.0656227245926857\n",
      "current step:20000   current loss:0.036815907806158066\n",
      "current step:20100   current loss:0.12324073165655136\n",
      "current step:20200   current loss:0.23460730910301208\n",
      "current step:20300   current loss:0.13273850083351135\n",
      "current step:20400   current loss:0.03435928374528885\n",
      "current step:20500   current loss:0.11166355758905411\n",
      "current step:20600   current loss:0.3545796871185303\n",
      "current step:20700   current loss:0.2367880493402481\n",
      "current step:20800   current loss:0.21066953241825104\n",
      "current step:20900   current loss:0.04479994624853134\n",
      "current step:21000   current loss:0.24394242465496063\n",
      "current step:21100   current loss:0.24300166964530945\n",
      "current step:21200   current loss:0.5343130826950073\n",
      "current step:21300   current loss:0.13893522322177887\n",
      "current step:21400   current loss:0.2030368149280548\n",
      "current step:21500   current loss:0.10591758787631989\n",
      "current step:21600   current loss:0.20695942640304565\n",
      "current step:21700   current loss:0.12566034495830536\n",
      "current step:21800   current loss:0.21843305230140686\n",
      "current step:21900   current loss:0.15040819346904755\n",
      "current step:22000   current loss:0.08952444046735764\n",
      "current step:22100   current loss:0.20833083987236023\n",
      "current step:22200   current loss:0.07986362278461456\n",
      "current step:22300   current loss:0.22656989097595215\n",
      "current step:22400   current loss:0.29046377539634705\n",
      "current step:22500   current loss:0.21409298479557037\n",
      "current step:22600   current loss:0.1838582158088684\n",
      "current step:22700   current loss:0.1428997665643692\n",
      "current step:22800   current loss:0.20759111642837524\n",
      "current step:22900   current loss:0.2827012836933136\n",
      "current step:23000   current loss:0.14825741946697235\n",
      "current step:23100   current loss:0.11625169217586517\n",
      "current step:23200   current loss:0.2234417349100113\n",
      "current step:23300   current loss:0.21541711688041687\n",
      "current step:23400   current loss:0.234599307179451\n",
      "current step:23500   current loss:0.3518139719963074\n",
      "current step:23600   current loss:0.3695071041584015\n",
      "current step:23700   current loss:0.09823275357484818\n",
      "current step:23800   current loss:0.11042290180921555\n",
      "current step:23900   current loss:0.2148839235305786\n",
      "current step:24000   current loss:0.6382299065589905\n",
      "current step:24100   current loss:0.22543904185295105\n",
      "current step:24200   current loss:0.3428843319416046\n",
      "current step:24300   current loss:0.11159762740135193\n",
      "current step:24400   current loss:0.2275870442390442\n",
      "current step:24500   current loss:0.27054065465927124\n",
      "current step:24600   current loss:0.10216554254293442\n",
      "current step:24700   current loss:0.13090790808200836\n",
      "current step:24800   current loss:0.04890105873346329\n",
      "current step:24900   current loss:0.09192398190498352\n",
      "current step:25000   current loss:0.42674994468688965\n",
      "current step:25100   current loss:0.09927579015493393\n",
      "current step:25200   current loss:0.09832808375358582\n",
      "current step:25300   current loss:0.17503982782363892\n",
      "current step:25400   current loss:0.3096226155757904\n",
      "current step:25500   current loss:0.045310840010643005\n",
      "current step:25600   current loss:0.23269735276699066\n",
      "current step:25700   current loss:0.46528175473213196\n",
      "current step:25800   current loss:0.10805961489677429\n",
      "current step:25900   current loss:0.27087944746017456\n",
      "current step:26000   current loss:0.14316056668758392\n",
      "current step:26100   current loss:0.07432764023542404\n",
      "current step:26200   current loss:0.05202552676200867\n",
      "current step:26300   current loss:0.34217512607574463\n",
      "current step:26400   current loss:0.21236106753349304\n",
      "current step:26500   current loss:0.0882464051246643\n",
      "current step:26600   current loss:0.11913073062896729\n",
      "current step:26700   current loss:0.16204260289669037\n",
      "current step:26800   current loss:0.04146933555603027\n",
      "current step:26900   current loss:0.2630731463432312\n",
      "current step:27000   current loss:0.06927236169576645\n",
      "current step:27100   current loss:0.04078401252627373\n",
      "current step:27200   current loss:0.13731849193572998\n",
      "current step:27300   current loss:0.2318674772977829\n",
      "current step:27400   current loss:0.18517126142978668\n",
      "current step:27500   current loss:0.11818843334913254\n",
      "current step:27600   current loss:0.19219240546226501\n",
      "current step:27700   current loss:0.10389627516269684\n",
      "current step:27800   current loss:0.22629719972610474\n",
      "current step:27900   current loss:0.3548286557197571\n",
      "current step:28000   current loss:0.3005903959274292\n",
      "current step:28100   current loss:0.23728300631046295\n",
      "current step:28200   current loss:0.15387621521949768\n",
      "current step:28300   current loss:0.23316684365272522\n",
      "current step:28400   current loss:0.40678679943084717\n",
      "current step:28500   current loss:0.12135351449251175\n",
      "current step:28600   current loss:0.19255158305168152\n",
      "current step:28700   current loss:0.15645653009414673\n",
      "current step:28800   current loss:0.1497141420841217\n",
      "current step:28900   current loss:0.05610062927007675\n",
      "current step:29000   current loss:0.09753009676933289\n",
      "current step:29100   current loss:0.3602222204208374\n",
      "current step:29200   current loss:0.3591579794883728\n",
      "current step:29300   current loss:0.13530832529067993\n",
      "current step:29400   current loss:0.31664201617240906\n",
      "current step:29500   current loss:0.021350182592868805\n",
      "current step:29600   current loss:0.10437732934951782\n",
      "current step:29700   current loss:0.06552687287330627\n",
      "current step:29800   current loss:0.1499132663011551\n",
      "current step:29900   current loss:0.15237976610660553\n",
      "current step:30000   current loss:0.09218835830688477\n",
      "current step:30100   current loss:0.40214037895202637\n",
      "current step:30200   current loss:0.20254859328269958\n",
      "current step:30300   current loss:0.03804449737071991\n",
      "current step:30400   current loss:0.16095618903636932\n",
      "current step:30500   current loss:0.22923284769058228\n",
      "current step:30600   current loss:0.17392125725746155\n",
      "current step:30700   current loss:0.10436826199293137\n",
      "current step:30800   current loss:0.14703650772571564\n",
      "current step:30900   current loss:0.08441119641065598\n",
      "current step:31000   current loss:0.13872650265693665\n",
      "current step:31100   current loss:0.11228341609239578\n",
      "current step:31200   current loss:0.48595741391181946\n",
      "current step:31300   current loss:0.18573616445064545\n",
      "current step:31400   current loss:0.17592623829841614\n",
      "current step:31500   current loss:0.1176370233297348\n",
      "current step:31600   current loss:0.13596773147583008\n",
      "current step:31700   current loss:0.044696319848299026\n",
      "current step:31800   current loss:0.47739142179489136\n",
      "current step:31900   current loss:0.09537185728549957\n",
      "current step:32000   current loss:0.17850938439369202\n",
      "current step:32100   current loss:0.266153484582901\n",
      "current step:32200   current loss:0.02346472069621086\n",
      "current step:32300   current loss:0.16479864716529846\n",
      "current step:32400   current loss:0.05769817531108856\n",
      "current step:32500   current loss:0.07932092249393463\n",
      "current step:32600   current loss:0.14209970831871033\n",
      "current step:32700   current loss:0.07160593569278717\n",
      "current step:32800   current loss:0.0450592115521431\n",
      "current step:32900   current loss:0.41108012199401855\n",
      "current step:33000   current loss:0.19010473787784576\n",
      "current step:33100   current loss:0.11307878792285919\n",
      "current step:33200   current loss:0.2547888159751892\n",
      "current step:33300   current loss:0.11538612842559814\n",
      "current step:33400   current loss:0.07382885366678238\n",
      "current step:33500   current loss:0.21369144320487976\n",
      "current step:33600   current loss:0.18767720460891724\n",
      "current step:33700   current loss:0.21150881052017212\n",
      "current step:33800   current loss:0.28939318656921387\n",
      "current step:33900   current loss:0.053449518978595734\n",
      "current step:34000   current loss:0.06499328464269638\n",
      "current step:34100   current loss:0.12786172330379486\n",
      "current step:34200   current loss:0.216200053691864\n",
      "current step:34300   current loss:0.24594372510910034\n",
      "current step:34400   current loss:0.2736283540725708\n",
      "current step:34500   current loss:0.3017226457595825\n",
      "current step:34600   current loss:0.22949165105819702\n",
      "current step:34700   current loss:0.17534536123275757\n",
      "current step:34800   current loss:0.025981638580560684\n",
      "current step:34900   current loss:0.09684891253709793\n",
      "current step:35000   current loss:0.08943942934274673\n",
      "current step:35100   current loss:0.2663462460041046\n",
      "current step:35200   current loss:0.19446887075901031\n",
      "current step:35300   current loss:0.11565685272216797\n",
      "current step:35400   current loss:0.18080243468284607\n",
      "current step:35500   current loss:0.12416508048772812\n",
      "current step:35600   current loss:0.3443325161933899\n",
      "current step:35700   current loss:0.5295213460922241\n",
      "current step:35800   current loss:0.1894320845603943\n",
      "current step:35900   current loss:0.22261899709701538\n",
      "current step:36000   current loss:0.33429327607154846\n",
      "current step:36100   current loss:0.22604341804981232\n",
      "current step:36200   current loss:0.055285029113292694\n",
      "current step:36300   current loss:0.08401596546173096\n",
      "current step:36400   current loss:0.056061118841171265\n",
      "current step:36500   current loss:0.2455422282218933\n",
      "current step:36600   current loss:0.11310286819934845\n",
      "current step:36700   current loss:0.15564891695976257\n",
      "current step:36800   current loss:0.49943017959594727\n",
      "current step:36900   current loss:0.18490147590637207\n",
      "current step:37000   current loss:0.1135566383600235\n",
      "current step:37100   current loss:0.10295860469341278\n",
      "current step:37200   current loss:0.14550761878490448\n",
      "current step:37300   current loss:0.19098050892353058\n",
      "current step:37400   current loss:0.09646742045879364\n",
      "current step:37500   current loss:0.38591432571411133\n",
      "current step:37600   current loss:0.08239230513572693\n",
      "current step:37700   current loss:0.05721518397331238\n",
      "current step:37800   current loss:0.12435103207826614\n",
      "current step:37900   current loss:0.10452816635370255\n",
      "current step:38000   current loss:0.3736031949520111\n",
      "current step:38100   current loss:0.06988400965929031\n",
      "current step:38200   current loss:0.14253273606300354\n",
      "current step:38300   current loss:0.16532686352729797\n",
      "current step:38400   current loss:0.15410321950912476\n",
      "current step:38500   current loss:0.20804274082183838\n",
      "current step:38600   current loss:0.220716655254364\n",
      "current step:38700   current loss:0.048976268619298935\n",
      "current step:38800   current loss:0.08928758651018143\n",
      "current step:38900   current loss:0.21587848663330078\n",
      "current step:39000   current loss:0.20583689212799072\n",
      "current step:39100   current loss:0.1749340295791626\n",
      "current step:39200   current loss:0.12151066958904266\n",
      "current step:39300   current loss:0.08507813513278961\n",
      "current step:39400   current loss:0.2572878301143646\n",
      "current step:39500   current loss:0.14346028864383698\n",
      "current step:39600   current loss:0.2716492712497711\n",
      "current step:39700   current loss:0.2382631003856659\n",
      "current step:39800   current loss:0.14807873964309692\n",
      "current step:39900   current loss:0.09759625047445297\n",
      "current step:40000   current loss:0.06025374308228493\n",
      "current step:40100   current loss:0.09282708168029785\n",
      "current step:40200   current loss:0.11149872839450836\n",
      "current step:40300   current loss:0.20047754049301147\n",
      "current step:40400   current loss:0.16974946856498718\n",
      "current step:40500   current loss:0.11998026072978973\n",
      "current step:40600   current loss:0.05066775530576706\n",
      "current step:40700   current loss:0.2701700031757355\n",
      "current step:40800   current loss:0.27629292011260986\n",
      "current step:40900   current loss:0.29363563656806946\n",
      "current step:41000   current loss:0.11072584986686707\n",
      "current step:41100   current loss:0.3061215877532959\n",
      "current step:41200   current loss:0.16432243585586548\n",
      "current step:41300   current loss:0.26699236035346985\n",
      "current step:41400   current loss:0.2054896354675293\n",
      "current step:41500   current loss:0.27397850155830383\n",
      "current step:41600   current loss:0.24964645504951477\n",
      "current step:41700   current loss:0.17112897336483002\n",
      "current step:41800   current loss:0.22729235887527466\n",
      "current step:41900   current loss:0.21562257409095764\n",
      "current step:42000   current loss:0.24341116845607758\n",
      "current step:42100   current loss:0.20945295691490173\n",
      "current step:42200   current loss:0.13465924561023712\n",
      "current step:42300   current loss:0.028782011941075325\n",
      "current step:42400   current loss:0.061287738382816315\n",
      "current step:42500   current loss:0.0652199387550354\n",
      "current step:42600   current loss:0.13769276440143585\n",
      "current step:42700   current loss:0.08724476397037506\n",
      "current step:42800   current loss:0.47540560364723206\n",
      "current step:42900   current loss:0.1492932289838791\n",
      "current step:43000   current loss:0.07789695262908936\n",
      "current step:43100   current loss:0.1061604768037796\n",
      "current step:43200   current loss:0.14790445566177368\n",
      "current step:43300   current loss:0.25399139523506165\n",
      "current step:43400   current loss:0.1811205893754959\n",
      "current step:43500   current loss:0.05485289543867111\n",
      "current step:43600   current loss:0.014078667387366295\n",
      "current step:43700   current loss:0.1332637071609497\n",
      "current step:43800   current loss:0.12410873174667358\n",
      "current step:43900   current loss:0.4332972764968872\n",
      "current step:44000   current loss:0.17739693820476532\n",
      "current step:44100   current loss:0.1134626716375351\n",
      "current step:44200   current loss:0.1482086181640625\n",
      "current step:44300   current loss:0.1903810203075409\n",
      "current step:44400   current loss:0.2529199719429016\n",
      "current step:44500   current loss:0.11901145428419113\n",
      "current step:44600   current loss:0.23411311209201813\n",
      "current step:44700   current loss:0.2107616513967514\n",
      "current step:44800   current loss:0.11637651920318604\n",
      "current step:44900   current loss:0.12576450407505035\n",
      "current step:45000   current loss:0.14308148622512817\n",
      "current step:45100   current loss:0.18906211853027344\n",
      "current step:45200   current loss:0.03123481571674347\n",
      "current step:45300   current loss:0.05249102786183357\n",
      "current step:45400   current loss:0.33943304419517517\n",
      "current step:45500   current loss:0.13347987830638885\n",
      "current step:45600   current loss:0.05016113817691803\n",
      "current step:45700   current loss:0.1391785591840744\n",
      "current step:45800   current loss:0.16356417536735535\n",
      "current step:45900   current loss:0.2876392602920532\n",
      "current step:46000   current loss:0.13216406106948853\n",
      "current step:46100   current loss:0.19118916988372803\n",
      "current step:46200   current loss:0.21370962262153625\n",
      "current step:46300   current loss:0.027934372425079346\n",
      "current step:46400   current loss:0.3075982630252838\n",
      "current step:46500   current loss:0.4050827622413635\n",
      "current step:46600   current loss:0.18249043822288513\n",
      "current step:46700   current loss:0.0524795725941658\n",
      "current step:46800   current loss:0.1350308656692505\n",
      "current step:46900   current loss:0.060893647372722626\n",
      "current step:47000   current loss:0.18043340742588043\n",
      "current step:47100   current loss:0.1701667308807373\n",
      "current step:47200   current loss:0.18296824395656586\n",
      "current step:47300   current loss:0.4518497586250305\n",
      "current step:47400   current loss:0.10477206110954285\n",
      "current step:47500   current loss:0.20311339199543\n",
      "current step:47600   current loss:0.3134267032146454\n",
      "current step:47700   current loss:0.13033650815486908\n",
      "current step:47800   current loss:0.14732152223587036\n",
      "current step:47900   current loss:0.07806533575057983\n",
      "current step:48000   current loss:0.253078818321228\n",
      "current step:48100   current loss:0.38658252358436584\n",
      "current step:48200   current loss:0.3182884156703949\n",
      "current step:48300   current loss:0.16610871255397797\n",
      "current step:48400   current loss:0.08684023469686508\n",
      "current step:48500   current loss:0.14919538795948029\n",
      "current step:48600   current loss:0.19673007726669312\n",
      "current step:48700   current loss:0.3210930824279785\n",
      "current step:48800   current loss:0.10652942955493927\n",
      "current step:48900   current loss:0.27760833501815796\n",
      "current step:49000   current loss:0.10548608005046844\n",
      "current step:49100   current loss:0.03990165889263153\n",
      "current step:49200   current loss:0.07752417027950287\n",
      "current step:49300   current loss:0.06335864961147308\n",
      "current step:49400   current loss:0.11031919717788696\n",
      "current step:49500   current loss:0.06431551277637482\n",
      "current step:49600   current loss:0.08079730719327927\n",
      "current step:49700   current loss:0.04273217171430588\n",
      "current step:49800   current loss:0.18136844038963318\n",
      "current step:49900   current loss:0.05258922278881073\n",
      "current step:50000   current loss:0.19564281404018402\n",
      "current step:50100   current loss:0.35728198289871216\n",
      "current step:50200   current loss:0.4202693998813629\n",
      "current step:50300   current loss:0.10695336014032364\n",
      "current step:50400   current loss:0.15655027329921722\n",
      "current step:50500   current loss:0.30313342809677124\n",
      "current step:50600   current loss:0.43868112564086914\n",
      "current step:50700   current loss:0.26087480783462524\n",
      "current step:50800   current loss:0.16595116257667542\n",
      "current step:50900   current loss:0.06869534403085709\n",
      "current step:51000   current loss:0.32081881165504456\n",
      "current step:51100   current loss:0.24754822254180908\n",
      "current step:51200   current loss:0.05808001756668091\n",
      "current step:51300   current loss:0.22885875403881073\n",
      "current step:51400   current loss:0.180929496884346\n",
      "current step:51500   current loss:0.16720789670944214\n",
      "current step:51600   current loss:0.11716964840888977\n",
      "current step:51700   current loss:0.07362180203199387\n",
      "current step:51800   current loss:0.0644773542881012\n",
      "current step:51900   current loss:0.1725565791130066\n",
      "current step:52000   current loss:0.05141063034534454\n",
      "current step:52100   current loss:0.30428338050842285\n",
      "current step:52200   current loss:0.10490602999925613\n",
      "current step:52300   current loss:0.2411806583404541\n",
      "current step:52400   current loss:0.13583165407180786\n",
      "current step:52500   current loss:0.016870664432644844\n",
      "current step:52600   current loss:0.14577969908714294\n",
      "current step:52700   current loss:0.3143542408943176\n",
      "current step:52800   current loss:0.04019348695874214\n",
      "current step:52900   current loss:0.20813246071338654\n",
      "current step:53000   current loss:0.09647233784198761\n",
      "current step:53100   current loss:0.18921403586864471\n",
      "current step:53200   current loss:0.02638094499707222\n",
      "current step:53300   current loss:0.15089823305606842\n",
      "current step:53400   current loss:0.04147963598370552\n",
      "current step:53500   current loss:0.02534474804997444\n",
      "current step:53600   current loss:0.019842058420181274\n",
      "current step:53700   current loss:0.06574298441410065\n",
      "current step:53800   current loss:0.14951860904693604\n",
      "current step:53900   current loss:0.21984416246414185\n",
      "current step:54000   current loss:0.12713658809661865\n",
      "current step:54100   current loss:0.2507054805755615\n",
      "current step:54200   current loss:0.20889131724834442\n",
      "current step:54300   current loss:0.11213415861129761\n",
      "current step:54400   current loss:0.028600648045539856\n",
      "current step:54500   current loss:0.18438692390918732\n",
      "current step:54600   current loss:0.12469169497489929\n",
      "current step:54700   current loss:0.19303067028522491\n",
      "current step:54800   current loss:0.22244799137115479\n",
      "current step:54900   current loss:0.21374419331550598\n",
      "current step:55000   current loss:0.090859055519104\n",
      "current step:55100   current loss:0.09680170565843582\n",
      "current step:55200   current loss:0.12282050400972366\n",
      "current step:55300   current loss:0.09506203979253769\n",
      "current step:55400   current loss:0.119255930185318\n",
      "current step:55500   current loss:0.32258594036102295\n",
      "current step:55600   current loss:0.08234293758869171\n",
      "current step:55700   current loss:0.09407965838909149\n",
      "current step:55800   current loss:0.033250465989112854\n",
      "current step:55900   current loss:0.21630822122097015\n",
      "current step:56000   current loss:0.04185041785240173\n",
      "current step:56100   current loss:0.1848166584968567\n",
      "current step:56200   current loss:0.04565420746803284\n",
      "current step:56300   current loss:0.22218315303325653\n",
      "current step:56400   current loss:0.022782251238822937\n",
      "current step:56500   current loss:0.03802770376205444\n",
      "current step:56600   current loss:0.17758366465568542\n",
      "current step:56700   current loss:0.23531264066696167\n",
      "current step:56800   current loss:0.209130197763443\n",
      "current step:56900   current loss:0.17232945561408997\n",
      "current step:57000   current loss:0.11383763700723648\n",
      "current step:57100   current loss:0.4031648635864258\n",
      "current step:57200   current loss:0.12086258083581924\n",
      "current step:57300   current loss:0.09539775550365448\n",
      "current step:57400   current loss:0.1345527172088623\n",
      "current step:57500   current loss:0.23073992133140564\n",
      "current step:57600   current loss:0.10254929959774017\n",
      "current step:57700   current loss:0.22201885282993317\n",
      "current step:57800   current loss:0.029625892639160156\n",
      "current step:57900   current loss:0.037744615226984024\n",
      "current step:58000   current loss:0.1413448005914688\n",
      "current step:58100   current loss:0.11464768648147583\n",
      "current step:58200   current loss:0.28290534019470215\n",
      "current step:58300   current loss:0.14249154925346375\n",
      "current step:58400   current loss:0.21723094582557678\n",
      "current step:58500   current loss:0.22257010638713837\n",
      "current step:58600   current loss:0.15455682575702667\n",
      "current step:58700   current loss:0.0788242295384407\n",
      "current step:58800   current loss:0.24879437685012817\n",
      "current step:58900   current loss:0.21471595764160156\n",
      "current step:59000   current loss:0.08106254786252975\n",
      "current step:59100   current loss:0.2880778908729553\n",
      "current step:59200   current loss:0.05774003267288208\n",
      "current step:59300   current loss:0.09240012615919113\n",
      "current step:59400   current loss:0.15610793232917786\n",
      "current step:59500   current loss:0.11176864057779312\n",
      "current step:59600   current loss:0.06173379719257355\n",
      "current step:59700   current loss:0.04415304213762283\n",
      "current step:59800   current loss:0.24205376207828522\n",
      "current step:59900   current loss:0.34491726756095886\n",
      "current step:60000   current loss:0.01801300048828125\n",
      "current step:60100   current loss:0.04460621997714043\n",
      "current step:60200   current loss:0.258729487657547\n",
      "current step:60300   current loss:0.07161881029605865\n",
      "current step:60400   current loss:0.12363441288471222\n",
      "current step:60500   current loss:0.37824228405952454\n",
      "current step:60600   current loss:0.021278824657201767\n",
      "current step:60700   current loss:0.03122624382376671\n",
      "current step:60800   current loss:0.12143266946077347\n",
      "current step:60900   current loss:0.09517185389995575\n",
      "current step:61000   current loss:0.04951121285557747\n",
      "current step:61100   current loss:0.2667350769042969\n",
      "current step:61200   current loss:0.2543954849243164\n",
      "current step:61300   current loss:0.17613571882247925\n",
      "current step:61400   current loss:0.0436626672744751\n",
      "current step:61500   current loss:0.16101160645484924\n",
      "current step:61600   current loss:0.30911898612976074\n",
      "current step:61700   current loss:0.28992557525634766\n",
      "current step:61800   current loss:0.13790130615234375\n",
      "current step:61900   current loss:0.13178779184818268\n",
      "current step:62000   current loss:0.0649423822760582\n",
      "current step:62100   current loss:0.05324728414416313\n",
      "current step:62200   current loss:0.05098222568631172\n",
      "current step:62300   current loss:0.20097488164901733\n",
      "current step:62400   current loss:0.10768833756446838\n",
      "current step:62500   current loss:0.1296270489692688\n",
      "current step:62600   current loss:0.26017236709594727\n",
      "current step:62700   current loss:0.04866707697510719\n",
      "current step:62800   current loss:0.14908581972122192\n",
      "current step:62900   current loss:0.1503886729478836\n",
      "current step:63000   current loss:0.13877159357070923\n",
      "current step:63100   current loss:0.018773190677165985\n",
      "current step:63200   current loss:0.052297696471214294\n",
      "current step:63300   current loss:0.20785200595855713\n",
      "current step:63400   current loss:0.07835300266742706\n",
      "current step:63500   current loss:0.16893377900123596\n",
      "current step:63600   current loss:0.02756006456911564\n",
      "current step:63700   current loss:0.007616621442139149\n",
      "current step:63800   current loss:0.13732177019119263\n",
      "current step:63900   current loss:0.0698084756731987\n",
      "current step:64000   current loss:0.060514964163303375\n",
      "current step:64100   current loss:0.29871153831481934\n",
      "current step:64200   current loss:0.052180346101522446\n",
      "current step:64300   current loss:0.10127142071723938\n",
      "current step:64400   current loss:0.032736580818891525\n",
      "current step:64500   current loss:0.12441720068454742\n",
      "current step:64600   current loss:0.18190106749534607\n",
      "current step:64700   current loss:0.01986035145819187\n",
      "current step:64800   current loss:0.08778904378414154\n",
      "current step:64900   current loss:0.10169827938079834\n",
      "current step:65000   current loss:0.1959787905216217\n",
      "current step:65100   current loss:0.23561212420463562\n",
      "current step:65200   current loss:0.04255188629031181\n",
      "current step:65300   current loss:0.07065704464912415\n",
      "current step:65400   current loss:0.11725330352783203\n",
      "current step:65500   current loss:0.38444384932518005\n",
      "current step:65600   current loss:0.1584438979625702\n",
      "current step:65700   current loss:0.10467588156461716\n",
      "current step:65800   current loss:0.2117345929145813\n",
      "current step:65900   current loss:0.02422565408051014\n",
      "current step:66000   current loss:0.060116786509752274\n",
      "current step:66100   current loss:0.2491072416305542\n",
      "current step:66200   current loss:0.15063567459583282\n",
      "current step:66300   current loss:0.4287880063056946\n",
      "current step:66400   current loss:0.042420338839292526\n",
      "current step:66500   current loss:0.05163027346134186\n",
      "current step:66600   current loss:0.10792305320501328\n",
      "current step:66700   current loss:0.266605019569397\n",
      "current step:66800   current loss:0.31739363074302673\n",
      "current step:66900   current loss:0.07127515226602554\n",
      "current step:67000   current loss:0.10349655896425247\n",
      "current step:67100   current loss:0.28106623888015747\n",
      "current step:67200   current loss:0.18281425535678864\n",
      "current step:67300   current loss:0.12991899251937866\n",
      "current step:67400   current loss:0.022058401256799698\n",
      "current step:67500   current loss:0.1775454878807068\n",
      "current step:67600   current loss:0.09026781469583511\n",
      "current step:67700   current loss:0.17476940155029297\n",
      "current step:67800   current loss:0.04668441787362099\n",
      "current step:67900   current loss:0.08938834071159363\n",
      "current step:68000   current loss:0.10013052821159363\n",
      "current step:68100   current loss:0.1880950927734375\n",
      "current step:68200   current loss:0.040014296770095825\n",
      "current step:68300   current loss:0.13058540225028992\n",
      "current step:68400   current loss:0.030019279569387436\n",
      "current step:68500   current loss:0.1827186942100525\n",
      "current step:68600   current loss:0.07376287877559662\n",
      "current step:68700   current loss:0.054476428776979446\n",
      "current step:68800   current loss:0.2864983081817627\n",
      "current step:68900   current loss:0.057171016931533813\n",
      "current step:69000   current loss:0.11020924150943756\n",
      "current step:69100   current loss:0.1981690526008606\n",
      "current step:69200   current loss:0.2092590630054474\n",
      "current step:69300   current loss:0.01658632792532444\n",
      "current step:69400   current loss:0.008211204782128334\n",
      "current step:69500   current loss:0.10513561218976974\n",
      "current step:69600   current loss:0.11326295137405396\n",
      "current step:69700   current loss:0.048535190522670746\n",
      "current step:69800   current loss:0.3350057303905487\n",
      "current step:69900   current loss:0.022291451692581177\n",
      "current step:70000   current loss:0.11966267228126526\n",
      "current step:70100   current loss:0.017643125727772713\n",
      "current step:70200   current loss:0.07147260010242462\n",
      "current step:70300   current loss:0.43137985467910767\n",
      "current step:70400   current loss:0.06929147988557816\n",
      "current step:70500   current loss:0.11144144833087921\n",
      "current step:70600   current loss:0.08508364111185074\n",
      "current step:70700   current loss:0.03707501292228699\n",
      "current step:70800   current loss:0.17729531228542328\n",
      "current step:70900   current loss:0.02325771376490593\n",
      "current step:71000   current loss:0.005148665048182011\n",
      "current step:71100   current loss:0.02000562846660614\n",
      "current step:71200   current loss:0.26250725984573364\n",
      "current step:71300   current loss:0.2889859080314636\n",
      "current step:71400   current loss:0.0642271637916565\n",
      "current step:71500   current loss:0.18945826590061188\n",
      "current step:71600   current loss:0.20165979862213135\n",
      "current step:71700   current loss:0.051501523703336716\n",
      "current step:71800   current loss:0.15519946813583374\n",
      "current step:71900   current loss:0.1557346135377884\n",
      "current step:72000   current loss:0.06327629834413528\n",
      "current step:72100   current loss:0.2013513594865799\n",
      "current step:72200   current loss:0.22822314500808716\n",
      "current step:72300   current loss:0.21607373654842377\n",
      "current step:72400   current loss:0.17496460676193237\n",
      "current step:72500   current loss:0.2013740837574005\n",
      "current step:72600   current loss:0.1591448187828064\n",
      "current step:72700   current loss:0.03724417835474014\n",
      "current step:72800   current loss:0.09500834345817566\n",
      "current step:72900   current loss:0.24254024028778076\n",
      "current step:73000   current loss:0.17762038111686707\n",
      "current step:73100   current loss:0.21079137921333313\n",
      "current step:73200   current loss:0.11215390264987946\n",
      "current step:73300   current loss:0.08367379009723663\n",
      "current step:73400   current loss:0.10193604230880737\n",
      "current step:73500   current loss:0.04114435985684395\n",
      "current step:73600   current loss:0.07239007949829102\n",
      "current step:73700   current loss:0.08227023482322693\n",
      "current step:73800   current loss:0.033654727041721344\n",
      "current step:73900   current loss:0.2760678827762604\n",
      "current step:74000   current loss:0.1431160569190979\n",
      "current step:74100   current loss:0.46329668164253235\n",
      "current step:74200   current loss:0.05337454751133919\n",
      "current step:74300   current loss:0.1873004287481308\n",
      "current step:74400   current loss:0.2236238420009613\n",
      "current step:74500   current loss:0.1221587210893631\n",
      "current step:74600   current loss:0.09370532631874084\n",
      "current step:74700   current loss:0.18344341218471527\n",
      "current step:74800   current loss:0.025364091619849205\n",
      "current step:74900   current loss:0.25628894567489624\n",
      "current step:75000   current loss:0.15665166079998016\n",
      "current step:75100   current loss:0.0500846728682518\n",
      "current step:75200   current loss:0.02226748876273632\n",
      "current step:75300   current loss:0.09698967635631561\n",
      "current step:75400   current loss:0.16005176305770874\n",
      "current step:75500   current loss:0.051329534500837326\n",
      "current step:75600   current loss:0.07428092509508133\n",
      "current step:75700   current loss:0.061376236379146576\n",
      "current step:75800   current loss:0.10440917313098907\n",
      "current step:75900   current loss:0.0949968621134758\n",
      "current step:76000   current loss:0.12030121684074402\n",
      "current step:76100   current loss:0.15835560858249664\n",
      "current step:76200   current loss:0.11171016097068787\n",
      "current step:76300   current loss:0.13174808025360107\n",
      "current step:76400   current loss:0.03272850066423416\n",
      "current step:76500   current loss:0.23736879229545593\n",
      "current step:76600   current loss:0.03587830439209938\n",
      "current step:76700   current loss:0.10754799097776413\n",
      "current step:76800   current loss:0.027646783739328384\n",
      "current step:76900   current loss:0.09132495522499084\n",
      "current step:77000   current loss:0.11080317944288254\n",
      "current step:77100   current loss:0.1363658308982849\n",
      "current step:77200   current loss:0.22869014739990234\n",
      "current step:77300   current loss:0.06896042078733444\n",
      "current step:77400   current loss:0.15366855263710022\n",
      "current step:77500   current loss:0.5363351106643677\n",
      "current step:77600   current loss:0.2610071301460266\n",
      "current step:77700   current loss:0.23776687681674957\n",
      "current step:77800   current loss:0.09345168620347977\n",
      "current step:77900   current loss:0.0443410724401474\n",
      "current step:78000   current loss:0.24403566122055054\n",
      "current step:78100   current loss:0.32294827699661255\n",
      "current step:78200   current loss:0.08514943718910217\n",
      "current step:78300   current loss:0.24020293354988098\n",
      "current step:78400   current loss:0.03579605370759964\n",
      "current step:78500   current loss:0.13708946108818054\n",
      "current step:78600   current loss:0.22535307705402374\n",
      "current step:78700   current loss:0.05930428206920624\n",
      "current step:78800   current loss:0.41209056973457336\n",
      "current step:78900   current loss:0.10780610144138336\n",
      "current step:79000   current loss:0.04829857498407364\n",
      "current step:79100   current loss:0.08030527085065842\n",
      "current step:79200   current loss:0.21770396828651428\n",
      "current step:79300   current loss:0.0822296217083931\n",
      "current step:79400   current loss:0.15329799056053162\n",
      "current step:79500   current loss:0.34631848335266113\n",
      "current step:79600   current loss:0.1315258890390396\n",
      "current step:79700   current loss:0.10212686657905579\n",
      "current step:79800   current loss:0.18238592147827148\n",
      "current step:79900   current loss:0.040945038199424744\n",
      "current step:80000   current loss:0.040454693138599396\n",
      "current step:80100   current loss:0.05384965240955353\n",
      "current step:80200   current loss:0.20088909566402435\n",
      "current step:80300   current loss:0.32266753911972046\n",
      "current step:80400   current loss:0.022428348660469055\n",
      "current step:80500   current loss:0.1492997407913208\n",
      "current step:80600   current loss:0.11335506290197372\n",
      "current step:80700   current loss:0.14508715271949768\n",
      "current step:80800   current loss:0.1900942623615265\n",
      "current step:80900   current loss:0.41527825593948364\n",
      "current step:81000   current loss:0.19205114245414734\n",
      "current step:81100   current loss:0.1777576506137848\n",
      "current step:81200   current loss:0.1587221771478653\n",
      "current step:81300   current loss:0.2805836498737335\n",
      "current step:81400   current loss:0.02606239914894104\n",
      "current step:81500   current loss:0.12024649232625961\n",
      "current step:81600   current loss:0.11512278765439987\n",
      "current step:81700   current loss:0.037036217749118805\n",
      "current step:81800   current loss:0.0374329537153244\n",
      "current step:81900   current loss:0.2020064890384674\n",
      "current step:82000   current loss:0.34686824679374695\n",
      "current step:82100   current loss:0.17998914420604706\n",
      "current step:82200   current loss:0.026670079678297043\n",
      "current step:82300   current loss:0.13444636762142181\n",
      "current step:82400   current loss:0.1555211842060089\n",
      "current step:82500   current loss:0.23086541891098022\n",
      "current step:82600   current loss:0.33500057458877563\n",
      "current step:82700   current loss:0.10035327076911926\n",
      "current step:82800   current loss:0.11658188700675964\n",
      "current step:82900   current loss:0.20006117224693298\n",
      "current step:83000   current loss:0.12171804904937744\n",
      "current step:83100   current loss:0.11421094834804535\n",
      "current step:83200   current loss:0.06299366801977158\n",
      "current step:83300   current loss:0.1312645971775055\n",
      "current step:83400   current loss:0.008480506017804146\n",
      "current step:83500   current loss:0.01987745612859726\n",
      "current step:83600   current loss:0.029838047921657562\n",
      "current step:83700   current loss:0.08064843714237213\n",
      "current step:83800   current loss:0.33864066004753113\n",
      "current step:83900   current loss:0.3066413998603821\n",
      "current step:84000   current loss:0.018528977409005165\n",
      "current step:84100   current loss:0.07586468756198883\n",
      "current step:84200   current loss:0.1762596070766449\n",
      "current step:84300   current loss:0.12382222712039948\n",
      "current step:84400   current loss:0.3622244894504547\n",
      "current step:84500   current loss:0.023804858326911926\n",
      "current step:84600   current loss:0.28038567304611206\n",
      "current step:84700   current loss:0.17742273211479187\n",
      "current step:84800   current loss:0.3132435381412506\n",
      "current step:84900   current loss:0.07809610664844513\n",
      "current step:85000   current loss:0.1328250765800476\n",
      "current step:85100   current loss:0.04849173128604889\n",
      "current step:85200   current loss:0.2710914611816406\n",
      "current step:85300   current loss:0.010005030781030655\n",
      "current step:85400   current loss:0.07887625694274902\n",
      "current step:85500   current loss:0.028867214918136597\n",
      "current step:85600   current loss:0.28001925349235535\n",
      "current step:85700   current loss:0.19547435641288757\n",
      "current step:85800   current loss:0.18084923923015594\n",
      "current step:85900   current loss:0.06889962404966354\n",
      "current step:86000   current loss:0.24220633506774902\n",
      "current step:86100   current loss:0.12346583604812622\n",
      "current step:86200   current loss:0.02482929453253746\n",
      "current step:86300   current loss:0.021703699603676796\n",
      "current step:86400   current loss:0.3415036201477051\n",
      "current step:86500   current loss:0.11840265989303589\n",
      "current step:86600   current loss:0.1828506588935852\n",
      "current step:86700   current loss:0.2548484802246094\n",
      "current step:86800   current loss:0.12908923625946045\n",
      "current step:86900   current loss:0.03973738104104996\n",
      "current step:87000   current loss:0.16271638870239258\n",
      "current step:87100   current loss:0.14502495527267456\n",
      "current step:87200   current loss:0.22679314017295837\n",
      "current step:87300   current loss:0.28383126854896545\n",
      "current step:87400   current loss:0.18274551630020142\n",
      "current step:87500   current loss:0.18353399634361267\n",
      "current step:87600   current loss:0.04117201268672943\n",
      "current step:87700   current loss:0.2586991786956787\n",
      "current step:87800   current loss:0.4776914715766907\n",
      "current step:87900   current loss:0.05192888155579567\n",
      "current step:88000   current loss:0.0955437570810318\n",
      "current step:88100   current loss:0.0887393057346344\n",
      "current step:88200   current loss:0.10147520899772644\n",
      "current step:88300   current loss:0.0642334371805191\n",
      "current step:88400   current loss:0.10953579097986221\n",
      "current step:88500   current loss:0.22311931848526\n",
      "current step:88600   current loss:0.2961580753326416\n",
      "current step:88700   current loss:0.3178167939186096\n",
      "current step:88800   current loss:0.29707375168800354\n",
      "current step:88900   current loss:0.11290839314460754\n",
      "current step:89000   current loss:0.07701162993907928\n",
      "current step:89100   current loss:0.1375042051076889\n",
      "current step:89200   current loss:0.05448022484779358\n",
      "current step:89300   current loss:0.23697762191295624\n",
      "current step:89400   current loss:0.14813347160816193\n",
      "current step:89500   current loss:0.2533404231071472\n",
      "current step:89600   current loss:0.06945809721946716\n",
      "current step:89700   current loss:0.22092117369174957\n",
      "current step:89800   current loss:0.036947138607501984\n",
      "current step:89900   current loss:0.28346920013427734\n",
      "current step:90000   current loss:0.15320569276809692\n",
      "current step:90100   current loss:0.18267692625522614\n",
      "current step:90200   current loss:0.2090841829776764\n",
      "current step:90300   current loss:0.29051125049591064\n",
      "current step:90400   current loss:0.10650680214166641\n",
      "current step:90500   current loss:0.12160651385784149\n",
      "current step:90600   current loss:0.14165300130844116\n",
      "current step:90700   current loss:0.07140152901411057\n",
      "current step:90800   current loss:0.32646864652633667\n",
      "current step:90900   current loss:0.043418556451797485\n",
      "current step:91000   current loss:0.13485285639762878\n",
      "current step:91100   current loss:0.4694962501525879\n",
      "current step:91200   current loss:0.22664697468280792\n",
      "current step:91300   current loss:0.20259028673171997\n",
      "current step:91400   current loss:0.24110588431358337\n",
      "current step:91500   current loss:0.06725452840328217\n",
      "current step:91600   current loss:0.23339147865772247\n",
      "current step:91700   current loss:0.09751027077436447\n",
      "current step:91800   current loss:0.10646624863147736\n",
      "current step:91900   current loss:0.15326283872127533\n",
      "current step:92000   current loss:0.16014927625656128\n",
      "current step:92100   current loss:0.1834319680929184\n",
      "current step:92200   current loss:0.1927238404750824\n",
      "current step:92300   current loss:0.24154745042324066\n",
      "current step:92400   current loss:0.09343622624874115\n",
      "current step:92500   current loss:0.027968887239694595\n",
      "current step:92600   current loss:0.3531566858291626\n",
      "current step:92700   current loss:0.08873086422681808\n",
      "current step:92800   current loss:0.08867938071489334\n",
      "current step:92900   current loss:0.11083576828241348\n",
      "current step:93000   current loss:0.0668385922908783\n",
      "current step:93100   current loss:0.054134007543325424\n",
      "current step:93200   current loss:0.20877042412757874\n",
      "current step:93300   current loss:0.2073010355234146\n",
      "current step:93400   current loss:0.027805067598819733\n",
      "current step:93500   current loss:0.06179388612508774\n",
      "current step:93600   current loss:0.062067605555057526\n",
      "current step:93700   current loss:0.12486326694488525\n",
      "current step:93800   current loss:0.09004970639944077\n",
      "current step:93900   current loss:0.3110402226448059\n",
      "current step:94000   current loss:0.089558906853199\n",
      "current step:94100   current loss:0.05900200456380844\n",
      "current step:94200   current loss:0.036352138966321945\n",
      "current step:94300   current loss:0.19136665761470795\n",
      "current step:94400   current loss:0.0082324193790555\n",
      "current step:94500   current loss:0.12166982889175415\n",
      "current step:94600   current loss:0.04387093707919121\n",
      "current step:94700   current loss:0.05617641657590866\n",
      "current step:94800   current loss:0.24871623516082764\n",
      "current step:94900   current loss:0.18124449253082275\n",
      "current step:95000   current loss:0.19006416201591492\n",
      "current step:95100   current loss:0.29472771286964417\n",
      "current step:95200   current loss:0.23349763453006744\n",
      "current step:95300   current loss:0.1040840670466423\n",
      "current step:95400   current loss:0.20208609104156494\n",
      "current step:95500   current loss:0.14655590057373047\n",
      "current step:95600   current loss:0.1166885495185852\n",
      "current step:95700   current loss:0.1470184326171875\n",
      "current step:95800   current loss:0.16396087408065796\n",
      "current step:95900   current loss:0.12837733328342438\n",
      "current step:96000   current loss:0.0492718443274498\n",
      "current step:96100   current loss:0.040516309440135956\n",
      "current step:96200   current loss:0.017392253503203392\n",
      "current step:96300   current loss:0.08595336228609085\n",
      "current step:96400   current loss:0.38678765296936035\n",
      "current step:96500   current loss:0.10306207835674286\n",
      "current step:96600   current loss:0.430184930562973\n",
      "current step:96700   current loss:0.03556593880057335\n",
      "current step:96800   current loss:0.290174663066864\n",
      "current step:96900   current loss:0.18306811153888702\n",
      "current step:97000   current loss:0.026393257081508636\n",
      "current step:97100   current loss:0.04684966802597046\n",
      "current step:97200   current loss:0.26741552352905273\n",
      "current step:97300   current loss:0.07801599055528641\n",
      "current step:97400   current loss:0.025558624416589737\n",
      "current step:97500   current loss:0.10294149816036224\n",
      "current step:97600   current loss:0.4627210795879364\n",
      "current step:97700   current loss:0.0359070748090744\n",
      "current step:97800   current loss:0.08560346066951752\n",
      "current step:97900   current loss:0.2819341719150543\n",
      "current step:98000   current loss:0.059986501932144165\n",
      "current step:98100   current loss:0.01395720336586237\n",
      "current step:98200   current loss:0.08121860772371292\n",
      "current step:98300   current loss:0.04401962459087372\n",
      "current step:98400   current loss:0.22658145427703857\n",
      "current step:98500   current loss:0.2846369445323944\n",
      "current step:98600   current loss:0.04917921498417854\n",
      "current step:98700   current loss:0.14233219623565674\n",
      "current step:98800   current loss:0.1991155594587326\n",
      "current step:98900   current loss:0.23783722519874573\n",
      "current step:99000   current loss:0.07505147904157639\n",
      "current step:99100   current loss:0.05820971727371216\n",
      "current step:99200   current loss:0.020742513239383698\n",
      "current step:99300   current loss:0.034488238394260406\n",
      "current step:99400   current loss:0.16919806599617004\n",
      "current step:99500   current loss:0.308042973279953\n",
      "current step:99600   current loss:0.059709955006837845\n",
      "current step:99700   current loss:0.16051438450813293\n",
      "current step:99800   current loss:0.010584143921732903\n",
      "current step:99900   current loss:0.38320136070251465\n",
      "current step:100000   current loss:0.18347762525081635\n",
      "current step:100100   current loss:0.06224812939763069\n",
      "current step:100200   current loss:0.16773568093776703\n",
      "current step:100300   current loss:0.14817678928375244\n",
      "current step:100400   current loss:0.027981216087937355\n",
      "current step:100500   current loss:0.18180350959300995\n",
      "current step:100600   current loss:0.11142326146364212\n",
      "current step:100700   current loss:0.16397953033447266\n",
      "current step:100800   current loss:0.021958375349640846\n",
      "current step:100900   current loss:0.06796213984489441\n",
      "current step:101000   current loss:0.05591639131307602\n",
      "current step:101100   current loss:0.11908133327960968\n",
      "current step:101200   current loss:0.15391889214515686\n",
      "current step:101300   current loss:0.1879604458808899\n",
      "current step:101400   current loss:0.3299793601036072\n",
      "current step:101500   current loss:0.13874949514865875\n",
      "current step:101600   current loss:0.22268112003803253\n",
      "current step:101700   current loss:0.08854018151760101\n",
      "current step:101800   current loss:0.03491894528269768\n",
      "current step:101900   current loss:0.10341465473175049\n",
      "current step:102000   current loss:0.21124419569969177\n",
      "current step:102100   current loss:0.23406606912612915\n",
      "current step:102200   current loss:0.1289350837469101\n",
      "current step:102300   current loss:0.026702407747507095\n",
      "current step:102400   current loss:0.09553083777427673\n",
      "current step:102500   current loss:0.06644904613494873\n",
      "current step:102600   current loss:0.17881181836128235\n",
      "current step:102700   current loss:0.22244754433631897\n",
      "current step:102800   current loss:0.09279663860797882\n",
      "current step:102900   current loss:0.025155361741781235\n",
      "current step:103000   current loss:0.13699156045913696\n",
      "current step:103100   current loss:0.23266935348510742\n",
      "current step:103200   current loss:0.07588512450456619\n",
      "current step:103300   current loss:0.05771065503358841\n",
      "current step:103400   current loss:0.18458983302116394\n",
      "current step:103500   current loss:0.10953396558761597\n",
      "current step:103600   current loss:0.1772797405719757\n",
      "current step:103700   current loss:0.2025572657585144\n",
      "current step:103800   current loss:0.04535217583179474\n",
      "current step:103900   current loss:0.12154853343963623\n",
      "current step:104000   current loss:0.2814076542854309\n",
      "current step:104100   current loss:0.04209238290786743\n",
      "current step:104200   current loss:0.12482836097478867\n",
      "current step:104300   current loss:0.1474519968032837\n",
      "current step:104400   current loss:0.07606744766235352\n",
      "current step:104500   current loss:0.16392578184604645\n",
      "current step:104600   current loss:0.055165112018585205\n",
      "current step:104700   current loss:0.1804271638393402\n",
      "current step:104800   current loss:0.04841045290231705\n",
      "current step:104900   current loss:0.15745583176612854\n",
      "current step:105000   current loss:0.20467200875282288\n",
      "current step:105100   current loss:0.4395507574081421\n",
      "current step:105200   current loss:0.0430891327559948\n",
      "current step:105300   current loss:0.3751155734062195\n",
      "current step:105400   current loss:0.0753665417432785\n",
      "current step:105500   current loss:0.09313278645277023\n",
      "current step:105600   current loss:0.11478806287050247\n",
      "current step:105700   current loss:0.26362061500549316\n",
      "current step:105800   current loss:0.0384347066283226\n",
      "current step:105900   current loss:0.14425227046012878\n",
      "current step:106000   current loss:0.07314462959766388\n",
      "current step:106100   current loss:0.03531453758478165\n",
      "current step:106200   current loss:0.06947650015354156\n",
      "current step:106300   current loss:0.28194132447242737\n",
      "current step:106400   current loss:0.047003839164972305\n",
      "current step:106500   current loss:0.03652612864971161\n",
      "current step:106600   current loss:0.36567625403404236\n",
      "current step:106700   current loss:0.02020023576915264\n",
      "current step:106800   current loss:0.16462598741054535\n",
      "current step:106900   current loss:0.07720350474119186\n",
      "current step:107000   current loss:0.019242946058511734\n",
      "current step:107100   current loss:0.11920898407697678\n",
      "current step:107200   current loss:0.11353810131549835\n",
      "current step:107300   current loss:0.14549343287944794\n",
      "current step:107400   current loss:0.07329383492469788\n",
      "current step:107500   current loss:0.1871437281370163\n",
      "current step:107600   current loss:0.26300281286239624\n",
      "current step:107700   current loss:0.0744929313659668\n",
      "current step:107800   current loss:0.09826153516769409\n",
      "current step:107900   current loss:0.3037686049938202\n",
      "current step:108000   current loss:0.022598493844270706\n",
      "current step:108100   current loss:0.18218785524368286\n",
      "current step:108200   current loss:0.30420956015586853\n",
      "current step:108300   current loss:0.03383295610547066\n",
      "current step:108400   current loss:0.11510469019412994\n",
      "current step:108500   current loss:0.04114498198032379\n",
      "current step:108600   current loss:0.11539837718009949\n",
      "current step:108700   current loss:0.011863889172673225\n",
      "current step:108800   current loss:0.16292770206928253\n",
      "current step:108900   current loss:0.3045564293861389\n",
      "current step:109000   current loss:0.19083595275878906\n",
      "current step:109100   current loss:0.1650259792804718\n",
      "current step:109200   current loss:0.14386701583862305\n",
      "current step:109300   current loss:0.13158322870731354\n",
      "current step:109400   current loss:0.16001006960868835\n",
      "current step:109500   current loss:0.18535540997982025\n",
      "current step:109600   current loss:0.16847661137580872\n",
      "current step:109700   current loss:0.0722074881196022\n",
      "current step:109800   current loss:0.06236378848552704\n",
      "current step:109900   current loss:0.024600211530923843\n",
      "current step:110000   current loss:0.12449008226394653\n",
      "current step:110100   current loss:0.09631048142910004\n",
      "current step:110200   current loss:0.033452652394771576\n",
      "current step:110300   current loss:0.05526778846979141\n",
      "current step:110400   current loss:0.12873324751853943\n",
      "current step:110500   current loss:0.23075008392333984\n",
      "current step:110600   current loss:0.018438290804624557\n",
      "current step:110700   current loss:0.028629235923290253\n",
      "current step:110800   current loss:0.3106553852558136\n",
      "current step:110900   current loss:0.06695666909217834\n",
      "current step:111000   current loss:0.07379736751317978\n",
      "current step:111100   current loss:0.05392424017190933\n",
      "current step:111200   current loss:0.1257740557193756\n",
      "current step:111300   current loss:0.07750243693590164\n",
      "current step:111400   current loss:0.10676133632659912\n",
      "current step:111500   current loss:0.43150633573532104\n",
      "current step:111600   current loss:0.22779883444309235\n",
      "current step:111700   current loss:0.00800155196338892\n",
      "current step:111800   current loss:0.1733807623386383\n",
      "current step:111900   current loss:0.2429088056087494\n",
      "current step:112000   current loss:0.10248509794473648\n",
      "current step:112100   current loss:0.14308658242225647\n",
      "current step:112200   current loss:0.05125698074698448\n",
      "current step:112300   current loss:0.1255815029144287\n",
      "current step:112400   current loss:0.15879374742507935\n",
      "current step:112500   current loss:0.03502936661243439\n",
      "current step:112600   current loss:0.06278509646654129\n",
      "current step:112700   current loss:0.061872199177742004\n",
      "current step:112800   current loss:0.06234540045261383\n",
      "current step:112900   current loss:0.13650627434253693\n",
      "current step:113000   current loss:0.13817787170410156\n",
      "current step:113100   current loss:0.01638663001358509\n",
      "current step:113200   current loss:0.06220705062150955\n",
      "current step:113300   current loss:0.10275517404079437\n",
      "current step:113400   current loss:0.20357394218444824\n",
      "current step:113500   current loss:0.11347964406013489\n",
      "current step:113600   current loss:0.13320064544677734\n",
      "current step:113700   current loss:0.10544340312480927\n",
      "current step:113800   current loss:0.023071933537721634\n",
      "current step:113900   current loss:0.18489795923233032\n",
      "current step:114000   current loss:0.22760151326656342\n",
      "current step:114100   current loss:0.14544732868671417\n",
      "current step:114200   current loss:0.14677374064922333\n",
      "current step:114300   current loss:0.25452369451522827\n",
      "current step:114400   current loss:0.14669060707092285\n",
      "current step:114500   current loss:0.09511694312095642\n",
      "current step:114600   current loss:0.015988780185580254\n",
      "current step:114700   current loss:0.3445303440093994\n",
      "current step:114800   current loss:0.18959569931030273\n",
      "current step:114900   current loss:0.4695359468460083\n",
      "current step:115000   current loss:0.02402544766664505\n",
      "current step:115100   current loss:0.07642538845539093\n",
      "current step:115200   current loss:0.021765021607279778\n",
      "current step:115300   current loss:0.18402385711669922\n",
      "current step:115400   current loss:0.2016400694847107\n",
      "current step:115500   current loss:0.016619805246591568\n",
      "current step:115600   current loss:0.1648063063621521\n",
      "current step:115700   current loss:0.24987374246120453\n",
      "current step:115800   current loss:0.29469576478004456\n",
      "current step:115900   current loss:0.10635782033205032\n",
      "current step:116000   current loss:0.013375663198530674\n",
      "current step:116100   current loss:0.25057435035705566\n",
      "current step:116200   current loss:0.1919075846672058\n",
      "current step:116300   current loss:0.027267081663012505\n",
      "current step:116400   current loss:0.11563374102115631\n",
      "current step:116500   current loss:0.1593731790781021\n",
      "current step:116600   current loss:0.016015753149986267\n",
      "current step:116700   current loss:0.1471874713897705\n",
      "current step:116800   current loss:0.14929567277431488\n",
      "current step:116900   current loss:0.11379145085811615\n",
      "current step:117000   current loss:0.025480393320322037\n",
      "current step:117100   current loss:0.15049254894256592\n",
      "current step:117200   current loss:0.11573866009712219\n",
      "current step:117300   current loss:0.11973360180854797\n",
      "current step:117400   current loss:0.031527210026979446\n",
      "current step:117500   current loss:0.07338450849056244\n",
      "current step:117600   current loss:0.1423521339893341\n",
      "current step:117700   current loss:0.24399733543395996\n",
      "current step:117800   current loss:0.066377654671669\n",
      "current step:117900   current loss:0.03083704598248005\n",
      "current step:118000   current loss:0.22494271397590637\n",
      "current step:118100   current loss:0.19065748155117035\n",
      "current step:118200   current loss:0.021709946915507317\n",
      "current step:118300   current loss:0.025315960869193077\n",
      "current step:118400   current loss:0.10241580009460449\n",
      "current step:118500   current loss:0.13701409101486206\n",
      "current step:118600   current loss:0.04078979045152664\n",
      "current step:118700   current loss:0.27127963304519653\n",
      "current step:118800   current loss:0.06404474377632141\n",
      "current step:118900   current loss:0.18113791942596436\n",
      "current step:119000   current loss:0.2325589507818222\n",
      "current step:119100   current loss:0.05856374651193619\n",
      "current step:119200   current loss:0.24757882952690125\n",
      "current step:119300   current loss:0.09508383274078369\n",
      "current step:119400   current loss:0.10744711756706238\n",
      "current step:119500   current loss:0.04948936402797699\n",
      "current step:119600   current loss:0.004257970489561558\n",
      "current step:119700   current loss:0.1546018421649933\n",
      "current step:119800   current loss:0.19839416444301605\n",
      "current step:119900   current loss:0.046749185770750046\n",
      "current step:120000   current loss:0.28201863169670105\n",
      "current step:120100   current loss:0.1938188076019287\n",
      "current step:120200   current loss:0.12661011517047882\n",
      "current step:120300   current loss:0.19432631134986877\n",
      "current step:120400   current loss:0.11670622229576111\n",
      "current step:120500   current loss:0.02524428255856037\n",
      "current step:120600   current loss:0.15407411754131317\n",
      "current step:120700   current loss:0.3453332185745239\n",
      "current step:120800   current loss:0.3470262289047241\n",
      "current step:120900   current loss:0.07122837007045746\n",
      "current step:121000   current loss:0.0641249343752861\n",
      "current step:121100   current loss:0.041441477835178375\n",
      "current step:121200   current loss:0.06690619885921478\n",
      "current step:121300   current loss:0.09022777527570724\n",
      "current step:121400   current loss:0.03403298556804657\n",
      "current step:121500   current loss:0.0697145164012909\n",
      "current step:121600   current loss:0.1518213003873825\n",
      "current step:121700   current loss:0.1106516420841217\n",
      "current step:121800   current loss:0.060669660568237305\n",
      "current step:121900   current loss:0.024972958490252495\n",
      "current step:122000   current loss:0.26864585280418396\n",
      "current step:122100   current loss:0.022524481639266014\n",
      "current step:122200   current loss:0.09623952209949493\n",
      "current step:122300   current loss:0.06260599195957184\n",
      "current step:122400   current loss:0.13086916506290436\n",
      "current step:122500   current loss:0.04677945002913475\n",
      "current step:122600   current loss:0.0877818763256073\n",
      "current step:122700   current loss:0.023192716762423515\n",
      "current step:122800   current loss:0.1989351511001587\n",
      "current step:122900   current loss:0.143027201294899\n",
      "current step:123000   current loss:0.24252267181873322\n",
      "current step:123100   current loss:0.16224408149719238\n",
      "current step:123200   current loss:0.0653042122721672\n",
      "current step:123300   current loss:0.21605616807937622\n",
      "current step:123400   current loss:0.12605322897434235\n",
      "current step:123500   current loss:0.12102655321359634\n",
      "current step:123600   current loss:0.02332262694835663\n",
      "current step:123700   current loss:0.11886551231145859\n",
      "current step:123800   current loss:0.04962088540196419\n",
      "current step:123900   current loss:0.09658774733543396\n",
      "current step:124000   current loss:0.08198453485965729\n",
      "current step:124100   current loss:0.04728444665670395\n",
      "current step:124200   current loss:0.0202358216047287\n",
      "current step:124300   current loss:0.28354060649871826\n",
      "current step:124400   current loss:0.013427751138806343\n",
      "current step:124500   current loss:0.10100936889648438\n",
      "current step:124600   current loss:0.045064620673656464\n",
      "current step:124700   current loss:0.14789435267448425\n",
      "current step:124800   current loss:0.12822812795639038\n",
      "current step:124900   current loss:0.0350116565823555\n",
      "current step:125000   current loss:0.4162220060825348\n",
      "current step:125100   current loss:0.025469094514846802\n",
      "current step:125200   current loss:0.29353928565979004\n",
      "current step:125300   current loss:0.06776493787765503\n",
      "current step:125400   current loss:0.24601614475250244\n",
      "current step:125500   current loss:0.04604668542742729\n",
      "current step:125600   current loss:0.11897825449705124\n",
      "current step:125700   current loss:0.11375636607408524\n",
      "current step:125800   current loss:0.08129184693098068\n",
      "current step:125900   current loss:0.16210530698299408\n",
      "current step:126000   current loss:0.023194463923573494\n",
      "current step:126100   current loss:0.012494951486587524\n",
      "current step:126200   current loss:0.19857701659202576\n",
      "current step:126300   current loss:0.20195487141609192\n",
      "current step:126400   current loss:0.19522008299827576\n",
      "current step:126500   current loss:0.07391854375600815\n",
      "current step:126600   current loss:0.2771124541759491\n",
      "current step:126700   current loss:0.2925053834915161\n",
      "current step:126800   current loss:0.015876896679401398\n",
      "current step:126900   current loss:0.01176006905734539\n",
      "current step:127000   current loss:0.2198280692100525\n",
      "current step:127100   current loss:0.07750679552555084\n",
      "current step:127200   current loss:0.008051900193095207\n",
      "current step:127300   current loss:0.15814249217510223\n",
      "current step:127400   current loss:0.2955593466758728\n",
      "current step:127500   current loss:0.06406435370445251\n",
      "current step:127600   current loss:0.037398818880319595\n",
      "current step:127700   current loss:0.13201411068439484\n",
      "current step:127800   current loss:0.21918368339538574\n",
      "current step:127900   current loss:0.059851475059986115\n",
      "current step:128000   current loss:0.2539491653442383\n",
      "current step:128100   current loss:0.08809889853000641\n",
      "current step:128200   current loss:0.13749606907367706\n",
      "current step:128300   current loss:0.14955997467041016\n",
      "current step:128400   current loss:0.161263570189476\n",
      "current step:128500   current loss:0.012904749251902103\n",
      "current step:128600   current loss:0.1484438180923462\n",
      "current step:128700   current loss:0.07986964285373688\n",
      "current step:128800   current loss:0.15296712517738342\n",
      "current step:128900   current loss:0.11581657081842422\n",
      "current step:129000   current loss:0.06993018090724945\n",
      "current step:129100   current loss:0.3490406572818756\n",
      "current step:129200   current loss:0.09974988549947739\n",
      "current step:129300   current loss:0.14494945108890533\n",
      "current step:129400   current loss:0.15360009670257568\n",
      "current step:129500   current loss:0.16676601767539978\n",
      "current step:129600   current loss:0.1876221001148224\n",
      "current step:129700   current loss:0.2583223283290863\n",
      "current step:129800   current loss:0.04077492654323578\n",
      "current step:129900   current loss:0.0485176146030426\n",
      "current step:130000   current loss:0.2694711685180664\n",
      "current step:130100   current loss:0.02934352308511734\n",
      "current step:130200   current loss:0.08283683657646179\n",
      "current step:130300   current loss:0.015340618789196014\n",
      "current step:130400   current loss:0.10982725024223328\n",
      "current step:130500   current loss:0.04730759933590889\n",
      "current step:130600   current loss:0.02683589793741703\n",
      "current step:130700   current loss:0.17030751705169678\n",
      "current step:130800   current loss:0.16813448071479797\n",
      "current step:130900   current loss:0.08115649223327637\n",
      "current step:131000   current loss:0.3006010055541992\n",
      "current step:131100   current loss:0.12722212076187134\n",
      "current step:131200   current loss:0.22656050324440002\n",
      "current step:131300   current loss:0.06847439706325531\n",
      "current step:131400   current loss:0.022986190393567085\n",
      "current step:131500   current loss:0.08161984384059906\n",
      "current step:131600   current loss:0.09147778153419495\n",
      "current step:131700   current loss:0.12285725027322769\n",
      "current step:131800   current loss:0.10192486643791199\n",
      "current step:131900   current loss:0.05041150748729706\n",
      "current step:132000   current loss:0.15336714684963226\n",
      "current step:132100   current loss:0.24443361163139343\n",
      "current step:132200   current loss:0.23348219692707062\n",
      "current step:132300   current loss:0.06427422165870667\n",
      "current step:132400   current loss:0.14581787586212158\n",
      "current step:132500   current loss:0.0786517858505249\n",
      "current step:132600   current loss:0.2695038318634033\n",
      "current step:132700   current loss:0.20507946610450745\n",
      "current step:132800   current loss:0.027947191148996353\n",
      "current step:132900   current loss:0.15483462810516357\n",
      "current step:133000   current loss:0.040358737111091614\n",
      "current step:133100   current loss:0.35079604387283325\n",
      "current step:133200   current loss:0.2002519816160202\n",
      "current step:133300   current loss:0.28693124651908875\n",
      "current step:133400   current loss:0.09637250751256943\n",
      "current step:133500   current loss:0.34855425357818604\n",
      "current step:133600   current loss:0.3060161769390106\n",
      "current step:133700   current loss:0.267261803150177\n",
      "current step:133800   current loss:0.12906278669834137\n",
      "current step:133900   current loss:0.36520299315452576\n",
      "current step:134000   current loss:0.2632089853286743\n",
      "current step:134100   current loss:0.11197365075349808\n",
      "current step:134200   current loss:0.19544166326522827\n",
      "current step:134300   current loss:0.02262042462825775\n",
      "current step:134400   current loss:0.10596375167369843\n",
      "current step:134500   current loss:0.21833011507987976\n",
      "current step:134600   current loss:0.022242514416575432\n",
      "current step:134700   current loss:0.04868463799357414\n",
      "current step:134800   current loss:0.18280959129333496\n",
      "current step:134900   current loss:0.31386998295783997\n",
      "current step:135000   current loss:0.058455705642700195\n",
      "current step:135100   current loss:0.32504698634147644\n",
      "current step:135200   current loss:0.03950466960668564\n",
      "current step:135300   current loss:0.11050671339035034\n",
      "current step:135400   current loss:0.13468873500823975\n",
      "current step:135500   current loss:0.1356121450662613\n",
      "current step:135600   current loss:0.06107176095247269\n",
      "current step:135700   current loss:0.1541651040315628\n",
      "current step:135800   current loss:0.03765832260251045\n",
      "current step:135900   current loss:0.042325764894485474\n",
      "current step:136000   current loss:0.11041215807199478\n",
      "current step:136100   current loss:0.10337112843990326\n",
      "current step:136200   current loss:0.01862352527678013\n",
      "current step:136300   current loss:0.07630936801433563\n",
      "current step:136400   current loss:0.1148892194032669\n",
      "current step:136500   current loss:0.1856052577495575\n",
      "current step:136600   current loss:0.39681005477905273\n",
      "current step:136700   current loss:0.01686199940741062\n",
      "current step:136800   current loss:0.1290537714958191\n",
      "current step:136900   current loss:0.015705373138189316\n",
      "current step:137000   current loss:0.08875681459903717\n",
      "current step:137100   current loss:0.08165198564529419\n",
      "current step:137200   current loss:0.022469423711299896\n",
      "current step:137300   current loss:0.20663151144981384\n",
      "current step:137400   current loss:0.13125154376029968\n",
      "current step:137500   current loss:0.21395623683929443\n",
      "current step:137600   current loss:0.016275200992822647\n",
      "current step:137700   current loss:0.12722252309322357\n",
      "current step:137800   current loss:0.15812267363071442\n",
      "current step:137900   current loss:0.2068508267402649\n",
      "current step:138000   current loss:0.016705520451068878\n",
      "current step:138100   current loss:0.21147938072681427\n",
      "current step:138200   current loss:0.17231318354606628\n",
      "current step:138300   current loss:0.2139534056186676\n",
      "current step:138400   current loss:0.06339811533689499\n",
      "current step:138500   current loss:0.30099642276763916\n",
      "current step:138600   current loss:0.4663194715976715\n",
      "current step:138700   current loss:0.1602308750152588\n",
      "current step:138800   current loss:0.07154381275177002\n",
      "current step:138900   current loss:0.2613568902015686\n",
      "current step:139000   current loss:0.023940710350871086\n",
      "current step:139100   current loss:0.2986820936203003\n",
      "current step:139200   current loss:0.22581085562705994\n",
      "current step:139300   current loss:0.0763779878616333\n",
      "current step:139400   current loss:0.171593576669693\n",
      "current step:139500   current loss:0.052218325436115265\n",
      "current step:139600   current loss:0.08465482294559479\n",
      "current step:139700   current loss:0.009162113070487976\n",
      "current step:139800   current loss:0.05854023993015289\n",
      "current step:139900   current loss:0.23687055706977844\n",
      "current step:140000   current loss:0.1379438191652298\n",
      "current step:140100   current loss:0.24541254341602325\n",
      "current step:140200   current loss:0.05659113824367523\n",
      "current step:140300   current loss:0.01828368380665779\n",
      "current step:140400   current loss:0.1771060824394226\n",
      "current step:140500   current loss:0.07274132966995239\n",
      "current step:140600   current loss:0.2091575562953949\n",
      "current step:140700   current loss:0.019422924146056175\n",
      "current step:140800   current loss:0.09627755731344223\n",
      "current step:140900   current loss:0.040641918778419495\n",
      "current step:141000   current loss:0.20725378394126892\n",
      "current step:141100   current loss:0.09458108991384506\n",
      "current step:141200   current loss:0.03290780633687973\n",
      "current step:141300   current loss:0.016211314126849174\n",
      "current step:141400   current loss:0.06682320684194565\n",
      "current step:141500   current loss:0.17285674810409546\n",
      "current step:141600   current loss:0.02745353803038597\n",
      "current step:141700   current loss:0.2166994959115982\n",
      "current step:141800   current loss:0.12337929010391235\n",
      "current step:141900   current loss:0.08203275501728058\n",
      "current step:142000   current loss:0.015893014147877693\n",
      "current step:142100   current loss:0.021203814074397087\n",
      "current step:142200   current loss:0.04270253702998161\n",
      "current step:142300   current loss:0.42945483326911926\n",
      "current step:142400   current loss:0.14468461275100708\n",
      "current step:142500   current loss:0.030682500451803207\n",
      "current step:142600   current loss:0.3439342975616455\n",
      "current step:142700   current loss:0.08535057306289673\n",
      "current step:142800   current loss:0.10148412734270096\n",
      "current step:142900   current loss:0.044429246336221695\n",
      "current step:143000   current loss:0.07865284383296967\n",
      "current step:143100   current loss:0.15013223886489868\n",
      "current step:143200   current loss:0.3551197648048401\n",
      "current step:143300   current loss:0.1543389856815338\n",
      "current step:143400   current loss:0.039293840527534485\n",
      "current step:143500   current loss:0.49107059836387634\n",
      "current step:143600   current loss:0.21664458513259888\n",
      "current step:143700   current loss:0.2049047350883484\n",
      "current step:143800   current loss:0.035746846348047256\n",
      "current step:143900   current loss:0.14375485479831696\n",
      "current step:144000   current loss:0.023155586794018745\n",
      "current step:144100   current loss:0.00651811808347702\n",
      "current step:144200   current loss:0.03056926466524601\n",
      "current step:144300   current loss:0.06637537479400635\n",
      "current step:144400   current loss:0.12264230102300644\n",
      "current step:144500   current loss:0.1452881246805191\n",
      "current step:144600   current loss:0.03713637590408325\n",
      "current step:144700   current loss:0.04307537525892258\n",
      "current step:144800   current loss:0.1628502756357193\n",
      "current step:144900   current loss:0.3506898283958435\n",
      "current step:145000   current loss:0.04999589920043945\n",
      "current step:145100   current loss:0.03687875717878342\n",
      "current step:145200   current loss:0.18097145855426788\n",
      "current step:145300   current loss:0.17729274928569794\n",
      "current step:145400   current loss:0.35011398792266846\n",
      "current step:145500   current loss:0.06956156343221664\n",
      "current step:145600   current loss:0.48343703150749207\n",
      "current step:145700   current loss:0.21996155381202698\n",
      "current step:145800   current loss:0.02552865818142891\n",
      "current step:145900   current loss:0.06471860408782959\n",
      "current step:146000   current loss:0.07577304542064667\n",
      "current step:146100   current loss:0.17951533198356628\n",
      "current step:146200   current loss:0.05725077539682388\n",
      "current step:146300   current loss:0.16900911927223206\n",
      "current step:146400   current loss:0.029289498925209045\n",
      "current step:146500   current loss:0.025789905339479446\n",
      "current step:146600   current loss:0.09264472126960754\n",
      "current step:146700   current loss:0.01643431931734085\n",
      "current step:146800   current loss:0.04488581418991089\n",
      "current step:146900   current loss:0.10387519747018814\n",
      "current step:147000   current loss:0.09577600657939911\n",
      "current step:147100   current loss:0.02597525529563427\n",
      "current step:147200   current loss:0.11704462766647339\n",
      "current step:147300   current loss:0.02598123997449875\n",
      "current step:147400   current loss:0.3055139183998108\n",
      "current step:147500   current loss:0.18797439336776733\n",
      "current step:147600   current loss:0.36360710859298706\n",
      "current step:147700   current loss:0.29047301411628723\n",
      "current step:147800   current loss:0.1488485485315323\n",
      "current step:147900   current loss:0.03303031250834465\n",
      "current step:148000   current loss:0.06683848798274994\n",
      "current step:148100   current loss:0.22245363891124725\n",
      "current step:148200   current loss:0.3228836953639984\n",
      "current step:148300   current loss:0.12127965688705444\n",
      "current step:148400   current loss:0.05002408102154732\n",
      "current step:148500   current loss:0.24487756192684174\n",
      "current step:148600   current loss:0.1090860366821289\n",
      "current step:148700   current loss:0.16025468707084656\n",
      "current step:148800   current loss:0.07827455550432205\n",
      "current step:148900   current loss:0.12759855389595032\n",
      "current step:149000   current loss:0.2238510400056839\n",
      "current step:149100   current loss:0.03772687539458275\n",
      "current step:149200   current loss:0.040651872754096985\n",
      "current step:149300   current loss:0.1831984519958496\n",
      "current step:149400   current loss:0.013417074456810951\n",
      "current step:149500   current loss:0.04543401673436165\n",
      "current step:149600   current loss:0.0875329077243805\n",
      "current step:149700   current loss:0.052698902785778046\n",
      "current step:149800   current loss:0.03456934541463852\n",
      "current step:149900   current loss:0.17588359117507935\n",
      "current step:150000   current loss:0.2200704962015152\n",
      "current step:150100   current loss:0.24034185707569122\n",
      "current step:150200   current loss:0.006819072645157576\n",
      "current step:150300   current loss:0.10034629702568054\n",
      "current step:150400   current loss:0.11095400899648666\n",
      "current step:150500   current loss:0.0651964619755745\n",
      "current step:150600   current loss:0.1390213966369629\n",
      "current step:150700   current loss:0.0985783040523529\n",
      "current step:150800   current loss:0.1541048288345337\n",
      "current step:150900   current loss:0.07810293138027191\n",
      "current step:151000   current loss:0.1434156894683838\n",
      "current step:151100   current loss:0.1260252743959427\n",
      "current step:151200   current loss:0.1041913777589798\n",
      "current step:151300   current loss:0.008672928437590599\n",
      "current step:151400   current loss:0.09767833352088928\n",
      "current step:151500   current loss:0.3026959002017975\n",
      "current step:151600   current loss:0.2785365581512451\n",
      "current step:151700   current loss:0.09808846563100815\n",
      "current step:151800   current loss:0.07355794310569763\n",
      "current step:151900   current loss:0.13394397497177124\n",
      "current step:152000   current loss:0.26670852303504944\n",
      "current step:152100   current loss:0.11390263587236404\n",
      "current step:152200   current loss:0.17639364302158356\n",
      "current step:152300   current loss:0.04226387292146683\n",
      "current step:152400   current loss:0.2523655295372009\n",
      "current step:152500   current loss:0.10579807311296463\n",
      "current step:152600   current loss:0.09818043559789658\n",
      "current step:152700   current loss:0.1156373992562294\n",
      "current step:152800   current loss:0.1317426562309265\n",
      "current step:152900   current loss:0.1072971522808075\n",
      "current step:153000   current loss:0.09289171546697617\n",
      "current step:153100   current loss:0.1255742311477661\n",
      "current step:153200   current loss:0.0880591869354248\n",
      "current step:153300   current loss:0.408128559589386\n",
      "current step:153400   current loss:0.1393539011478424\n",
      "current step:153500   current loss:0.0165852140635252\n",
      "current step:153600   current loss:0.15351799130439758\n",
      "current step:153700   current loss:0.18082764744758606\n",
      "current step:153800   current loss:0.11863049864768982\n",
      "current step:153900   current loss:0.23625223338603973\n",
      "current step:154000   current loss:0.028337722644209862\n",
      "current step:154100   current loss:0.049418509006500244\n",
      "current step:154200   current loss:0.05842746049165726\n",
      "current step:154300   current loss:0.19333145022392273\n",
      "current step:154400   current loss:0.24048170447349548\n",
      "current step:154500   current loss:0.11858420819044113\n",
      "current step:154600   current loss:0.21401357650756836\n",
      "current step:154700   current loss:0.1848127245903015\n",
      "current step:154800   current loss:0.1289459466934204\n",
      "current step:154900   current loss:0.0544673427939415\n",
      "current step:155000   current loss:0.035911548882722855\n",
      "current step:155100   current loss:0.2438109964132309\n",
      "current step:155200   current loss:0.14365410804748535\n",
      "current step:155300   current loss:0.05279158055782318\n",
      "current step:155400   current loss:0.362009733915329\n",
      "current step:155500   current loss:0.14884597063064575\n",
      "current step:155600   current loss:0.10345721244812012\n",
      "current step:155700   current loss:0.06648053973913193\n",
      "current step:155800   current loss:0.16572655737400055\n",
      "current step:155900   current loss:0.05538077652454376\n",
      "current step:156000   current loss:0.04171771556138992\n",
      "current step:156100   current loss:0.01090650912374258\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = tf.keras.optimizers.AdamW(learning_rate=1e-3, clipnorm=1.0)\n",
    "\n",
    "# 放其使用fit函式，因為該函式無法覆蓋複雜的倒傳遞計算。若要依照GAN範例重寫train_step，可能會破壞原本\n",
    "# 進行distribute運算的單元。最終工程與重寫一整個customize training loop相當。\n",
    "\n",
    "# 目標先改回使用customize training step\n",
    "# Keras3把optimizer的minimize函數移除，只能使用gradient tape\n",
    "\n",
    "# training loop\n",
    "trainingSteps = 156200\n",
    "\n",
    "@tf.function(jit_compile=True)\n",
    "def training_loop(tr_test_loader):\n",
    "    with tf.GradientTape() as gTape:\n",
    "        loss = fitness(tr_test_loader[1], datasetFetchingScaling(tr_test_loader[0]))\n",
    "        \n",
    "    grads = gTape.gradient(loss, model.trainable_weights)\n",
    "    opt.apply(grads, model.trainable_weights)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "for currentTrainingStep in range(trainingSteps):\n",
    "    # fetch data\n",
    "    tr_test_loader = next(train_dataset_iter)\n",
    "    \n",
    "    loss = training_loop(tr_test_loader)\n",
    "    \n",
    "    if currentTrainingStep % 100 == 0:\n",
    "        print(\"current step:{}   current loss:{}\".format(currentTrainingStep, loss))\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
