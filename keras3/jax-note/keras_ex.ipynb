{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This guide can only be run with the jax backend.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# We import TF so we can use tf.data.\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 06:27:02.992570: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    x2 = keras.layers.Dense(64, activation=\"relu\")(x1)\n",
    "    outputs = keras.layers.Dense(10, name=\"predictions\")(x2)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# model = get_model()\n",
    "\n",
    "# Prepare the training dataset.\n",
    "batch_size = 32\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\")\n",
    "x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\")\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=1e-3, clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n",
    "    y_pred, non_trainable_variables = model.stateless_call(\n",
    "        trainable_variables, non_trainable_variables, x\n",
    "    )\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return loss, non_trainable_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, data):\n",
    "    # 不使用jit會有錯誤發生而無法訓練，目前原因未知\n",
    "    trainable_variables, non_trainable_variables, optimizer_variables = state\n",
    "    x, y = data\n",
    "    (loss, non_trainable_variables), grads = grad_fn(\n",
    "        trainable_variables, non_trainable_variables, x, y\n",
    "    )\n",
    "    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
    "        optimizer_variables, grads, trainable_variables\n",
    "    )\n",
    "    # Return updated state\n",
    "    return loss, (\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        optimizer_variables,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for 1 batch) at step 0: 111.7812\n",
      "Seen so far: 32 samples\n",
      "Training loss (for 1 batch) at step 100: 1.6654\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for 1 batch) at step 200: 1.1273\n",
      "Seen so far: 6432 samples\n",
      "Training loss (for 1 batch) at step 300: 1.6074\n",
      "Seen so far: 9632 samples\n",
      "Training loss (for 1 batch) at step 400: 1.6776\n",
      "Seen so far: 12832 samples\n",
      "Training loss (for 1 batch) at step 500: 0.2396\n",
      "Seen so far: 16032 samples\n",
      "Training loss (for 1 batch) at step 600: 0.6327\n",
      "Seen so far: 19232 samples\n",
      "Training loss (for 1 batch) at step 700: 0.2158\n",
      "Seen so far: 22432 samples\n",
      "Training loss (for 1 batch) at step 800: 0.3267\n",
      "Seen so far: 25632 samples\n",
      "Training loss (for 1 batch) at step 900: 0.6049\n",
      "Seen so far: 28832 samples\n",
      "Training loss (for 1 batch) at step 1000: 0.3289\n",
      "Seen so far: 32032 samples\n",
      "Training loss (for 1 batch) at step 1100: 0.2887\n",
      "Seen so far: 35232 samples\n",
      "Training loss (for 1 batch) at step 1200: 0.3123\n",
      "Seen so far: 38432 samples\n",
      "Training loss (for 1 batch) at step 1300: 0.3617\n",
      "Seen so far: 41632 samples\n",
      "Training loss (for 1 batch) at step 1400: 0.1765\n",
      "Seen so far: 44832 samples\n",
      "Training loss (for 1 batch) at step 1500: 0.4517\n",
      "Seen so far: 48032 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 06:27:31.601270: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Build optimizer variables.\n",
    "optimizer.build(model.trainable_variables)\n",
    "\n",
    "trainable_variables = model.trainable_variables\n",
    "non_trainable_variables = model.non_trainable_variables\n",
    "optimizer_variables = optimizer.variables\n",
    "state = trainable_variables, non_trainable_variables, optimizer_variables\n",
    "\n",
    "# Training loop\n",
    "for step, data in enumerate(train_dataset):\n",
    "    data = (data[0].numpy(), data[1].numpy())\n",
    "    loss, state = train_step(state, data)\n",
    "    # Log every 100 batches.\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Training loss (for 1 batch) at step {step}: {float(loss):.4f}\")\n",
    "        print(f\"Seen so far: {(step + 1) * batch_size} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before assign:\n",
      "[[-0.56451714 -0.41317883 -1.0507475   0.86134243 -0.3582103   0.69896895\n",
      "   0.5061509  -0.8784539  -0.22967747 -0.57622534]]\n",
      "after assign:\n",
      "[[-0.20653455 -0.3140297   0.12025344  0.12553349  0.07457571 -0.01390003\n",
      "  -0.11240885 -0.17743774  0.4671492   0.02217555]]\n"
     ]
    }
   ],
   "source": [
    "# 透過Stateless訓練的結果只會儲存在state的變數當中，需要把這些算完的state放回到模型中，\n",
    "# 才能使用keras.model的物件進行操作(例如存檔等等的行為)\n",
    "\n",
    "print(\"before assign:\")\n",
    "print(model(np.ones([1,784])))\n",
    "\n",
    "trainable_variables, non_trainable_variables, optimizer_variables = state\n",
    "for variable, value in zip(model.trainable_variables, trainable_variables):\n",
    "    variable.assign(value)\n",
    "for variable, value in zip(model.non_trainable_variables, non_trainable_variables):\n",
    "    variable.assign(value)\n",
    "    \n",
    "print(\"after assign:\")\n",
    "print(model(np.ones([1,784])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
