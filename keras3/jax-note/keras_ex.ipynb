{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This guide can only be run with the jax backend.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# We import TF so we can use tf.data.\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 12:15:49.844295: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    x2 = keras.layers.Dense(64, activation=\"relu\")(x1)\n",
    "    outputs = keras.layers.Dense(10, name=\"predictions\")(x2)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# model = get_model()\n",
    "\n",
    "# Prepare the training dataset.\n",
    "batch_size = 32\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784)).astype(\"float32\")\n",
    "x_test = np.reshape(x_test, (-1, 784)).astype(\"float32\")\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).repeat(100)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=1e-3, clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n",
    "    y_pred, non_trainable_variables = model.stateless_call(\n",
    "        trainable_variables, non_trainable_variables, x\n",
    "    )\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return loss, non_trainable_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, data):\n",
    "    # 不使用jit會有錯誤發生而無法訓練，目前原因未知\n",
    "    trainable_variables, non_trainable_variables, optimizer_variables = state\n",
    "    x, y = data\n",
    "    (loss, non_trainable_variables), grads = grad_fn(\n",
    "        trainable_variables, non_trainable_variables, x, y\n",
    "    )\n",
    "    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
    "        optimizer_variables, grads, trainable_variables\n",
    "    )\n",
    "    # Return updated state\n",
    "    return loss, (\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        optimizer_variables,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for 1 batch) at step 0: 93.1028\n",
      "Seen so far: 32 samples\n",
      "Training loss (for 1 batch) at step 100: 4.4164\n",
      "Seen so far: 3232 samples\n",
      "Training loss (for 1 batch) at step 200: 1.5426\n",
      "Seen so far: 6432 samples\n",
      "Training loss (for 1 batch) at step 300: 1.2138\n",
      "Seen so far: 9632 samples\n",
      "Training loss (for 1 batch) at step 400: 1.3932\n",
      "Seen so far: 12832 samples\n",
      "Training loss (for 1 batch) at step 500: 0.5289\n",
      "Seen so far: 16032 samples\n",
      "Training loss (for 1 batch) at step 600: 1.1409\n",
      "Seen so far: 19232 samples\n",
      "Training loss (for 1 batch) at step 700: 1.0675\n",
      "Seen so far: 22432 samples\n",
      "Training loss (for 1 batch) at step 800: 0.9719\n",
      "Seen so far: 25632 samples\n",
      "Training loss (for 1 batch) at step 900: 0.6001\n",
      "Seen so far: 28832 samples\n",
      "Training loss (for 1 batch) at step 1000: 0.5128\n",
      "Seen so far: 32032 samples\n",
      "Training loss (for 1 batch) at step 1100: 0.6188\n",
      "Seen so far: 35232 samples\n",
      "Training loss (for 1 batch) at step 1200: 0.2034\n",
      "Seen so far: 38432 samples\n",
      "Training loss (for 1 batch) at step 1300: 0.2621\n",
      "Seen so far: 41632 samples\n",
      "Training loss (for 1 batch) at step 1400: 0.3714\n",
      "Seen so far: 44832 samples\n",
      "Training loss (for 1 batch) at step 1500: 0.2268\n",
      "Seen so far: 48032 samples\n",
      "Training loss (for 1 batch) at step 1600: 1.2499\n",
      "Seen so far: 51232 samples\n",
      "Training loss (for 1 batch) at step 1700: 0.2422\n",
      "Seen so far: 54432 samples\n",
      "Training loss (for 1 batch) at step 1800: 0.2693\n",
      "Seen so far: 57632 samples\n",
      "Training loss (for 1 batch) at step 1900: 0.4627\n",
      "Seen so far: 60832 samples\n",
      "Training loss (for 1 batch) at step 2000: 0.6198\n",
      "Seen so far: 64032 samples\n",
      "Training loss (for 1 batch) at step 2100: 0.2925\n",
      "Seen so far: 67232 samples\n",
      "Training loss (for 1 batch) at step 2200: 0.9178\n",
      "Seen so far: 70432 samples\n",
      "Training loss (for 1 batch) at step 2300: 0.3151\n",
      "Seen so far: 73632 samples\n",
      "Training loss (for 1 batch) at step 2400: 0.6109\n",
      "Seen so far: 76832 samples\n",
      "Training loss (for 1 batch) at step 2500: 0.1684\n",
      "Seen so far: 80032 samples\n",
      "Training loss (for 1 batch) at step 2600: 0.2696\n",
      "Seen so far: 83232 samples\n",
      "Training loss (for 1 batch) at step 2700: 0.2223\n",
      "Seen so far: 86432 samples\n",
      "Training loss (for 1 batch) at step 2800: 0.4233\n",
      "Seen so far: 89632 samples\n",
      "Training loss (for 1 batch) at step 2900: 0.8042\n",
      "Seen so far: 92832 samples\n",
      "Training loss (for 1 batch) at step 3000: 0.4112\n",
      "Seen so far: 96032 samples\n",
      "Training loss (for 1 batch) at step 3100: 1.4826\n",
      "Seen so far: 99232 samples\n",
      "Training loss (for 1 batch) at step 3200: 0.0907\n",
      "Seen so far: 102432 samples\n",
      "Training loss (for 1 batch) at step 3300: 0.0074\n",
      "Seen so far: 105632 samples\n",
      "Training loss (for 1 batch) at step 3400: 0.0437\n",
      "Seen so far: 108832 samples\n",
      "Training loss (for 1 batch) at step 3500: 0.0635\n",
      "Seen so far: 112032 samples\n",
      "Training loss (for 1 batch) at step 3600: 0.3731\n",
      "Seen so far: 115232 samples\n",
      "Training loss (for 1 batch) at step 3700: 0.4820\n",
      "Seen so far: 118432 samples\n",
      "Training loss (for 1 batch) at step 3800: 0.7944\n",
      "Seen so far: 121632 samples\n",
      "Training loss (for 1 batch) at step 3900: 0.3733\n",
      "Seen so far: 124832 samples\n",
      "Training loss (for 1 batch) at step 4000: 0.3528\n",
      "Seen so far: 128032 samples\n",
      "Training loss (for 1 batch) at step 4100: 0.1452\n",
      "Seen so far: 131232 samples\n",
      "Training loss (for 1 batch) at step 4200: 0.2025\n",
      "Seen so far: 134432 samples\n",
      "Training loss (for 1 batch) at step 4300: 0.3377\n",
      "Seen so far: 137632 samples\n",
      "Training loss (for 1 batch) at step 4400: 0.0109\n",
      "Seen so far: 140832 samples\n",
      "Training loss (for 1 batch) at step 4500: 0.0156\n",
      "Seen so far: 144032 samples\n",
      "Training loss (for 1 batch) at step 4600: 0.1710\n",
      "Seen so far: 147232 samples\n",
      "Training loss (for 1 batch) at step 4700: 0.0474\n",
      "Seen so far: 150432 samples\n",
      "Training loss (for 1 batch) at step 4800: 0.0978\n",
      "Seen so far: 153632 samples\n",
      "Training loss (for 1 batch) at step 4900: 0.0048\n",
      "Seen so far: 156832 samples\n",
      "Training loss (for 1 batch) at step 5000: 0.3694\n",
      "Seen so far: 160032 samples\n",
      "Training loss (for 1 batch) at step 5100: 0.1796\n",
      "Seen so far: 163232 samples\n",
      "Training loss (for 1 batch) at step 5200: 0.1289\n",
      "Seen so far: 166432 samples\n",
      "Training loss (for 1 batch) at step 5300: 0.1784\n",
      "Seen so far: 169632 samples\n",
      "Training loss (for 1 batch) at step 5400: 0.0263\n",
      "Seen so far: 172832 samples\n",
      "Training loss (for 1 batch) at step 5500: 0.1064\n",
      "Seen so far: 176032 samples\n",
      "Training loss (for 1 batch) at step 5600: 0.3435\n",
      "Seen so far: 179232 samples\n",
      "Training loss (for 1 batch) at step 5700: 0.0535\n",
      "Seen so far: 182432 samples\n",
      "Training loss (for 1 batch) at step 5800: 0.0109\n",
      "Seen so far: 185632 samples\n",
      "Training loss (for 1 batch) at step 5900: 0.0251\n",
      "Seen so far: 188832 samples\n",
      "Training loss (for 1 batch) at step 6000: 0.1466\n",
      "Seen so far: 192032 samples\n",
      "Training loss (for 1 batch) at step 6100: 0.1043\n",
      "Seen so far: 195232 samples\n",
      "Training loss (for 1 batch) at step 6200: 0.0262\n",
      "Seen so far: 198432 samples\n",
      "Training loss (for 1 batch) at step 6300: 0.1315\n",
      "Seen so far: 201632 samples\n",
      "Training loss (for 1 batch) at step 6400: 0.0600\n",
      "Seen so far: 204832 samples\n",
      "Training loss (for 1 batch) at step 6500: 0.3471\n",
      "Seen so far: 208032 samples\n",
      "Training loss (for 1 batch) at step 6600: 0.1439\n",
      "Seen so far: 211232 samples\n",
      "Training loss (for 1 batch) at step 6700: 0.2669\n",
      "Seen so far: 214432 samples\n",
      "Training loss (for 1 batch) at step 6800: 0.0184\n",
      "Seen so far: 217632 samples\n",
      "Training loss (for 1 batch) at step 6900: 0.1199\n",
      "Seen so far: 220832 samples\n",
      "Training loss (for 1 batch) at step 7000: 0.1629\n",
      "Seen so far: 224032 samples\n",
      "Training loss (for 1 batch) at step 7100: 0.0794\n",
      "Seen so far: 227232 samples\n",
      "Training loss (for 1 batch) at step 7200: 0.0032\n",
      "Seen so far: 230432 samples\n",
      "Training loss (for 1 batch) at step 7300: 0.0104\n",
      "Seen so far: 233632 samples\n",
      "Training loss (for 1 batch) at step 7400: 0.1921\n",
      "Seen so far: 236832 samples\n",
      "Training loss (for 1 batch) at step 7500: 0.1742\n",
      "Seen so far: 240032 samples\n",
      "Training loss (for 1 batch) at step 7600: 0.1370\n",
      "Seen so far: 243232 samples\n",
      "Training loss (for 1 batch) at step 7700: 0.3839\n",
      "Seen so far: 246432 samples\n",
      "Training loss (for 1 batch) at step 7800: 0.0348\n",
      "Seen so far: 249632 samples\n",
      "Training loss (for 1 batch) at step 7900: 0.0194\n",
      "Seen so far: 252832 samples\n",
      "Training loss (for 1 batch) at step 8000: 0.1735\n",
      "Seen so far: 256032 samples\n",
      "Training loss (for 1 batch) at step 8100: 0.0905\n",
      "Seen so far: 259232 samples\n",
      "Training loss (for 1 batch) at step 8200: 0.0027\n",
      "Seen so far: 262432 samples\n",
      "Training loss (for 1 batch) at step 8300: 0.1174\n",
      "Seen so far: 265632 samples\n",
      "Training loss (for 1 batch) at step 8400: 0.2431\n",
      "Seen so far: 268832 samples\n",
      "Training loss (for 1 batch) at step 8500: 0.5552\n",
      "Seen so far: 272032 samples\n",
      "Training loss (for 1 batch) at step 8600: 0.1469\n",
      "Seen so far: 275232 samples\n",
      "Training loss (for 1 batch) at step 8700: 0.0205\n",
      "Seen so far: 278432 samples\n",
      "Training loss (for 1 batch) at step 8800: 0.1034\n",
      "Seen so far: 281632 samples\n",
      "Training loss (for 1 batch) at step 8900: 0.0366\n",
      "Seen so far: 284832 samples\n",
      "Training loss (for 1 batch) at step 9000: 0.0795\n",
      "Seen so far: 288032 samples\n",
      "Training loss (for 1 batch) at step 9100: 0.0492\n",
      "Seen so far: 291232 samples\n",
      "Training loss (for 1 batch) at step 9200: 0.1270\n",
      "Seen so far: 294432 samples\n",
      "Training loss (for 1 batch) at step 9300: 0.0303\n",
      "Seen so far: 297632 samples\n",
      "Training loss (for 1 batch) at step 9400: 0.1625\n",
      "Seen so far: 300832 samples\n",
      "Training loss (for 1 batch) at step 9500: 0.3652\n",
      "Seen so far: 304032 samples\n",
      "Training loss (for 1 batch) at step 9600: 0.1611\n",
      "Seen so far: 307232 samples\n",
      "Training loss (for 1 batch) at step 9700: 0.0225\n",
      "Seen so far: 310432 samples\n",
      "Training loss (for 1 batch) at step 9800: 0.2517\n",
      "Seen so far: 313632 samples\n",
      "Training loss (for 1 batch) at step 9900: 0.3601\n",
      "Seen so far: 316832 samples\n",
      "Training loss (for 1 batch) at step 10000: 0.1914\n",
      "Seen so far: 320032 samples\n",
      "Training loss (for 1 batch) at step 10100: 0.0446\n",
      "Seen so far: 323232 samples\n",
      "Training loss (for 1 batch) at step 10200: 0.0543\n",
      "Seen so far: 326432 samples\n",
      "Training loss (for 1 batch) at step 10300: 0.7422\n",
      "Seen so far: 329632 samples\n",
      "Training loss (for 1 batch) at step 10400: 0.8234\n",
      "Seen so far: 332832 samples\n",
      "Training loss (for 1 batch) at step 10500: 0.0795\n",
      "Seen so far: 336032 samples\n",
      "Training loss (for 1 batch) at step 10600: 0.2186\n",
      "Seen so far: 339232 samples\n",
      "Training loss (for 1 batch) at step 10700: 0.0549\n",
      "Seen so far: 342432 samples\n",
      "Training loss (for 1 batch) at step 10800: 0.0719\n",
      "Seen so far: 345632 samples\n",
      "Training loss (for 1 batch) at step 10900: 0.1871\n",
      "Seen so far: 348832 samples\n",
      "Training loss (for 1 batch) at step 11000: 0.0763\n",
      "Seen so far: 352032 samples\n",
      "Training loss (for 1 batch) at step 11100: 0.2339\n",
      "Seen so far: 355232 samples\n",
      "Training loss (for 1 batch) at step 11200: 0.0631\n",
      "Seen so far: 358432 samples\n",
      "Training loss (for 1 batch) at step 11300: 0.5181\n",
      "Seen so far: 361632 samples\n",
      "Training loss (for 1 batch) at step 11400: 0.1063\n",
      "Seen so far: 364832 samples\n",
      "Training loss (for 1 batch) at step 11500: 0.4241\n",
      "Seen so far: 368032 samples\n",
      "Training loss (for 1 batch) at step 11600: 0.0480\n",
      "Seen so far: 371232 samples\n",
      "Training loss (for 1 batch) at step 11700: 0.0100\n",
      "Seen so far: 374432 samples\n",
      "Training loss (for 1 batch) at step 11800: 0.1921\n",
      "Seen so far: 377632 samples\n",
      "Training loss (for 1 batch) at step 11900: 0.2929\n",
      "Seen so far: 380832 samples\n",
      "Training loss (for 1 batch) at step 12000: 0.0483\n",
      "Seen so far: 384032 samples\n",
      "Training loss (for 1 batch) at step 12100: 0.4574\n",
      "Seen so far: 387232 samples\n",
      "Training loss (for 1 batch) at step 12200: 0.1368\n",
      "Seen so far: 390432 samples\n",
      "Training loss (for 1 batch) at step 12300: 0.1363\n",
      "Seen so far: 393632 samples\n",
      "Training loss (for 1 batch) at step 12400: 0.1727\n",
      "Seen so far: 396832 samples\n",
      "Training loss (for 1 batch) at step 12500: 0.5221\n",
      "Seen so far: 400032 samples\n",
      "Training loss (for 1 batch) at step 12600: 0.3150\n",
      "Seen so far: 403232 samples\n",
      "Training loss (for 1 batch) at step 12700: 0.1297\n",
      "Seen so far: 406432 samples\n",
      "Training loss (for 1 batch) at step 12800: 0.0072\n",
      "Seen so far: 409632 samples\n",
      "Training loss (for 1 batch) at step 12900: 0.0893\n",
      "Seen so far: 412832 samples\n",
      "Training loss (for 1 batch) at step 13000: 0.0042\n",
      "Seen so far: 416032 samples\n",
      "Training loss (for 1 batch) at step 13100: 0.2367\n",
      "Seen so far: 419232 samples\n",
      "Training loss (for 1 batch) at step 13200: 0.0588\n",
      "Seen so far: 422432 samples\n",
      "Training loss (for 1 batch) at step 13300: 0.4124\n",
      "Seen so far: 425632 samples\n",
      "Training loss (for 1 batch) at step 13400: 0.0895\n",
      "Seen so far: 428832 samples\n",
      "Training loss (for 1 batch) at step 13500: 0.1579\n",
      "Seen so far: 432032 samples\n",
      "Training loss (for 1 batch) at step 13600: 0.0031\n",
      "Seen so far: 435232 samples\n",
      "Training loss (for 1 batch) at step 13700: 0.0341\n",
      "Seen so far: 438432 samples\n",
      "Training loss (for 1 batch) at step 13800: 0.0109\n",
      "Seen so far: 441632 samples\n",
      "Training loss (for 1 batch) at step 13900: 0.1145\n",
      "Seen so far: 444832 samples\n",
      "Training loss (for 1 batch) at step 14000: 0.0756\n",
      "Seen so far: 448032 samples\n",
      "Training loss (for 1 batch) at step 14100: 0.0150\n",
      "Seen so far: 451232 samples\n",
      "Training loss (for 1 batch) at step 14200: 0.0885\n",
      "Seen so far: 454432 samples\n",
      "Training loss (for 1 batch) at step 14300: 0.1807\n",
      "Seen so far: 457632 samples\n",
      "Training loss (for 1 batch) at step 14400: 0.4342\n",
      "Seen so far: 460832 samples\n",
      "Training loss (for 1 batch) at step 14500: 0.0450\n",
      "Seen so far: 464032 samples\n",
      "Training loss (for 1 batch) at step 14600: 0.1922\n",
      "Seen so far: 467232 samples\n",
      "Training loss (for 1 batch) at step 14700: 0.1230\n",
      "Seen so far: 470432 samples\n",
      "Training loss (for 1 batch) at step 14800: 0.0158\n",
      "Seen so far: 473632 samples\n",
      "Training loss (for 1 batch) at step 14900: 0.1248\n",
      "Seen so far: 476832 samples\n",
      "Training loss (for 1 batch) at step 15000: 0.0726\n",
      "Seen so far: 480032 samples\n",
      "Training loss (for 1 batch) at step 15100: 0.1787\n",
      "Seen so far: 483232 samples\n",
      "Training loss (for 1 batch) at step 15200: 0.1606\n",
      "Seen so far: 486432 samples\n",
      "Training loss (for 1 batch) at step 15300: 0.3698\n",
      "Seen so far: 489632 samples\n",
      "Training loss (for 1 batch) at step 15400: 0.2055\n",
      "Seen so far: 492832 samples\n",
      "Training loss (for 1 batch) at step 15500: 0.0719\n",
      "Seen so far: 496032 samples\n",
      "Training loss (for 1 batch) at step 15600: 0.0113\n",
      "Seen so far: 499232 samples\n",
      "Training loss (for 1 batch) at step 15700: 0.0229\n",
      "Seen so far: 502432 samples\n",
      "Training loss (for 1 batch) at step 15800: 0.4932\n",
      "Seen so far: 505632 samples\n",
      "Training loss (for 1 batch) at step 15900: 0.0761\n",
      "Seen so far: 508832 samples\n",
      "Training loss (for 1 batch) at step 16000: 0.2847\n",
      "Seen so far: 512032 samples\n",
      "Training loss (for 1 batch) at step 16100: 0.2423\n",
      "Seen so far: 515232 samples\n",
      "Training loss (for 1 batch) at step 16200: 0.0473\n",
      "Seen so far: 518432 samples\n",
      "Training loss (for 1 batch) at step 16300: 0.0274\n",
      "Seen so far: 521632 samples\n",
      "Training loss (for 1 batch) at step 16400: 0.0088\n",
      "Seen so far: 524832 samples\n",
      "Training loss (for 1 batch) at step 16500: 0.0051\n",
      "Seen so far: 528032 samples\n",
      "Training loss (for 1 batch) at step 16600: 0.3374\n",
      "Seen so far: 531232 samples\n",
      "Training loss (for 1 batch) at step 16700: 0.2020\n",
      "Seen so far: 534432 samples\n",
      "Training loss (for 1 batch) at step 16800: 0.4106\n",
      "Seen so far: 537632 samples\n",
      "Training loss (for 1 batch) at step 16900: 0.1760\n",
      "Seen so far: 540832 samples\n",
      "Training loss (for 1 batch) at step 17000: 0.3099\n",
      "Seen so far: 544032 samples\n",
      "Training loss (for 1 batch) at step 17100: 0.1231\n",
      "Seen so far: 547232 samples\n",
      "Training loss (for 1 batch) at step 17200: 0.6806\n",
      "Seen so far: 550432 samples\n",
      "Training loss (for 1 batch) at step 17300: 0.1066\n",
      "Seen so far: 553632 samples\n",
      "Training loss (for 1 batch) at step 17400: 0.2490\n",
      "Seen so far: 556832 samples\n",
      "Training loss (for 1 batch) at step 17500: 0.0340\n",
      "Seen so far: 560032 samples\n",
      "Training loss (for 1 batch) at step 17600: 0.1649\n",
      "Seen so far: 563232 samples\n",
      "Training loss (for 1 batch) at step 17700: 0.0801\n",
      "Seen so far: 566432 samples\n",
      "Training loss (for 1 batch) at step 17800: 0.2534\n",
      "Seen so far: 569632 samples\n",
      "Training loss (for 1 batch) at step 17900: 0.0674\n",
      "Seen so far: 572832 samples\n",
      "Training loss (for 1 batch) at step 18000: 0.0923\n",
      "Seen so far: 576032 samples\n",
      "Training loss (for 1 batch) at step 18100: 0.0698\n",
      "Seen so far: 579232 samples\n",
      "Training loss (for 1 batch) at step 18200: 0.0045\n",
      "Seen so far: 582432 samples\n",
      "Training loss (for 1 batch) at step 18300: 0.0709\n",
      "Seen so far: 585632 samples\n",
      "Training loss (for 1 batch) at step 18400: 0.1690\n",
      "Seen so far: 588832 samples\n",
      "Training loss (for 1 batch) at step 18500: 0.4470\n",
      "Seen so far: 592032 samples\n",
      "Training loss (for 1 batch) at step 18600: 0.0914\n",
      "Seen so far: 595232 samples\n",
      "Training loss (for 1 batch) at step 18700: 0.0391\n",
      "Seen so far: 598432 samples\n",
      "Training loss (for 1 batch) at step 18800: 0.0869\n",
      "Seen so far: 601632 samples\n",
      "Training loss (for 1 batch) at step 18900: 0.0559\n",
      "Seen so far: 604832 samples\n",
      "Training loss (for 1 batch) at step 19000: 0.1597\n",
      "Seen so far: 608032 samples\n",
      "Training loss (for 1 batch) at step 19100: 0.0039\n",
      "Seen so far: 611232 samples\n",
      "Training loss (for 1 batch) at step 19200: 0.0048\n",
      "Seen so far: 614432 samples\n",
      "Training loss (for 1 batch) at step 19300: 0.0863\n",
      "Seen so far: 617632 samples\n",
      "Training loss (for 1 batch) at step 19400: 0.1250\n",
      "Seen so far: 620832 samples\n",
      "Training loss (for 1 batch) at step 19500: 0.0590\n",
      "Seen so far: 624032 samples\n",
      "Training loss (for 1 batch) at step 19600: 0.1279\n",
      "Seen so far: 627232 samples\n",
      "Training loss (for 1 batch) at step 19700: 0.0035\n",
      "Seen so far: 630432 samples\n",
      "Training loss (for 1 batch) at step 19800: 0.0003\n",
      "Seen so far: 633632 samples\n",
      "Training loss (for 1 batch) at step 19900: 0.3574\n",
      "Seen so far: 636832 samples\n",
      "Training loss (for 1 batch) at step 20000: 0.4073\n",
      "Seen so far: 640032 samples\n",
      "Training loss (for 1 batch) at step 20100: 0.0906\n",
      "Seen so far: 643232 samples\n",
      "Training loss (for 1 batch) at step 20200: 0.3192\n",
      "Seen so far: 646432 samples\n",
      "Training loss (for 1 batch) at step 20300: 0.1047\n",
      "Seen so far: 649632 samples\n",
      "Training loss (for 1 batch) at step 20400: 0.0021\n",
      "Seen so far: 652832 samples\n",
      "Training loss (for 1 batch) at step 20500: 0.0877\n",
      "Seen so far: 656032 samples\n",
      "Training loss (for 1 batch) at step 20600: 0.1970\n",
      "Seen so far: 659232 samples\n",
      "Training loss (for 1 batch) at step 20700: 0.0003\n",
      "Seen so far: 662432 samples\n",
      "Training loss (for 1 batch) at step 20800: 0.0451\n",
      "Seen so far: 665632 samples\n",
      "Training loss (for 1 batch) at step 20900: 0.0477\n",
      "Seen so far: 668832 samples\n",
      "Training loss (for 1 batch) at step 21000: 0.1439\n",
      "Seen so far: 672032 samples\n",
      "Training loss (for 1 batch) at step 21100: 0.0575\n",
      "Seen so far: 675232 samples\n",
      "Training loss (for 1 batch) at step 21200: 0.0348\n",
      "Seen so far: 678432 samples\n",
      "Training loss (for 1 batch) at step 21300: 0.0021\n",
      "Seen so far: 681632 samples\n",
      "Training loss (for 1 batch) at step 21400: 0.0010\n",
      "Seen so far: 684832 samples\n",
      "Training loss (for 1 batch) at step 21500: 0.0154\n",
      "Seen so far: 688032 samples\n",
      "Training loss (for 1 batch) at step 21600: 0.0542\n",
      "Seen so far: 691232 samples\n",
      "Training loss (for 1 batch) at step 21700: 0.1222\n",
      "Seen so far: 694432 samples\n",
      "Training loss (for 1 batch) at step 21800: 0.0029\n",
      "Seen so far: 697632 samples\n",
      "Training loss (for 1 batch) at step 21900: 0.0007\n",
      "Seen so far: 700832 samples\n",
      "Training loss (for 1 batch) at step 22000: 0.3708\n",
      "Seen so far: 704032 samples\n",
      "Training loss (for 1 batch) at step 22100: 0.3138\n",
      "Seen so far: 707232 samples\n",
      "Training loss (for 1 batch) at step 22200: 0.1294\n",
      "Seen so far: 710432 samples\n",
      "Training loss (for 1 batch) at step 22300: 0.1968\n",
      "Seen so far: 713632 samples\n",
      "Training loss (for 1 batch) at step 22400: 0.0085\n",
      "Seen so far: 716832 samples\n",
      "Training loss (for 1 batch) at step 22500: 0.0025\n",
      "Seen so far: 720032 samples\n",
      "Training loss (for 1 batch) at step 22600: 0.0359\n",
      "Seen so far: 723232 samples\n",
      "Training loss (for 1 batch) at step 22700: 0.0319\n",
      "Seen so far: 726432 samples\n",
      "Training loss (for 1 batch) at step 22800: 0.0103\n",
      "Seen so far: 729632 samples\n",
      "Training loss (for 1 batch) at step 22900: 0.0746\n",
      "Seen so far: 732832 samples\n",
      "Training loss (for 1 batch) at step 23000: 0.0114\n",
      "Seen so far: 736032 samples\n",
      "Training loss (for 1 batch) at step 23100: 0.1549\n",
      "Seen so far: 739232 samples\n",
      "Training loss (for 1 batch) at step 23200: 0.3159\n",
      "Seen so far: 742432 samples\n",
      "Training loss (for 1 batch) at step 23300: 0.0243\n",
      "Seen so far: 745632 samples\n",
      "Training loss (for 1 batch) at step 23400: 0.2544\n",
      "Seen so far: 748832 samples\n",
      "Training loss (for 1 batch) at step 23500: 0.0424\n",
      "Seen so far: 752032 samples\n",
      "Training loss (for 1 batch) at step 23600: 0.0034\n",
      "Seen so far: 755232 samples\n",
      "Training loss (for 1 batch) at step 23700: 0.0324\n",
      "Seen so far: 758432 samples\n",
      "Training loss (for 1 batch) at step 23800: 0.0357\n",
      "Seen so far: 761632 samples\n",
      "Training loss (for 1 batch) at step 23900: 0.2426\n",
      "Seen so far: 764832 samples\n",
      "Training loss (for 1 batch) at step 24000: 0.0045\n",
      "Seen so far: 768032 samples\n",
      "Training loss (for 1 batch) at step 24100: 0.0094\n",
      "Seen so far: 771232 samples\n",
      "Training loss (for 1 batch) at step 24200: 0.1515\n",
      "Seen so far: 774432 samples\n",
      "Training loss (for 1 batch) at step 24300: 0.0060\n",
      "Seen so far: 777632 samples\n",
      "Training loss (for 1 batch) at step 24400: 0.0726\n",
      "Seen so far: 780832 samples\n",
      "Training loss (for 1 batch) at step 24500: 0.0700\n",
      "Seen so far: 784032 samples\n",
      "Training loss (for 1 batch) at step 24600: 0.2706\n",
      "Seen so far: 787232 samples\n",
      "Training loss (for 1 batch) at step 24700: 0.0016\n",
      "Seen so far: 790432 samples\n",
      "Training loss (for 1 batch) at step 24800: 0.0319\n",
      "Seen so far: 793632 samples\n",
      "Training loss (for 1 batch) at step 24900: 0.0001\n",
      "Seen so far: 796832 samples\n",
      "Training loss (for 1 batch) at step 25000: 0.1122\n",
      "Seen so far: 800032 samples\n",
      "Training loss (for 1 batch) at step 25100: 0.0758\n",
      "Seen so far: 803232 samples\n",
      "Training loss (for 1 batch) at step 25200: 0.0471\n",
      "Seen so far: 806432 samples\n",
      "Training loss (for 1 batch) at step 25300: 0.0018\n",
      "Seen so far: 809632 samples\n",
      "Training loss (for 1 batch) at step 25400: 0.0071\n",
      "Seen so far: 812832 samples\n",
      "Training loss (for 1 batch) at step 25500: 0.0916\n",
      "Seen so far: 816032 samples\n",
      "Training loss (for 1 batch) at step 25600: 0.0045\n",
      "Seen so far: 819232 samples\n",
      "Training loss (for 1 batch) at step 25700: 0.0029\n",
      "Seen so far: 822432 samples\n",
      "Training loss (for 1 batch) at step 25800: 0.1366\n",
      "Seen so far: 825632 samples\n",
      "Training loss (for 1 batch) at step 25900: 0.0015\n",
      "Seen so far: 828832 samples\n",
      "Training loss (for 1 batch) at step 26000: 0.3059\n",
      "Seen so far: 832032 samples\n",
      "Training loss (for 1 batch) at step 26100: 0.1133\n",
      "Seen so far: 835232 samples\n",
      "Training loss (for 1 batch) at step 26200: 0.3796\n",
      "Seen so far: 838432 samples\n",
      "Training loss (for 1 batch) at step 26300: 0.0403\n",
      "Seen so far: 841632 samples\n",
      "Training loss (for 1 batch) at step 26400: 0.0431\n",
      "Seen so far: 844832 samples\n",
      "Training loss (for 1 batch) at step 26500: 0.1565\n",
      "Seen so far: 848032 samples\n",
      "Training loss (for 1 batch) at step 26600: 0.0014\n",
      "Seen so far: 851232 samples\n",
      "Training loss (for 1 batch) at step 26700: 0.0239\n",
      "Seen so far: 854432 samples\n",
      "Training loss (for 1 batch) at step 26800: 0.0715\n",
      "Seen so far: 857632 samples\n",
      "Training loss (for 1 batch) at step 26900: 0.0583\n",
      "Seen so far: 860832 samples\n",
      "Training loss (for 1 batch) at step 27000: 0.0042\n",
      "Seen so far: 864032 samples\n",
      "Training loss (for 1 batch) at step 27100: 0.2669\n",
      "Seen so far: 867232 samples\n",
      "Training loss (for 1 batch) at step 27200: 0.1052\n",
      "Seen so far: 870432 samples\n",
      "Training loss (for 1 batch) at step 27300: 0.0363\n",
      "Seen so far: 873632 samples\n",
      "Training loss (for 1 batch) at step 27400: 0.2918\n",
      "Seen so far: 876832 samples\n",
      "Training loss (for 1 batch) at step 27500: 0.0010\n",
      "Seen so far: 880032 samples\n",
      "Training loss (for 1 batch) at step 27600: 0.0473\n",
      "Seen so far: 883232 samples\n",
      "Training loss (for 1 batch) at step 27700: 0.0109\n",
      "Seen so far: 886432 samples\n",
      "Training loss (for 1 batch) at step 27800: 0.1707\n",
      "Seen so far: 889632 samples\n",
      "Training loss (for 1 batch) at step 27900: 0.0006\n",
      "Seen so far: 892832 samples\n",
      "Training loss (for 1 batch) at step 28000: 0.0243\n",
      "Seen so far: 896032 samples\n",
      "Training loss (for 1 batch) at step 28100: 0.3647\n",
      "Seen so far: 899232 samples\n",
      "Training loss (for 1 batch) at step 28200: 0.0005\n",
      "Seen so far: 902432 samples\n",
      "Training loss (for 1 batch) at step 28300: 0.0462\n",
      "Seen so far: 905632 samples\n",
      "Training loss (for 1 batch) at step 28400: 0.1995\n",
      "Seen so far: 908832 samples\n",
      "Training loss (for 1 batch) at step 28500: 0.1316\n",
      "Seen so far: 912032 samples\n",
      "Training loss (for 1 batch) at step 28600: 0.0362\n",
      "Seen so far: 915232 samples\n",
      "Training loss (for 1 batch) at step 28700: 0.2662\n",
      "Seen so far: 918432 samples\n",
      "Training loss (for 1 batch) at step 28800: 0.0004\n",
      "Seen so far: 921632 samples\n",
      "Training loss (for 1 batch) at step 28900: 0.0122\n",
      "Seen so far: 924832 samples\n",
      "Training loss (for 1 batch) at step 29000: 0.0731\n",
      "Seen so far: 928032 samples\n",
      "Training loss (for 1 batch) at step 29100: 0.1077\n",
      "Seen so far: 931232 samples\n",
      "Training loss (for 1 batch) at step 29200: 0.0432\n",
      "Seen so far: 934432 samples\n",
      "Training loss (for 1 batch) at step 29300: 0.3172\n",
      "Seen so far: 937632 samples\n",
      "Training loss (for 1 batch) at step 29400: 0.0750\n",
      "Seen so far: 940832 samples\n",
      "Training loss (for 1 batch) at step 29500: 0.0121\n",
      "Seen so far: 944032 samples\n",
      "Training loss (for 1 batch) at step 29600: 0.0782\n",
      "Seen so far: 947232 samples\n",
      "Training loss (for 1 batch) at step 29700: 0.0093\n",
      "Seen so far: 950432 samples\n",
      "Training loss (for 1 batch) at step 29800: 0.1859\n",
      "Seen so far: 953632 samples\n",
      "Training loss (for 1 batch) at step 29900: 0.0703\n",
      "Seen so far: 956832 samples\n",
      "Training loss (for 1 batch) at step 30000: 0.0474\n",
      "Seen so far: 960032 samples\n",
      "Training loss (for 1 batch) at step 30100: 0.3331\n",
      "Seen so far: 963232 samples\n",
      "Training loss (for 1 batch) at step 30200: 0.1363\n",
      "Seen so far: 966432 samples\n",
      "Training loss (for 1 batch) at step 30300: 0.0086\n",
      "Seen so far: 969632 samples\n",
      "Training loss (for 1 batch) at step 30400: 0.0043\n",
      "Seen so far: 972832 samples\n",
      "Training loss (for 1 batch) at step 30500: 0.0048\n",
      "Seen so far: 976032 samples\n",
      "Training loss (for 1 batch) at step 30600: 0.0250\n",
      "Seen so far: 979232 samples\n",
      "Training loss (for 1 batch) at step 30700: 0.2719\n",
      "Seen so far: 982432 samples\n",
      "Training loss (for 1 batch) at step 30800: 0.3020\n",
      "Seen so far: 985632 samples\n",
      "Training loss (for 1 batch) at step 30900: 0.0283\n",
      "Seen so far: 988832 samples\n",
      "Training loss (for 1 batch) at step 31000: 0.0015\n",
      "Seen so far: 992032 samples\n",
      "Training loss (for 1 batch) at step 31100: 0.7968\n",
      "Seen so far: 995232 samples\n",
      "Training loss (for 1 batch) at step 31200: 0.0017\n",
      "Seen so far: 998432 samples\n",
      "Training loss (for 1 batch) at step 31300: 0.0055\n",
      "Seen so far: 1001632 samples\n",
      "Training loss (for 1 batch) at step 31400: 0.3578\n",
      "Seen so far: 1004832 samples\n",
      "Training loss (for 1 batch) at step 31500: 0.2417\n",
      "Seen so far: 1008032 samples\n",
      "Training loss (for 1 batch) at step 31600: 0.0020\n",
      "Seen so far: 1011232 samples\n",
      "Training loss (for 1 batch) at step 31700: 0.0065\n",
      "Seen so far: 1014432 samples\n",
      "Training loss (for 1 batch) at step 31800: 0.0041\n",
      "Seen so far: 1017632 samples\n",
      "Training loss (for 1 batch) at step 31900: 0.3972\n",
      "Seen so far: 1020832 samples\n",
      "Training loss (for 1 batch) at step 32000: 0.0320\n",
      "Seen so far: 1024032 samples\n",
      "Training loss (for 1 batch) at step 32100: 0.0077\n",
      "Seen so far: 1027232 samples\n",
      "Training loss (for 1 batch) at step 32200: 0.0075\n",
      "Seen so far: 1030432 samples\n",
      "Training loss (for 1 batch) at step 32300: 0.0001\n",
      "Seen so far: 1033632 samples\n",
      "Training loss (for 1 batch) at step 32400: 0.0136\n",
      "Seen so far: 1036832 samples\n",
      "Training loss (for 1 batch) at step 32500: 0.0020\n",
      "Seen so far: 1040032 samples\n",
      "Training loss (for 1 batch) at step 32600: 0.0148\n",
      "Seen so far: 1043232 samples\n",
      "Training loss (for 1 batch) at step 32700: 0.1180\n",
      "Seen so far: 1046432 samples\n",
      "Training loss (for 1 batch) at step 32800: 0.0702\n",
      "Seen so far: 1049632 samples\n",
      "Training loss (for 1 batch) at step 32900: 0.0653\n",
      "Seen so far: 1052832 samples\n",
      "Training loss (for 1 batch) at step 33000: 0.0102\n",
      "Seen so far: 1056032 samples\n",
      "Training loss (for 1 batch) at step 33100: 0.0021\n",
      "Seen so far: 1059232 samples\n",
      "Training loss (for 1 batch) at step 33200: 0.0415\n",
      "Seen so far: 1062432 samples\n",
      "Training loss (for 1 batch) at step 33300: 0.0871\n",
      "Seen so far: 1065632 samples\n",
      "Training loss (for 1 batch) at step 33400: 0.0029\n",
      "Seen so far: 1068832 samples\n",
      "Training loss (for 1 batch) at step 33500: 0.0003\n",
      "Seen so far: 1072032 samples\n",
      "Training loss (for 1 batch) at step 33600: 0.0000\n",
      "Seen so far: 1075232 samples\n",
      "Training loss (for 1 batch) at step 33700: 0.1256\n",
      "Seen so far: 1078432 samples\n",
      "Training loss (for 1 batch) at step 33800: 0.1616\n",
      "Seen so far: 1081632 samples\n",
      "Training loss (for 1 batch) at step 33900: 0.1372\n",
      "Seen so far: 1084832 samples\n",
      "Training loss (for 1 batch) at step 34000: 0.1138\n",
      "Seen so far: 1088032 samples\n",
      "Training loss (for 1 batch) at step 34100: 0.0323\n",
      "Seen so far: 1091232 samples\n",
      "Training loss (for 1 batch) at step 34200: 0.0004\n",
      "Seen so far: 1094432 samples\n",
      "Training loss (for 1 batch) at step 34300: 0.3782\n",
      "Seen so far: 1097632 samples\n",
      "Training loss (for 1 batch) at step 34400: 0.0333\n",
      "Seen so far: 1100832 samples\n",
      "Training loss (for 1 batch) at step 34500: 0.0655\n",
      "Seen so far: 1104032 samples\n",
      "Training loss (for 1 batch) at step 34600: 0.0178\n",
      "Seen so far: 1107232 samples\n",
      "Training loss (for 1 batch) at step 34700: 0.0328\n",
      "Seen so far: 1110432 samples\n",
      "Training loss (for 1 batch) at step 34800: 0.0670\n",
      "Seen so far: 1113632 samples\n",
      "Training loss (for 1 batch) at step 34900: 0.3378\n",
      "Seen so far: 1116832 samples\n",
      "Training loss (for 1 batch) at step 35000: 0.0002\n",
      "Seen so far: 1120032 samples\n",
      "Training loss (for 1 batch) at step 35100: 0.0066\n",
      "Seen so far: 1123232 samples\n",
      "Training loss (for 1 batch) at step 35200: 0.0067\n",
      "Seen so far: 1126432 samples\n",
      "Training loss (for 1 batch) at step 35300: 0.0353\n",
      "Seen so far: 1129632 samples\n",
      "Training loss (for 1 batch) at step 35400: 0.0243\n",
      "Seen so far: 1132832 samples\n",
      "Training loss (for 1 batch) at step 35500: 0.1517\n",
      "Seen so far: 1136032 samples\n",
      "Training loss (for 1 batch) at step 35600: 0.1104\n",
      "Seen so far: 1139232 samples\n",
      "Training loss (for 1 batch) at step 35700: 0.0113\n",
      "Seen so far: 1142432 samples\n",
      "Training loss (for 1 batch) at step 35800: 0.0035\n",
      "Seen so far: 1145632 samples\n",
      "Training loss (for 1 batch) at step 35900: 0.0913\n",
      "Seen so far: 1148832 samples\n",
      "Training loss (for 1 batch) at step 36000: 0.0009\n",
      "Seen so far: 1152032 samples\n",
      "Training loss (for 1 batch) at step 36100: 0.0181\n",
      "Seen so far: 1155232 samples\n",
      "Training loss (for 1 batch) at step 36200: 0.0003\n",
      "Seen so far: 1158432 samples\n",
      "Training loss (for 1 batch) at step 36300: 0.0432\n",
      "Seen so far: 1161632 samples\n",
      "Training loss (for 1 batch) at step 36400: 0.0095\n",
      "Seen so far: 1164832 samples\n",
      "Training loss (for 1 batch) at step 36500: 0.0059\n",
      "Seen so far: 1168032 samples\n",
      "Training loss (for 1 batch) at step 36600: 0.0000\n",
      "Seen so far: 1171232 samples\n",
      "Training loss (for 1 batch) at step 36700: 0.0494\n",
      "Seen so far: 1174432 samples\n",
      "Training loss (for 1 batch) at step 36800: 0.0074\n",
      "Seen so far: 1177632 samples\n",
      "Training loss (for 1 batch) at step 36900: 0.4362\n",
      "Seen so far: 1180832 samples\n",
      "Training loss (for 1 batch) at step 37000: 0.0583\n",
      "Seen so far: 1184032 samples\n",
      "Training loss (for 1 batch) at step 37100: 0.6692\n",
      "Seen so far: 1187232 samples\n",
      "Training loss (for 1 batch) at step 37200: 0.0051\n",
      "Seen so far: 1190432 samples\n",
      "Training loss (for 1 batch) at step 37300: 0.0001\n",
      "Seen so far: 1193632 samples\n",
      "Training loss (for 1 batch) at step 37400: 0.0016\n",
      "Seen so far: 1196832 samples\n",
      "Training loss (for 1 batch) at step 37500: 0.0004\n",
      "Seen so far: 1200032 samples\n",
      "Training loss (for 1 batch) at step 37600: 0.0615\n",
      "Seen so far: 1203232 samples\n",
      "Training loss (for 1 batch) at step 37700: 0.1346\n",
      "Seen so far: 1206432 samples\n",
      "Training loss (for 1 batch) at step 37800: 0.0001\n",
      "Seen so far: 1209632 samples\n",
      "Training loss (for 1 batch) at step 37900: 0.0572\n",
      "Seen so far: 1212832 samples\n",
      "Training loss (for 1 batch) at step 38000: 0.0250\n",
      "Seen so far: 1216032 samples\n",
      "Training loss (for 1 batch) at step 38100: 0.0006\n",
      "Seen so far: 1219232 samples\n",
      "Training loss (for 1 batch) at step 38200: 0.0010\n",
      "Seen so far: 1222432 samples\n",
      "Training loss (for 1 batch) at step 38300: 0.0167\n",
      "Seen so far: 1225632 samples\n",
      "Training loss (for 1 batch) at step 38400: 0.7320\n",
      "Seen so far: 1228832 samples\n",
      "Training loss (for 1 batch) at step 38500: 0.0682\n",
      "Seen so far: 1232032 samples\n",
      "Training loss (for 1 batch) at step 38600: 0.0005\n",
      "Seen so far: 1235232 samples\n",
      "Training loss (for 1 batch) at step 38700: 0.0023\n",
      "Seen so far: 1238432 samples\n",
      "Training loss (for 1 batch) at step 38800: 0.0691\n",
      "Seen so far: 1241632 samples\n",
      "Training loss (for 1 batch) at step 38900: 0.0612\n",
      "Seen so far: 1244832 samples\n",
      "Training loss (for 1 batch) at step 39000: 0.2428\n",
      "Seen so far: 1248032 samples\n",
      "Training loss (for 1 batch) at step 39100: 0.1468\n",
      "Seen so far: 1251232 samples\n",
      "Training loss (for 1 batch) at step 39200: 0.1488\n",
      "Seen so far: 1254432 samples\n",
      "Training loss (for 1 batch) at step 39300: 0.2315\n",
      "Seen so far: 1257632 samples\n",
      "Training loss (for 1 batch) at step 39400: 0.0029\n",
      "Seen so far: 1260832 samples\n",
      "Training loss (for 1 batch) at step 39500: 0.0579\n",
      "Seen so far: 1264032 samples\n",
      "Training loss (for 1 batch) at step 39600: 0.0070\n",
      "Seen so far: 1267232 samples\n",
      "Training loss (for 1 batch) at step 39700: 0.0968\n",
      "Seen so far: 1270432 samples\n",
      "Training loss (for 1 batch) at step 39800: 0.0065\n",
      "Seen so far: 1273632 samples\n",
      "Training loss (for 1 batch) at step 39900: 0.0969\n",
      "Seen so far: 1276832 samples\n",
      "Training loss (for 1 batch) at step 40000: 0.0704\n",
      "Seen so far: 1280032 samples\n",
      "Training loss (for 1 batch) at step 40100: 0.0024\n",
      "Seen so far: 1283232 samples\n",
      "Training loss (for 1 batch) at step 40200: 0.0012\n",
      "Seen so far: 1286432 samples\n",
      "Training loss (for 1 batch) at step 40300: 0.0679\n",
      "Seen so far: 1289632 samples\n",
      "Training loss (for 1 batch) at step 40400: 0.1274\n",
      "Seen so far: 1292832 samples\n",
      "Training loss (for 1 batch) at step 40500: 0.0089\n",
      "Seen so far: 1296032 samples\n",
      "Training loss (for 1 batch) at step 40600: 0.0028\n",
      "Seen so far: 1299232 samples\n",
      "Training loss (for 1 batch) at step 40700: 0.0727\n",
      "Seen so far: 1302432 samples\n",
      "Training loss (for 1 batch) at step 40800: 0.0140\n",
      "Seen so far: 1305632 samples\n",
      "Training loss (for 1 batch) at step 40900: 0.0002\n",
      "Seen so far: 1308832 samples\n",
      "Training loss (for 1 batch) at step 41000: 0.0080\n",
      "Seen so far: 1312032 samples\n",
      "Training loss (for 1 batch) at step 41100: 0.0003\n",
      "Seen so far: 1315232 samples\n",
      "Training loss (for 1 batch) at step 41200: 0.0960\n",
      "Seen so far: 1318432 samples\n",
      "Training loss (for 1 batch) at step 41300: 0.0207\n",
      "Seen so far: 1321632 samples\n",
      "Training loss (for 1 batch) at step 41400: 0.1890\n",
      "Seen so far: 1324832 samples\n",
      "Training loss (for 1 batch) at step 41500: 0.0083\n",
      "Seen so far: 1328032 samples\n",
      "Training loss (for 1 batch) at step 41600: 0.1486\n",
      "Seen so far: 1331232 samples\n",
      "Training loss (for 1 batch) at step 41700: 0.1459\n",
      "Seen so far: 1334432 samples\n",
      "Training loss (for 1 batch) at step 41800: 0.2051\n",
      "Seen so far: 1337632 samples\n",
      "Training loss (for 1 batch) at step 41900: 0.0884\n",
      "Seen so far: 1340832 samples\n",
      "Training loss (for 1 batch) at step 42000: 0.0006\n",
      "Seen so far: 1344032 samples\n",
      "Training loss (for 1 batch) at step 42100: 0.0413\n",
      "Seen so far: 1347232 samples\n",
      "Training loss (for 1 batch) at step 42200: 0.0043\n",
      "Seen so far: 1350432 samples\n",
      "Training loss (for 1 batch) at step 42300: 0.1300\n",
      "Seen so far: 1353632 samples\n",
      "Training loss (for 1 batch) at step 42400: 0.0356\n",
      "Seen so far: 1356832 samples\n",
      "Training loss (for 1 batch) at step 42500: 0.0033\n",
      "Seen so far: 1360032 samples\n",
      "Training loss (for 1 batch) at step 42600: 0.1832\n",
      "Seen so far: 1363232 samples\n",
      "Training loss (for 1 batch) at step 42700: 0.0354\n",
      "Seen so far: 1366432 samples\n",
      "Training loss (for 1 batch) at step 42800: 0.0647\n",
      "Seen so far: 1369632 samples\n",
      "Training loss (for 1 batch) at step 42900: 0.0010\n",
      "Seen so far: 1372832 samples\n",
      "Training loss (for 1 batch) at step 43000: 0.5182\n",
      "Seen so far: 1376032 samples\n",
      "Training loss (for 1 batch) at step 43100: 0.0008\n",
      "Seen so far: 1379232 samples\n",
      "Training loss (for 1 batch) at step 43200: 0.0873\n",
      "Seen so far: 1382432 samples\n",
      "Training loss (for 1 batch) at step 43300: 0.0000\n",
      "Seen so far: 1385632 samples\n",
      "Training loss (for 1 batch) at step 43400: 0.1385\n",
      "Seen so far: 1388832 samples\n",
      "Training loss (for 1 batch) at step 43500: 0.0024\n",
      "Seen so far: 1392032 samples\n",
      "Training loss (for 1 batch) at step 43600: 0.0893\n",
      "Seen so far: 1395232 samples\n",
      "Training loss (for 1 batch) at step 43700: 0.1176\n",
      "Seen so far: 1398432 samples\n",
      "Training loss (for 1 batch) at step 43800: 0.0011\n",
      "Seen so far: 1401632 samples\n",
      "Training loss (for 1 batch) at step 43900: 0.0512\n",
      "Seen so far: 1404832 samples\n",
      "Training loss (for 1 batch) at step 44000: 0.0007\n",
      "Seen so far: 1408032 samples\n",
      "Training loss (for 1 batch) at step 44100: 0.0353\n",
      "Seen so far: 1411232 samples\n",
      "Training loss (for 1 batch) at step 44200: 0.1302\n",
      "Seen so far: 1414432 samples\n",
      "Training loss (for 1 batch) at step 44300: 0.0783\n",
      "Seen so far: 1417632 samples\n",
      "Training loss (for 1 batch) at step 44400: 0.1635\n",
      "Seen so far: 1420832 samples\n",
      "Training loss (for 1 batch) at step 44500: 0.0002\n",
      "Seen so far: 1424032 samples\n",
      "Training loss (for 1 batch) at step 44600: 0.1033\n",
      "Seen so far: 1427232 samples\n",
      "Training loss (for 1 batch) at step 44700: 0.0439\n",
      "Seen so far: 1430432 samples\n",
      "Training loss (for 1 batch) at step 44800: 0.0174\n",
      "Seen so far: 1433632 samples\n",
      "Training loss (for 1 batch) at step 44900: 0.0018\n",
      "Seen so far: 1436832 samples\n",
      "Training loss (for 1 batch) at step 45000: 0.0223\n",
      "Seen so far: 1440032 samples\n",
      "Training loss (for 1 batch) at step 45100: 0.0009\n",
      "Seen so far: 1443232 samples\n",
      "Training loss (for 1 batch) at step 45200: 0.0006\n",
      "Seen so far: 1446432 samples\n",
      "Training loss (for 1 batch) at step 45300: 0.0322\n",
      "Seen so far: 1449632 samples\n",
      "Training loss (for 1 batch) at step 45400: 0.0030\n",
      "Seen so far: 1452832 samples\n",
      "Training loss (for 1 batch) at step 45500: 0.0071\n",
      "Seen so far: 1456032 samples\n",
      "Training loss (for 1 batch) at step 45600: 0.0095\n",
      "Seen so far: 1459232 samples\n",
      "Training loss (for 1 batch) at step 45700: 0.0008\n",
      "Seen so far: 1462432 samples\n",
      "Training loss (for 1 batch) at step 45800: 0.0041\n",
      "Seen so far: 1465632 samples\n",
      "Training loss (for 1 batch) at step 45900: 0.0001\n",
      "Seen so far: 1468832 samples\n",
      "Training loss (for 1 batch) at step 46000: 0.0212\n",
      "Seen so far: 1472032 samples\n",
      "Training loss (for 1 batch) at step 46100: 0.0044\n",
      "Seen so far: 1475232 samples\n",
      "Training loss (for 1 batch) at step 46200: 0.0812\n",
      "Seen so far: 1478432 samples\n",
      "Training loss (for 1 batch) at step 46300: 0.0216\n",
      "Seen so far: 1481632 samples\n",
      "Training loss (for 1 batch) at step 46400: 0.0000\n",
      "Seen so far: 1484832 samples\n",
      "Training loss (for 1 batch) at step 46500: 0.0132\n",
      "Seen so far: 1488032 samples\n",
      "Training loss (for 1 batch) at step 46600: 0.0733\n",
      "Seen so far: 1491232 samples\n",
      "Training loss (for 1 batch) at step 46700: 0.0096\n",
      "Seen so far: 1494432 samples\n",
      "Training loss (for 1 batch) at step 46800: 0.0952\n",
      "Seen so far: 1497632 samples\n",
      "Training loss (for 1 batch) at step 46900: 0.0510\n",
      "Seen so far: 1500832 samples\n",
      "Training loss (for 1 batch) at step 47000: 0.0425\n",
      "Seen so far: 1504032 samples\n",
      "Training loss (for 1 batch) at step 47100: 0.0022\n",
      "Seen so far: 1507232 samples\n",
      "Training loss (for 1 batch) at step 47200: 0.0162\n",
      "Seen so far: 1510432 samples\n",
      "Training loss (for 1 batch) at step 47300: 0.2088\n",
      "Seen so far: 1513632 samples\n",
      "Training loss (for 1 batch) at step 47400: 0.0001\n",
      "Seen so far: 1516832 samples\n",
      "Training loss (for 1 batch) at step 47500: 0.0045\n",
      "Seen so far: 1520032 samples\n",
      "Training loss (for 1 batch) at step 47600: 0.0200\n",
      "Seen so far: 1523232 samples\n",
      "Training loss (for 1 batch) at step 47700: 0.2489\n",
      "Seen so far: 1526432 samples\n",
      "Training loss (for 1 batch) at step 47800: 0.0363\n",
      "Seen so far: 1529632 samples\n",
      "Training loss (for 1 batch) at step 47900: 0.0173\n",
      "Seen so far: 1532832 samples\n",
      "Training loss (for 1 batch) at step 48000: 0.0007\n",
      "Seen so far: 1536032 samples\n",
      "Training loss (for 1 batch) at step 48100: 0.0167\n",
      "Seen so far: 1539232 samples\n",
      "Training loss (for 1 batch) at step 48200: 0.0017\n",
      "Seen so far: 1542432 samples\n",
      "Training loss (for 1 batch) at step 48300: 0.0023\n",
      "Seen so far: 1545632 samples\n",
      "Training loss (for 1 batch) at step 48400: 0.1704\n",
      "Seen so far: 1548832 samples\n",
      "Training loss (for 1 batch) at step 48500: 0.0017\n",
      "Seen so far: 1552032 samples\n",
      "Training loss (for 1 batch) at step 48600: 0.0482\n",
      "Seen so far: 1555232 samples\n",
      "Training loss (for 1 batch) at step 48700: 0.0045\n",
      "Seen so far: 1558432 samples\n",
      "Training loss (for 1 batch) at step 48800: 0.0173\n",
      "Seen so far: 1561632 samples\n",
      "Training loss (for 1 batch) at step 48900: 0.1823\n",
      "Seen so far: 1564832 samples\n",
      "Training loss (for 1 batch) at step 49000: 0.0753\n",
      "Seen so far: 1568032 samples\n",
      "Training loss (for 1 batch) at step 49100: 0.0001\n",
      "Seen so far: 1571232 samples\n",
      "Training loss (for 1 batch) at step 49200: 0.0022\n",
      "Seen so far: 1574432 samples\n",
      "Training loss (for 1 batch) at step 49300: 0.0520\n",
      "Seen so far: 1577632 samples\n",
      "Training loss (for 1 batch) at step 49400: 0.1335\n",
      "Seen so far: 1580832 samples\n",
      "Training loss (for 1 batch) at step 49500: 0.0269\n",
      "Seen so far: 1584032 samples\n",
      "Training loss (for 1 batch) at step 49600: 0.0199\n",
      "Seen so far: 1587232 samples\n",
      "Training loss (for 1 batch) at step 49700: 0.0022\n",
      "Seen so far: 1590432 samples\n",
      "Training loss (for 1 batch) at step 49800: 0.0041\n",
      "Seen so far: 1593632 samples\n",
      "Training loss (for 1 batch) at step 49900: 0.1328\n",
      "Seen so far: 1596832 samples\n",
      "Training loss (for 1 batch) at step 50000: 0.1577\n",
      "Seen so far: 1600032 samples\n",
      "Training loss (for 1 batch) at step 50100: 0.0011\n",
      "Seen so far: 1603232 samples\n",
      "Training loss (for 1 batch) at step 50200: 0.0052\n",
      "Seen so far: 1606432 samples\n",
      "Training loss (for 1 batch) at step 50300: 0.0001\n",
      "Seen so far: 1609632 samples\n",
      "Training loss (for 1 batch) at step 50400: 0.2813\n",
      "Seen so far: 1612832 samples\n",
      "Training loss (for 1 batch) at step 50500: 0.0735\n",
      "Seen so far: 1616032 samples\n",
      "Training loss (for 1 batch) at step 50600: 0.0004\n",
      "Seen so far: 1619232 samples\n",
      "Training loss (for 1 batch) at step 50700: 0.0038\n",
      "Seen so far: 1622432 samples\n",
      "Training loss (for 1 batch) at step 50800: 0.0829\n",
      "Seen so far: 1625632 samples\n",
      "Training loss (for 1 batch) at step 50900: 0.0984\n",
      "Seen so far: 1628832 samples\n",
      "Training loss (for 1 batch) at step 51000: 0.0110\n",
      "Seen so far: 1632032 samples\n",
      "Training loss (for 1 batch) at step 51100: 0.0041\n",
      "Seen so far: 1635232 samples\n",
      "Training loss (for 1 batch) at step 51200: 0.1239\n",
      "Seen so far: 1638432 samples\n",
      "Training loss (for 1 batch) at step 51300: 0.0028\n",
      "Seen so far: 1641632 samples\n",
      "Training loss (for 1 batch) at step 51400: 0.0188\n",
      "Seen so far: 1644832 samples\n",
      "Training loss (for 1 batch) at step 51500: 0.1007\n",
      "Seen so far: 1648032 samples\n",
      "Training loss (for 1 batch) at step 51600: 0.2074\n",
      "Seen so far: 1651232 samples\n",
      "Training loss (for 1 batch) at step 51700: 0.0733\n",
      "Seen so far: 1654432 samples\n",
      "Training loss (for 1 batch) at step 51800: 0.1366\n",
      "Seen so far: 1657632 samples\n",
      "Training loss (for 1 batch) at step 51900: 0.0104\n",
      "Seen so far: 1660832 samples\n",
      "Training loss (for 1 batch) at step 52000: 0.0006\n",
      "Seen so far: 1664032 samples\n",
      "Training loss (for 1 batch) at step 52100: 0.0039\n",
      "Seen so far: 1667232 samples\n",
      "Training loss (for 1 batch) at step 52200: 0.0917\n",
      "Seen so far: 1670432 samples\n",
      "Training loss (for 1 batch) at step 52300: 0.0047\n",
      "Seen so far: 1673632 samples\n",
      "Training loss (for 1 batch) at step 52400: 0.1047\n",
      "Seen so far: 1676832 samples\n",
      "Training loss (for 1 batch) at step 52500: 0.0565\n",
      "Seen so far: 1680032 samples\n",
      "Training loss (for 1 batch) at step 52600: 0.1038\n",
      "Seen so far: 1683232 samples\n",
      "Training loss (for 1 batch) at step 52700: 0.0015\n",
      "Seen so far: 1686432 samples\n",
      "Training loss (for 1 batch) at step 52800: 0.0005\n",
      "Seen so far: 1689632 samples\n",
      "Training loss (for 1 batch) at step 52900: 0.0449\n",
      "Seen so far: 1692832 samples\n",
      "Training loss (for 1 batch) at step 53000: 0.0060\n",
      "Seen so far: 1696032 samples\n",
      "Training loss (for 1 batch) at step 53100: 0.1350\n",
      "Seen so far: 1699232 samples\n",
      "Training loss (for 1 batch) at step 53200: 0.0018\n",
      "Seen so far: 1702432 samples\n",
      "Training loss (for 1 batch) at step 53300: 0.0106\n",
      "Seen so far: 1705632 samples\n",
      "Training loss (for 1 batch) at step 53400: 0.0766\n",
      "Seen so far: 1708832 samples\n",
      "Training loss (for 1 batch) at step 53500: 0.1009\n",
      "Seen so far: 1712032 samples\n",
      "Training loss (for 1 batch) at step 53600: 0.0011\n",
      "Seen so far: 1715232 samples\n",
      "Training loss (for 1 batch) at step 53700: 0.0114\n",
      "Seen so far: 1718432 samples\n",
      "Training loss (for 1 batch) at step 53800: 0.3310\n",
      "Seen so far: 1721632 samples\n",
      "Training loss (for 1 batch) at step 53900: 0.0067\n",
      "Seen so far: 1724832 samples\n",
      "Training loss (for 1 batch) at step 54000: 0.0986\n",
      "Seen so far: 1728032 samples\n",
      "Training loss (for 1 batch) at step 54100: 0.0056\n",
      "Seen so far: 1731232 samples\n",
      "Training loss (for 1 batch) at step 54200: 0.1689\n",
      "Seen so far: 1734432 samples\n",
      "Training loss (for 1 batch) at step 54300: 0.0988\n",
      "Seen so far: 1737632 samples\n",
      "Training loss (for 1 batch) at step 54400: 0.0001\n",
      "Seen so far: 1740832 samples\n",
      "Training loss (for 1 batch) at step 54500: 0.0005\n",
      "Seen so far: 1744032 samples\n",
      "Training loss (for 1 batch) at step 54600: 0.0824\n",
      "Seen so far: 1747232 samples\n",
      "Training loss (for 1 batch) at step 54700: 0.0033\n",
      "Seen so far: 1750432 samples\n",
      "Training loss (for 1 batch) at step 54800: 0.0025\n",
      "Seen so far: 1753632 samples\n",
      "Training loss (for 1 batch) at step 54900: 0.0106\n",
      "Seen so far: 1756832 samples\n",
      "Training loss (for 1 batch) at step 55000: 0.0019\n",
      "Seen so far: 1760032 samples\n",
      "Training loss (for 1 batch) at step 55100: 0.3824\n",
      "Seen so far: 1763232 samples\n",
      "Training loss (for 1 batch) at step 55200: 0.0298\n",
      "Seen so far: 1766432 samples\n",
      "Training loss (for 1 batch) at step 55300: 0.2484\n",
      "Seen so far: 1769632 samples\n",
      "Training loss (for 1 batch) at step 55400: 0.0517\n",
      "Seen so far: 1772832 samples\n",
      "Training loss (for 1 batch) at step 55500: 0.1436\n",
      "Seen so far: 1776032 samples\n",
      "Training loss (for 1 batch) at step 55600: 0.1348\n",
      "Seen so far: 1779232 samples\n",
      "Training loss (for 1 batch) at step 55700: 0.0674\n",
      "Seen so far: 1782432 samples\n",
      "Training loss (for 1 batch) at step 55800: 0.3015\n",
      "Seen so far: 1785632 samples\n",
      "Training loss (for 1 batch) at step 55900: 0.0467\n",
      "Seen so far: 1788832 samples\n",
      "Training loss (for 1 batch) at step 56000: 0.0186\n",
      "Seen so far: 1792032 samples\n",
      "Training loss (for 1 batch) at step 56100: 0.0000\n",
      "Seen so far: 1795232 samples\n",
      "Training loss (for 1 batch) at step 56200: 0.0598\n",
      "Seen so far: 1798432 samples\n",
      "Training loss (for 1 batch) at step 56300: 0.0136\n",
      "Seen so far: 1801632 samples\n",
      "Training loss (for 1 batch) at step 56400: 0.0019\n",
      "Seen so far: 1804832 samples\n",
      "Training loss (for 1 batch) at step 56500: 0.0003\n",
      "Seen so far: 1808032 samples\n",
      "Training loss (for 1 batch) at step 56600: 0.3824\n",
      "Seen so far: 1811232 samples\n",
      "Training loss (for 1 batch) at step 56700: 0.0003\n",
      "Seen so far: 1814432 samples\n",
      "Training loss (for 1 batch) at step 56800: 0.0742\n",
      "Seen so far: 1817632 samples\n",
      "Training loss (for 1 batch) at step 56900: 0.0233\n",
      "Seen so far: 1820832 samples\n",
      "Training loss (for 1 batch) at step 57000: 0.0125\n",
      "Seen so far: 1824032 samples\n",
      "Training loss (for 1 batch) at step 57100: 0.1647\n",
      "Seen so far: 1827232 samples\n",
      "Training loss (for 1 batch) at step 57200: 0.0004\n",
      "Seen so far: 1830432 samples\n",
      "Training loss (for 1 batch) at step 57300: 0.2452\n",
      "Seen so far: 1833632 samples\n",
      "Training loss (for 1 batch) at step 57400: 0.0001\n",
      "Seen so far: 1836832 samples\n",
      "Training loss (for 1 batch) at step 57500: 0.0053\n",
      "Seen so far: 1840032 samples\n",
      "Training loss (for 1 batch) at step 57600: 0.0013\n",
      "Seen so far: 1843232 samples\n",
      "Training loss (for 1 batch) at step 57700: 0.0267\n",
      "Seen so far: 1846432 samples\n",
      "Training loss (for 1 batch) at step 57800: 0.0621\n",
      "Seen so far: 1849632 samples\n",
      "Training loss (for 1 batch) at step 57900: 0.1033\n",
      "Seen so far: 1852832 samples\n",
      "Training loss (for 1 batch) at step 58000: 0.0002\n",
      "Seen so far: 1856032 samples\n",
      "Training loss (for 1 batch) at step 58100: 0.0003\n",
      "Seen so far: 1859232 samples\n",
      "Training loss (for 1 batch) at step 58200: 0.0004\n",
      "Seen so far: 1862432 samples\n",
      "Training loss (for 1 batch) at step 58300: 0.0011\n",
      "Seen so far: 1865632 samples\n",
      "Training loss (for 1 batch) at step 58400: 0.1737\n",
      "Seen so far: 1868832 samples\n",
      "Training loss (for 1 batch) at step 58500: 0.6843\n",
      "Seen so far: 1872032 samples\n",
      "Training loss (for 1 batch) at step 58600: 0.0050\n",
      "Seen so far: 1875232 samples\n",
      "Training loss (for 1 batch) at step 58700: 0.2454\n",
      "Seen so far: 1878432 samples\n",
      "Training loss (for 1 batch) at step 58800: 0.0007\n",
      "Seen so far: 1881632 samples\n",
      "Training loss (for 1 batch) at step 58900: 0.0859\n",
      "Seen so far: 1884832 samples\n",
      "Training loss (for 1 batch) at step 59000: 0.0048\n",
      "Seen so far: 1888032 samples\n",
      "Training loss (for 1 batch) at step 59100: 0.0142\n",
      "Seen so far: 1891232 samples\n",
      "Training loss (for 1 batch) at step 59200: 0.0019\n",
      "Seen so far: 1894432 samples\n",
      "Training loss (for 1 batch) at step 59300: 0.0568\n",
      "Seen so far: 1897632 samples\n",
      "Training loss (for 1 batch) at step 59400: 0.0670\n",
      "Seen so far: 1900832 samples\n",
      "Training loss (for 1 batch) at step 59500: 0.0280\n",
      "Seen so far: 1904032 samples\n",
      "Training loss (for 1 batch) at step 59600: 0.0704\n",
      "Seen so far: 1907232 samples\n",
      "Training loss (for 1 batch) at step 59700: 0.0112\n",
      "Seen so far: 1910432 samples\n",
      "Training loss (for 1 batch) at step 59800: 0.0000\n",
      "Seen so far: 1913632 samples\n",
      "Training loss (for 1 batch) at step 59900: 0.0000\n",
      "Seen so far: 1916832 samples\n",
      "Training loss (for 1 batch) at step 60000: 0.0022\n",
      "Seen so far: 1920032 samples\n",
      "Training loss (for 1 batch) at step 60100: 0.0019\n",
      "Seen so far: 1923232 samples\n",
      "Training loss (for 1 batch) at step 60200: 0.2613\n",
      "Seen so far: 1926432 samples\n",
      "Training loss (for 1 batch) at step 60300: 0.0004\n",
      "Seen so far: 1929632 samples\n",
      "Training loss (for 1 batch) at step 60400: 0.0970\n",
      "Seen so far: 1932832 samples\n",
      "Training loss (for 1 batch) at step 60500: 0.0644\n",
      "Seen so far: 1936032 samples\n",
      "Training loss (for 1 batch) at step 60600: 0.0000\n",
      "Seen so far: 1939232 samples\n",
      "Training loss (for 1 batch) at step 60700: 0.0097\n",
      "Seen so far: 1942432 samples\n",
      "Training loss (for 1 batch) at step 60800: 0.0081\n",
      "Seen so far: 1945632 samples\n",
      "Training loss (for 1 batch) at step 60900: 0.0004\n",
      "Seen so far: 1948832 samples\n",
      "Training loss (for 1 batch) at step 61000: 0.0005\n",
      "Seen so far: 1952032 samples\n",
      "Training loss (for 1 batch) at step 61100: 0.1660\n",
      "Seen so far: 1955232 samples\n",
      "Training loss (for 1 batch) at step 61200: 0.2375\n",
      "Seen so far: 1958432 samples\n",
      "Training loss (for 1 batch) at step 61300: 0.0162\n",
      "Seen so far: 1961632 samples\n",
      "Training loss (for 1 batch) at step 61400: 0.0135\n",
      "Seen so far: 1964832 samples\n",
      "Training loss (for 1 batch) at step 61500: 0.0036\n",
      "Seen so far: 1968032 samples\n",
      "Training loss (for 1 batch) at step 61600: 0.2004\n",
      "Seen so far: 1971232 samples\n",
      "Training loss (for 1 batch) at step 61700: 0.0852\n",
      "Seen so far: 1974432 samples\n",
      "Training loss (for 1 batch) at step 61800: 0.0024\n",
      "Seen so far: 1977632 samples\n",
      "Training loss (for 1 batch) at step 61900: 0.0133\n",
      "Seen so far: 1980832 samples\n",
      "Training loss (for 1 batch) at step 62000: 0.0001\n",
      "Seen so far: 1984032 samples\n",
      "Training loss (for 1 batch) at step 62100: 0.0064\n",
      "Seen so far: 1987232 samples\n",
      "Training loss (for 1 batch) at step 62200: 0.0041\n",
      "Seen so far: 1990432 samples\n",
      "Training loss (for 1 batch) at step 62300: 0.2781\n",
      "Seen so far: 1993632 samples\n",
      "Training loss (for 1 batch) at step 62400: 0.0489\n",
      "Seen so far: 1996832 samples\n",
      "Training loss (for 1 batch) at step 62500: 0.0749\n",
      "Seen so far: 2000032 samples\n",
      "Training loss (for 1 batch) at step 62600: 0.0624\n",
      "Seen so far: 2003232 samples\n",
      "Training loss (for 1 batch) at step 62700: 0.0524\n",
      "Seen so far: 2006432 samples\n",
      "Training loss (for 1 batch) at step 62800: 0.0022\n",
      "Seen so far: 2009632 samples\n",
      "Training loss (for 1 batch) at step 62900: 0.1683\n",
      "Seen so far: 2012832 samples\n",
      "Training loss (for 1 batch) at step 63000: 0.0005\n",
      "Seen so far: 2016032 samples\n",
      "Training loss (for 1 batch) at step 63100: 0.0000\n",
      "Seen so far: 2019232 samples\n",
      "Training loss (for 1 batch) at step 63200: 0.3685\n",
      "Seen so far: 2022432 samples\n",
      "Training loss (for 1 batch) at step 63300: 0.0015\n",
      "Seen so far: 2025632 samples\n",
      "Training loss (for 1 batch) at step 63400: 0.1627\n",
      "Seen so far: 2028832 samples\n",
      "Training loss (for 1 batch) at step 63500: 0.0311\n",
      "Seen so far: 2032032 samples\n",
      "Training loss (for 1 batch) at step 63600: 0.0021\n",
      "Seen so far: 2035232 samples\n",
      "Training loss (for 1 batch) at step 63700: 0.0903\n",
      "Seen so far: 2038432 samples\n",
      "Training loss (for 1 batch) at step 63800: 0.0002\n",
      "Seen so far: 2041632 samples\n",
      "Training loss (for 1 batch) at step 63900: 0.0074\n",
      "Seen so far: 2044832 samples\n",
      "Training loss (for 1 batch) at step 64000: 0.0008\n",
      "Seen so far: 2048032 samples\n",
      "Training loss (for 1 batch) at step 64100: 0.1398\n",
      "Seen so far: 2051232 samples\n",
      "Training loss (for 1 batch) at step 64200: 0.0756\n",
      "Seen so far: 2054432 samples\n",
      "Training loss (for 1 batch) at step 64300: 0.0437\n",
      "Seen so far: 2057632 samples\n",
      "Training loss (for 1 batch) at step 64400: 0.0632\n",
      "Seen so far: 2060832 samples\n",
      "Training loss (for 1 batch) at step 64500: 0.0005\n",
      "Seen so far: 2064032 samples\n",
      "Training loss (for 1 batch) at step 64600: 0.0079\n",
      "Seen so far: 2067232 samples\n",
      "Training loss (for 1 batch) at step 64700: 0.0000\n",
      "Seen so far: 2070432 samples\n",
      "Training loss (for 1 batch) at step 64800: 0.3986\n",
      "Seen so far: 2073632 samples\n",
      "Training loss (for 1 batch) at step 64900: 0.0000\n",
      "Seen so far: 2076832 samples\n",
      "Training loss (for 1 batch) at step 65000: 0.0010\n",
      "Seen so far: 2080032 samples\n",
      "Training loss (for 1 batch) at step 65100: 0.0581\n",
      "Seen so far: 2083232 samples\n",
      "Training loss (for 1 batch) at step 65200: 0.0693\n",
      "Seen so far: 2086432 samples\n",
      "Training loss (for 1 batch) at step 65300: 0.0015\n",
      "Seen so far: 2089632 samples\n",
      "Training loss (for 1 batch) at step 65400: 0.0019\n",
      "Seen so far: 2092832 samples\n",
      "Training loss (for 1 batch) at step 65500: 0.0013\n",
      "Seen so far: 2096032 samples\n",
      "Training loss (for 1 batch) at step 65600: 0.0101\n",
      "Seen so far: 2099232 samples\n",
      "Training loss (for 1 batch) at step 65700: 0.0001\n",
      "Seen so far: 2102432 samples\n",
      "Training loss (for 1 batch) at step 65800: 0.4250\n",
      "Seen so far: 2105632 samples\n",
      "Training loss (for 1 batch) at step 65900: 0.0016\n",
      "Seen so far: 2108832 samples\n",
      "Training loss (for 1 batch) at step 66000: 0.0963\n",
      "Seen so far: 2112032 samples\n",
      "Training loss (for 1 batch) at step 66100: 0.0014\n",
      "Seen so far: 2115232 samples\n",
      "Training loss (for 1 batch) at step 66200: 0.0298\n",
      "Seen so far: 2118432 samples\n",
      "Training loss (for 1 batch) at step 66300: 0.0612\n",
      "Seen so far: 2121632 samples\n",
      "Training loss (for 1 batch) at step 66400: 0.0023\n",
      "Seen so far: 2124832 samples\n",
      "Training loss (for 1 batch) at step 66500: 0.0039\n",
      "Seen so far: 2128032 samples\n",
      "Training loss (for 1 batch) at step 66600: 0.0498\n",
      "Seen so far: 2131232 samples\n",
      "Training loss (for 1 batch) at step 66700: 0.0000\n",
      "Seen so far: 2134432 samples\n",
      "Training loss (for 1 batch) at step 66800: 0.0003\n",
      "Seen so far: 2137632 samples\n",
      "Training loss (for 1 batch) at step 66900: 0.0006\n",
      "Seen so far: 2140832 samples\n",
      "Training loss (for 1 batch) at step 67000: 0.0332\n",
      "Seen so far: 2144032 samples\n",
      "Training loss (for 1 batch) at step 67100: 0.4421\n",
      "Seen so far: 2147232 samples\n",
      "Training loss (for 1 batch) at step 67200: 0.0174\n",
      "Seen so far: 2150432 samples\n",
      "Training loss (for 1 batch) at step 67300: 0.0044\n",
      "Seen so far: 2153632 samples\n",
      "Training loss (for 1 batch) at step 67400: 0.0002\n",
      "Seen so far: 2156832 samples\n",
      "Training loss (for 1 batch) at step 67500: 0.3871\n",
      "Seen so far: 2160032 samples\n",
      "Training loss (for 1 batch) at step 67600: 0.0316\n",
      "Seen so far: 2163232 samples\n",
      "Training loss (for 1 batch) at step 67700: 0.0146\n",
      "Seen so far: 2166432 samples\n",
      "Training loss (for 1 batch) at step 67800: 0.0863\n",
      "Seen so far: 2169632 samples\n",
      "Training loss (for 1 batch) at step 67900: 0.0008\n",
      "Seen so far: 2172832 samples\n",
      "Training loss (for 1 batch) at step 68000: 0.3838\n",
      "Seen so far: 2176032 samples\n",
      "Training loss (for 1 batch) at step 68100: 0.0005\n",
      "Seen so far: 2179232 samples\n",
      "Training loss (for 1 batch) at step 68200: 0.0048\n",
      "Seen so far: 2182432 samples\n",
      "Training loss (for 1 batch) at step 68300: 0.1131\n",
      "Seen so far: 2185632 samples\n",
      "Training loss (for 1 batch) at step 68400: 0.0038\n",
      "Seen so far: 2188832 samples\n",
      "Training loss (for 1 batch) at step 68500: 0.0007\n",
      "Seen so far: 2192032 samples\n",
      "Training loss (for 1 batch) at step 68600: 0.0062\n",
      "Seen so far: 2195232 samples\n",
      "Training loss (for 1 batch) at step 68700: 0.0994\n",
      "Seen so far: 2198432 samples\n",
      "Training loss (for 1 batch) at step 68800: 0.0066\n",
      "Seen so far: 2201632 samples\n",
      "Training loss (for 1 batch) at step 68900: 0.0018\n",
      "Seen so far: 2204832 samples\n",
      "Training loss (for 1 batch) at step 69000: 0.0002\n",
      "Seen so far: 2208032 samples\n",
      "Training loss (for 1 batch) at step 69100: 0.0006\n",
      "Seen so far: 2211232 samples\n",
      "Training loss (for 1 batch) at step 69200: 0.0149\n",
      "Seen so far: 2214432 samples\n",
      "Training loss (for 1 batch) at step 69300: 0.0006\n",
      "Seen so far: 2217632 samples\n",
      "Training loss (for 1 batch) at step 69400: 0.1316\n",
      "Seen so far: 2220832 samples\n",
      "Training loss (for 1 batch) at step 69500: 0.0308\n",
      "Seen so far: 2224032 samples\n",
      "Training loss (for 1 batch) at step 69600: 0.0018\n",
      "Seen so far: 2227232 samples\n",
      "Training loss (for 1 batch) at step 69700: 0.0019\n",
      "Seen so far: 2230432 samples\n",
      "Training loss (for 1 batch) at step 69800: 0.0661\n",
      "Seen so far: 2233632 samples\n",
      "Training loss (for 1 batch) at step 69900: 0.0343\n",
      "Seen so far: 2236832 samples\n",
      "Training loss (for 1 batch) at step 70000: 0.0023\n",
      "Seen so far: 2240032 samples\n",
      "Training loss (for 1 batch) at step 70100: 0.1580\n",
      "Seen so far: 2243232 samples\n",
      "Training loss (for 1 batch) at step 70200: 0.0067\n",
      "Seen so far: 2246432 samples\n",
      "Training loss (for 1 batch) at step 70300: 0.0128\n",
      "Seen so far: 2249632 samples\n",
      "Training loss (for 1 batch) at step 70400: 0.0119\n",
      "Seen so far: 2252832 samples\n",
      "Training loss (for 1 batch) at step 70500: 0.0004\n",
      "Seen so far: 2256032 samples\n",
      "Training loss (for 1 batch) at step 70600: 0.0627\n",
      "Seen so far: 2259232 samples\n",
      "Training loss (for 1 batch) at step 70700: 0.0010\n",
      "Seen so far: 2262432 samples\n",
      "Training loss (for 1 batch) at step 70800: 0.0007\n",
      "Seen so far: 2265632 samples\n",
      "Training loss (for 1 batch) at step 70900: 0.0057\n",
      "Seen so far: 2268832 samples\n",
      "Training loss (for 1 batch) at step 71000: 0.2878\n",
      "Seen so far: 2272032 samples\n",
      "Training loss (for 1 batch) at step 71100: 0.0006\n",
      "Seen so far: 2275232 samples\n",
      "Training loss (for 1 batch) at step 71200: 0.0009\n",
      "Seen so far: 2278432 samples\n",
      "Training loss (for 1 batch) at step 71300: 0.1766\n",
      "Seen so far: 2281632 samples\n",
      "Training loss (for 1 batch) at step 71400: 0.0085\n",
      "Seen so far: 2284832 samples\n",
      "Training loss (for 1 batch) at step 71500: 0.0002\n",
      "Seen so far: 2288032 samples\n",
      "Training loss (for 1 batch) at step 71600: 0.1844\n",
      "Seen so far: 2291232 samples\n",
      "Training loss (for 1 batch) at step 71700: 0.0001\n",
      "Seen so far: 2294432 samples\n",
      "Training loss (for 1 batch) at step 71800: 0.0175\n",
      "Seen so far: 2297632 samples\n",
      "Training loss (for 1 batch) at step 71900: 0.1223\n",
      "Seen so far: 2300832 samples\n",
      "Training loss (for 1 batch) at step 72000: 0.1081\n",
      "Seen so far: 2304032 samples\n",
      "Training loss (for 1 batch) at step 72100: 0.1352\n",
      "Seen so far: 2307232 samples\n",
      "Training loss (for 1 batch) at step 72200: 0.0002\n",
      "Seen so far: 2310432 samples\n",
      "Training loss (for 1 batch) at step 72300: 0.0003\n",
      "Seen so far: 2313632 samples\n",
      "Training loss (for 1 batch) at step 72400: 0.0017\n",
      "Seen so far: 2316832 samples\n",
      "Training loss (for 1 batch) at step 72500: 0.0065\n",
      "Seen so far: 2320032 samples\n",
      "Training loss (for 1 batch) at step 72600: 0.0766\n",
      "Seen so far: 2323232 samples\n",
      "Training loss (for 1 batch) at step 72700: 0.0000\n",
      "Seen so far: 2326432 samples\n",
      "Training loss (for 1 batch) at step 72800: 0.0470\n",
      "Seen so far: 2329632 samples\n",
      "Training loss (for 1 batch) at step 72900: 0.0501\n",
      "Seen so far: 2332832 samples\n",
      "Training loss (for 1 batch) at step 73000: 0.0832\n",
      "Seen so far: 2336032 samples\n",
      "Training loss (for 1 batch) at step 73100: 0.0017\n",
      "Seen so far: 2339232 samples\n",
      "Training loss (for 1 batch) at step 73200: 0.0002\n",
      "Seen so far: 2342432 samples\n",
      "Training loss (for 1 batch) at step 73300: 0.0261\n",
      "Seen so far: 2345632 samples\n",
      "Training loss (for 1 batch) at step 73400: 0.0007\n",
      "Seen so far: 2348832 samples\n",
      "Training loss (for 1 batch) at step 73500: 0.0162\n",
      "Seen so far: 2352032 samples\n",
      "Training loss (for 1 batch) at step 73600: 0.0069\n",
      "Seen so far: 2355232 samples\n",
      "Training loss (for 1 batch) at step 73700: 0.1041\n",
      "Seen so far: 2358432 samples\n",
      "Training loss (for 1 batch) at step 73800: 0.0096\n",
      "Seen so far: 2361632 samples\n",
      "Training loss (for 1 batch) at step 73900: 0.0039\n",
      "Seen so far: 2364832 samples\n",
      "Training loss (for 1 batch) at step 74000: 0.0455\n",
      "Seen so far: 2368032 samples\n",
      "Training loss (for 1 batch) at step 74100: 0.1335\n",
      "Seen so far: 2371232 samples\n",
      "Training loss (for 1 batch) at step 74200: 0.0002\n",
      "Seen so far: 2374432 samples\n",
      "Training loss (for 1 batch) at step 74300: 0.0000\n",
      "Seen so far: 2377632 samples\n",
      "Training loss (for 1 batch) at step 74400: 0.1795\n",
      "Seen so far: 2380832 samples\n",
      "Training loss (for 1 batch) at step 74500: 0.0513\n",
      "Seen so far: 2384032 samples\n",
      "Training loss (for 1 batch) at step 74600: 0.0050\n",
      "Seen so far: 2387232 samples\n",
      "Training loss (for 1 batch) at step 74700: 0.0108\n",
      "Seen so far: 2390432 samples\n",
      "Training loss (for 1 batch) at step 74800: 0.0765\n",
      "Seen so far: 2393632 samples\n",
      "Training loss (for 1 batch) at step 74900: 0.0011\n",
      "Seen so far: 2396832 samples\n",
      "Training loss (for 1 batch) at step 75000: 0.0001\n",
      "Seen so far: 2400032 samples\n",
      "Training loss (for 1 batch) at step 75100: 0.0004\n",
      "Seen so far: 2403232 samples\n",
      "Training loss (for 1 batch) at step 75200: 0.6932\n",
      "Seen so far: 2406432 samples\n",
      "Training loss (for 1 batch) at step 75300: 0.0002\n",
      "Seen so far: 2409632 samples\n",
      "Training loss (for 1 batch) at step 75400: 0.0626\n",
      "Seen so far: 2412832 samples\n",
      "Training loss (for 1 batch) at step 75500: 0.4138\n",
      "Seen so far: 2416032 samples\n",
      "Training loss (for 1 batch) at step 75600: 0.0298\n",
      "Seen so far: 2419232 samples\n",
      "Training loss (for 1 batch) at step 75700: 0.0000\n",
      "Seen so far: 2422432 samples\n",
      "Training loss (for 1 batch) at step 75800: 0.0110\n",
      "Seen so far: 2425632 samples\n",
      "Training loss (for 1 batch) at step 75900: 0.0000\n",
      "Seen so far: 2428832 samples\n",
      "Training loss (for 1 batch) at step 76000: 0.0063\n",
      "Seen so far: 2432032 samples\n",
      "Training loss (for 1 batch) at step 76100: 0.0023\n",
      "Seen so far: 2435232 samples\n",
      "Training loss (for 1 batch) at step 76200: 0.0011\n",
      "Seen so far: 2438432 samples\n",
      "Training loss (for 1 batch) at step 76300: 0.4235\n",
      "Seen so far: 2441632 samples\n",
      "Training loss (for 1 batch) at step 76400: 0.0144\n",
      "Seen so far: 2444832 samples\n",
      "Training loss (for 1 batch) at step 76500: 0.0869\n",
      "Seen so far: 2448032 samples\n",
      "Training loss (for 1 batch) at step 76600: 0.1362\n",
      "Seen so far: 2451232 samples\n",
      "Training loss (for 1 batch) at step 76700: 0.0045\n",
      "Seen so far: 2454432 samples\n",
      "Training loss (for 1 batch) at step 76800: 0.2050\n",
      "Seen so far: 2457632 samples\n",
      "Training loss (for 1 batch) at step 76900: 0.0010\n",
      "Seen so far: 2460832 samples\n",
      "Training loss (for 1 batch) at step 77000: 0.0001\n",
      "Seen so far: 2464032 samples\n",
      "Training loss (for 1 batch) at step 77100: 0.0011\n",
      "Seen so far: 2467232 samples\n",
      "Training loss (for 1 batch) at step 77200: 0.1556\n",
      "Seen so far: 2470432 samples\n",
      "Training loss (for 1 batch) at step 77300: 0.0002\n",
      "Seen so far: 2473632 samples\n",
      "Training loss (for 1 batch) at step 77400: 0.3079\n",
      "Seen so far: 2476832 samples\n",
      "Training loss (for 1 batch) at step 77500: 0.0000\n",
      "Seen so far: 2480032 samples\n",
      "Training loss (for 1 batch) at step 77600: 0.0002\n",
      "Seen so far: 2483232 samples\n",
      "Training loss (for 1 batch) at step 77700: 0.0001\n",
      "Seen so far: 2486432 samples\n",
      "Training loss (for 1 batch) at step 77800: 0.2854\n",
      "Seen so far: 2489632 samples\n",
      "Training loss (for 1 batch) at step 77900: 0.0018\n",
      "Seen so far: 2492832 samples\n",
      "Training loss (for 1 batch) at step 78000: 0.0009\n",
      "Seen so far: 2496032 samples\n",
      "Training loss (for 1 batch) at step 78100: 0.3952\n",
      "Seen so far: 2499232 samples\n",
      "Training loss (for 1 batch) at step 78200: 0.2819\n",
      "Seen so far: 2502432 samples\n",
      "Training loss (for 1 batch) at step 78300: 0.0013\n",
      "Seen so far: 2505632 samples\n",
      "Training loss (for 1 batch) at step 78400: 0.1327\n",
      "Seen so far: 2508832 samples\n",
      "Training loss (for 1 batch) at step 78500: 0.0133\n",
      "Seen so far: 2512032 samples\n",
      "Training loss (for 1 batch) at step 78600: 0.0001\n",
      "Seen so far: 2515232 samples\n",
      "Training loss (for 1 batch) at step 78700: 0.0602\n",
      "Seen so far: 2518432 samples\n",
      "Training loss (for 1 batch) at step 78800: 0.1079\n",
      "Seen so far: 2521632 samples\n",
      "Training loss (for 1 batch) at step 78900: 0.0002\n",
      "Seen so far: 2524832 samples\n",
      "Training loss (for 1 batch) at step 79000: 0.0000\n",
      "Seen so far: 2528032 samples\n",
      "Training loss (for 1 batch) at step 79100: 0.0004\n",
      "Seen so far: 2531232 samples\n",
      "Training loss (for 1 batch) at step 79200: 0.0002\n",
      "Seen so far: 2534432 samples\n",
      "Training loss (for 1 batch) at step 79300: 0.0344\n",
      "Seen so far: 2537632 samples\n",
      "Training loss (for 1 batch) at step 79400: 0.0000\n",
      "Seen so far: 2540832 samples\n",
      "Training loss (for 1 batch) at step 79500: 0.2263\n",
      "Seen so far: 2544032 samples\n",
      "Training loss (for 1 batch) at step 79600: 0.0001\n",
      "Seen so far: 2547232 samples\n",
      "Training loss (for 1 batch) at step 79700: 0.5481\n",
      "Seen so far: 2550432 samples\n",
      "Training loss (for 1 batch) at step 79800: 0.0830\n",
      "Seen so far: 2553632 samples\n",
      "Training loss (for 1 batch) at step 79900: 0.0001\n",
      "Seen so far: 2556832 samples\n",
      "Training loss (for 1 batch) at step 80000: 0.0001\n",
      "Seen so far: 2560032 samples\n",
      "Training loss (for 1 batch) at step 80100: 0.0042\n",
      "Seen so far: 2563232 samples\n",
      "Training loss (for 1 batch) at step 80200: 0.1490\n",
      "Seen so far: 2566432 samples\n",
      "Training loss (for 1 batch) at step 80300: 0.0001\n",
      "Seen so far: 2569632 samples\n",
      "Training loss (for 1 batch) at step 80400: 0.0012\n",
      "Seen so far: 2572832 samples\n",
      "Training loss (for 1 batch) at step 80500: 0.1094\n",
      "Seen so far: 2576032 samples\n",
      "Training loss (for 1 batch) at step 80600: 0.0539\n",
      "Seen so far: 2579232 samples\n",
      "Training loss (for 1 batch) at step 80700: 0.0004\n",
      "Seen so far: 2582432 samples\n",
      "Training loss (for 1 batch) at step 80800: 0.0000\n",
      "Seen so far: 2585632 samples\n",
      "Training loss (for 1 batch) at step 80900: 0.0473\n",
      "Seen so far: 2588832 samples\n",
      "Training loss (for 1 batch) at step 81000: 0.0009\n",
      "Seen so far: 2592032 samples\n",
      "Training loss (for 1 batch) at step 81100: 0.1191\n",
      "Seen so far: 2595232 samples\n",
      "Training loss (for 1 batch) at step 81200: 0.0138\n",
      "Seen so far: 2598432 samples\n",
      "Training loss (for 1 batch) at step 81300: 0.0014\n",
      "Seen so far: 2601632 samples\n",
      "Training loss (for 1 batch) at step 81400: 0.0395\n",
      "Seen so far: 2604832 samples\n",
      "Training loss (for 1 batch) at step 81500: 0.0002\n",
      "Seen so far: 2608032 samples\n",
      "Training loss (for 1 batch) at step 81600: 0.0000\n",
      "Seen so far: 2611232 samples\n",
      "Training loss (for 1 batch) at step 81700: 0.0000\n",
      "Seen so far: 2614432 samples\n",
      "Training loss (for 1 batch) at step 81800: 0.0135\n",
      "Seen so far: 2617632 samples\n",
      "Training loss (for 1 batch) at step 81900: 0.0091\n",
      "Seen so far: 2620832 samples\n",
      "Training loss (for 1 batch) at step 82000: 0.0570\n",
      "Seen so far: 2624032 samples\n",
      "Training loss (for 1 batch) at step 82100: 0.0045\n",
      "Seen so far: 2627232 samples\n",
      "Training loss (for 1 batch) at step 82200: 0.1221\n",
      "Seen so far: 2630432 samples\n",
      "Training loss (for 1 batch) at step 82300: 0.0000\n",
      "Seen so far: 2633632 samples\n",
      "Training loss (for 1 batch) at step 82400: 0.0009\n",
      "Seen so far: 2636832 samples\n",
      "Training loss (for 1 batch) at step 82500: 0.0688\n",
      "Seen so far: 2640032 samples\n",
      "Training loss (for 1 batch) at step 82600: 0.0000\n",
      "Seen so far: 2643232 samples\n",
      "Training loss (for 1 batch) at step 82700: 0.0018\n",
      "Seen so far: 2646432 samples\n",
      "Training loss (for 1 batch) at step 82800: 0.1472\n",
      "Seen so far: 2649632 samples\n",
      "Training loss (for 1 batch) at step 82900: 0.0221\n",
      "Seen so far: 2652832 samples\n",
      "Training loss (for 1 batch) at step 83000: 0.0000\n",
      "Seen so far: 2656032 samples\n",
      "Training loss (for 1 batch) at step 83100: 0.0003\n",
      "Seen so far: 2659232 samples\n",
      "Training loss (for 1 batch) at step 83200: 0.0000\n",
      "Seen so far: 2662432 samples\n",
      "Training loss (for 1 batch) at step 83300: 0.0016\n",
      "Seen so far: 2665632 samples\n",
      "Training loss (for 1 batch) at step 83400: 0.0003\n",
      "Seen so far: 2668832 samples\n",
      "Training loss (for 1 batch) at step 83500: 0.0112\n",
      "Seen so far: 2672032 samples\n",
      "Training loss (for 1 batch) at step 83600: 0.0001\n",
      "Seen so far: 2675232 samples\n",
      "Training loss (for 1 batch) at step 83700: 0.0196\n",
      "Seen so far: 2678432 samples\n",
      "Training loss (for 1 batch) at step 83800: 0.1887\n",
      "Seen so far: 2681632 samples\n",
      "Training loss (for 1 batch) at step 83900: 0.6657\n",
      "Seen so far: 2684832 samples\n",
      "Training loss (for 1 batch) at step 84000: 0.0760\n",
      "Seen so far: 2688032 samples\n",
      "Training loss (for 1 batch) at step 84100: 0.0495\n",
      "Seen so far: 2691232 samples\n",
      "Training loss (for 1 batch) at step 84200: 0.0014\n",
      "Seen so far: 2694432 samples\n",
      "Training loss (for 1 batch) at step 84300: 0.0003\n",
      "Seen so far: 2697632 samples\n",
      "Training loss (for 1 batch) at step 84400: 0.0002\n",
      "Seen so far: 2700832 samples\n",
      "Training loss (for 1 batch) at step 84500: 0.0408\n",
      "Seen so far: 2704032 samples\n",
      "Training loss (for 1 batch) at step 84600: 0.0065\n",
      "Seen so far: 2707232 samples\n",
      "Training loss (for 1 batch) at step 84700: 0.0275\n",
      "Seen so far: 2710432 samples\n",
      "Training loss (for 1 batch) at step 84800: 0.0001\n",
      "Seen so far: 2713632 samples\n",
      "Training loss (for 1 batch) at step 84900: 0.0004\n",
      "Seen so far: 2716832 samples\n",
      "Training loss (for 1 batch) at step 85000: 0.0000\n",
      "Seen so far: 2720032 samples\n",
      "Training loss (for 1 batch) at step 85100: 0.0130\n",
      "Seen so far: 2723232 samples\n",
      "Training loss (for 1 batch) at step 85200: 0.1218\n",
      "Seen so far: 2726432 samples\n",
      "Training loss (for 1 batch) at step 85300: 0.0009\n",
      "Seen so far: 2729632 samples\n",
      "Training loss (for 1 batch) at step 85400: 0.0777\n",
      "Seen so far: 2732832 samples\n",
      "Training loss (for 1 batch) at step 85500: 0.0016\n",
      "Seen so far: 2736032 samples\n",
      "Training loss (for 1 batch) at step 85600: 0.0165\n",
      "Seen so far: 2739232 samples\n",
      "Training loss (for 1 batch) at step 85700: 0.0114\n",
      "Seen so far: 2742432 samples\n",
      "Training loss (for 1 batch) at step 85800: 0.0001\n",
      "Seen so far: 2745632 samples\n",
      "Training loss (for 1 batch) at step 85900: 0.1508\n",
      "Seen so far: 2748832 samples\n",
      "Training loss (for 1 batch) at step 86000: 0.0175\n",
      "Seen so far: 2752032 samples\n",
      "Training loss (for 1 batch) at step 86100: 0.0826\n",
      "Seen so far: 2755232 samples\n",
      "Training loss (for 1 batch) at step 86200: 0.0001\n",
      "Seen so far: 2758432 samples\n",
      "Training loss (for 1 batch) at step 86300: 0.0004\n",
      "Seen so far: 2761632 samples\n",
      "Training loss (for 1 batch) at step 86400: 0.0073\n",
      "Seen so far: 2764832 samples\n",
      "Training loss (for 1 batch) at step 86500: 0.0171\n",
      "Seen so far: 2768032 samples\n",
      "Training loss (for 1 batch) at step 86600: 0.0004\n",
      "Seen so far: 2771232 samples\n",
      "Training loss (for 1 batch) at step 86700: 0.2075\n",
      "Seen so far: 2774432 samples\n",
      "Training loss (for 1 batch) at step 86800: 0.2508\n",
      "Seen so far: 2777632 samples\n",
      "Training loss (for 1 batch) at step 86900: 0.0128\n",
      "Seen so far: 2780832 samples\n",
      "Training loss (for 1 batch) at step 87000: 0.0003\n",
      "Seen so far: 2784032 samples\n",
      "Training loss (for 1 batch) at step 87100: 0.0058\n",
      "Seen so far: 2787232 samples\n",
      "Training loss (for 1 batch) at step 87200: 0.0075\n",
      "Seen so far: 2790432 samples\n",
      "Training loss (for 1 batch) at step 87300: 0.0052\n",
      "Seen so far: 2793632 samples\n",
      "Training loss (for 1 batch) at step 87400: 0.0001\n",
      "Seen so far: 2796832 samples\n",
      "Training loss (for 1 batch) at step 87500: 0.0056\n",
      "Seen so far: 2800032 samples\n",
      "Training loss (for 1 batch) at step 87600: 0.2830\n",
      "Seen so far: 2803232 samples\n",
      "Training loss (for 1 batch) at step 87700: 0.1189\n",
      "Seen so far: 2806432 samples\n",
      "Training loss (for 1 batch) at step 87800: 0.1211\n",
      "Seen so far: 2809632 samples\n",
      "Training loss (for 1 batch) at step 87900: 0.0703\n",
      "Seen so far: 2812832 samples\n",
      "Training loss (for 1 batch) at step 88000: 0.0197\n",
      "Seen so far: 2816032 samples\n",
      "Training loss (for 1 batch) at step 88100: 0.0040\n",
      "Seen so far: 2819232 samples\n",
      "Training loss (for 1 batch) at step 88200: 0.0057\n",
      "Seen so far: 2822432 samples\n",
      "Training loss (for 1 batch) at step 88300: 0.0000\n",
      "Seen so far: 2825632 samples\n",
      "Training loss (for 1 batch) at step 88400: 0.0003\n",
      "Seen so far: 2828832 samples\n",
      "Training loss (for 1 batch) at step 88500: 0.0896\n",
      "Seen so far: 2832032 samples\n",
      "Training loss (for 1 batch) at step 88600: 0.0001\n",
      "Seen so far: 2835232 samples\n",
      "Training loss (for 1 batch) at step 88700: 0.0483\n",
      "Seen so far: 2838432 samples\n",
      "Training loss (for 1 batch) at step 88800: 0.0001\n",
      "Seen so far: 2841632 samples\n",
      "Training loss (for 1 batch) at step 88900: 0.0027\n",
      "Seen so far: 2844832 samples\n",
      "Training loss (for 1 batch) at step 89000: 0.0648\n",
      "Seen so far: 2848032 samples\n",
      "Training loss (for 1 batch) at step 89100: 0.1200\n",
      "Seen so far: 2851232 samples\n",
      "Training loss (for 1 batch) at step 89200: 0.0329\n",
      "Seen so far: 2854432 samples\n",
      "Training loss (for 1 batch) at step 89300: 0.2567\n",
      "Seen so far: 2857632 samples\n",
      "Training loss (for 1 batch) at step 89400: 0.0609\n",
      "Seen so far: 2860832 samples\n",
      "Training loss (for 1 batch) at step 89500: 0.0006\n",
      "Seen so far: 2864032 samples\n",
      "Training loss (for 1 batch) at step 89600: 0.0307\n",
      "Seen so far: 2867232 samples\n",
      "Training loss (for 1 batch) at step 89700: 0.0001\n",
      "Seen so far: 2870432 samples\n",
      "Training loss (for 1 batch) at step 89800: 0.0009\n",
      "Seen so far: 2873632 samples\n",
      "Training loss (for 1 batch) at step 89900: 0.0314\n",
      "Seen so far: 2876832 samples\n",
      "Training loss (for 1 batch) at step 90000: 0.0020\n",
      "Seen so far: 2880032 samples\n",
      "Training loss (for 1 batch) at step 90100: 0.0000\n",
      "Seen so far: 2883232 samples\n",
      "Training loss (for 1 batch) at step 90200: 0.1548\n",
      "Seen so far: 2886432 samples\n",
      "Training loss (for 1 batch) at step 90300: 0.0012\n",
      "Seen so far: 2889632 samples\n",
      "Training loss (for 1 batch) at step 90400: 0.0009\n",
      "Seen so far: 2892832 samples\n",
      "Training loss (for 1 batch) at step 90500: 0.0117\n",
      "Seen so far: 2896032 samples\n",
      "Training loss (for 1 batch) at step 90600: 0.0000\n",
      "Seen so far: 2899232 samples\n",
      "Training loss (for 1 batch) at step 90700: 0.0015\n",
      "Seen so far: 2902432 samples\n",
      "Training loss (for 1 batch) at step 90800: 0.0015\n",
      "Seen so far: 2905632 samples\n",
      "Training loss (for 1 batch) at step 90900: 0.0026\n",
      "Seen so far: 2908832 samples\n",
      "Training loss (for 1 batch) at step 91000: 0.0002\n",
      "Seen so far: 2912032 samples\n",
      "Training loss (for 1 batch) at step 91100: 0.0169\n",
      "Seen so far: 2915232 samples\n",
      "Training loss (for 1 batch) at step 91200: 0.1199\n",
      "Seen so far: 2918432 samples\n",
      "Training loss (for 1 batch) at step 91300: 0.0772\n",
      "Seen so far: 2921632 samples\n",
      "Training loss (for 1 batch) at step 91400: 0.0006\n",
      "Seen so far: 2924832 samples\n",
      "Training loss (for 1 batch) at step 91500: 0.0035\n",
      "Seen so far: 2928032 samples\n",
      "Training loss (for 1 batch) at step 91600: 0.1676\n",
      "Seen so far: 2931232 samples\n",
      "Training loss (for 1 batch) at step 91700: 0.0003\n",
      "Seen so far: 2934432 samples\n",
      "Training loss (for 1 batch) at step 91800: 0.0277\n",
      "Seen so far: 2937632 samples\n",
      "Training loss (for 1 batch) at step 91900: 0.0001\n",
      "Seen so far: 2940832 samples\n",
      "Training loss (for 1 batch) at step 92000: 0.0010\n",
      "Seen so far: 2944032 samples\n",
      "Training loss (for 1 batch) at step 92100: 0.2697\n",
      "Seen so far: 2947232 samples\n",
      "Training loss (for 1 batch) at step 92200: 0.0007\n",
      "Seen so far: 2950432 samples\n",
      "Training loss (for 1 batch) at step 92300: 0.0000\n",
      "Seen so far: 2953632 samples\n",
      "Training loss (for 1 batch) at step 92400: 0.0554\n",
      "Seen so far: 2956832 samples\n",
      "Training loss (for 1 batch) at step 92500: 0.1194\n",
      "Seen so far: 2960032 samples\n",
      "Training loss (for 1 batch) at step 92600: 0.0002\n",
      "Seen so far: 2963232 samples\n",
      "Training loss (for 1 batch) at step 92700: 0.0003\n",
      "Seen so far: 2966432 samples\n",
      "Training loss (for 1 batch) at step 92800: 0.0000\n",
      "Seen so far: 2969632 samples\n",
      "Training loss (for 1 batch) at step 92900: 0.0010\n",
      "Seen so far: 2972832 samples\n",
      "Training loss (for 1 batch) at step 93000: 0.0040\n",
      "Seen so far: 2976032 samples\n",
      "Training loss (for 1 batch) at step 93100: 0.0010\n",
      "Seen so far: 2979232 samples\n",
      "Training loss (for 1 batch) at step 93200: 0.0000\n",
      "Seen so far: 2982432 samples\n",
      "Training loss (for 1 batch) at step 93300: 0.0274\n",
      "Seen so far: 2985632 samples\n",
      "Training loss (for 1 batch) at step 93400: 0.0000\n",
      "Seen so far: 2988832 samples\n",
      "Training loss (for 1 batch) at step 93500: 0.3215\n",
      "Seen so far: 2992032 samples\n",
      "Training loss (for 1 batch) at step 93600: 0.0296\n",
      "Seen so far: 2995232 samples\n",
      "Training loss (for 1 batch) at step 93700: 0.0000\n",
      "Seen so far: 2998432 samples\n",
      "Training loss (for 1 batch) at step 93800: 0.0801\n",
      "Seen so far: 3001632 samples\n",
      "Training loss (for 1 batch) at step 93900: 0.0070\n",
      "Seen so far: 3004832 samples\n",
      "Training loss (for 1 batch) at step 94000: 0.0605\n",
      "Seen so far: 3008032 samples\n",
      "Training loss (for 1 batch) at step 94100: 0.0081\n",
      "Seen so far: 3011232 samples\n",
      "Training loss (for 1 batch) at step 94200: 0.1235\n",
      "Seen so far: 3014432 samples\n",
      "Training loss (for 1 batch) at step 94300: 0.0572\n",
      "Seen so far: 3017632 samples\n",
      "Training loss (for 1 batch) at step 94400: 0.0771\n",
      "Seen so far: 3020832 samples\n",
      "Training loss (for 1 batch) at step 94500: 0.0000\n",
      "Seen so far: 3024032 samples\n",
      "Training loss (for 1 batch) at step 94600: 0.2317\n",
      "Seen so far: 3027232 samples\n",
      "Training loss (for 1 batch) at step 94700: 0.0007\n",
      "Seen so far: 3030432 samples\n",
      "Training loss (for 1 batch) at step 94800: 0.0094\n",
      "Seen so far: 3033632 samples\n",
      "Training loss (for 1 batch) at step 94900: 0.0001\n",
      "Seen so far: 3036832 samples\n",
      "Training loss (for 1 batch) at step 95000: 0.0009\n",
      "Seen so far: 3040032 samples\n",
      "Training loss (for 1 batch) at step 95100: 0.0059\n",
      "Seen so far: 3043232 samples\n",
      "Training loss (for 1 batch) at step 95200: 0.0886\n",
      "Seen so far: 3046432 samples\n",
      "Training loss (for 1 batch) at step 95300: 0.0001\n",
      "Seen so far: 3049632 samples\n",
      "Training loss (for 1 batch) at step 95400: 0.0032\n",
      "Seen so far: 3052832 samples\n",
      "Training loss (for 1 batch) at step 95500: 0.0546\n",
      "Seen so far: 3056032 samples\n",
      "Training loss (for 1 batch) at step 95600: 0.0405\n",
      "Seen so far: 3059232 samples\n",
      "Training loss (for 1 batch) at step 95700: 0.0659\n",
      "Seen so far: 3062432 samples\n",
      "Training loss (for 1 batch) at step 95800: 0.0507\n",
      "Seen so far: 3065632 samples\n",
      "Training loss (for 1 batch) at step 95900: 0.0009\n",
      "Seen so far: 3068832 samples\n",
      "Training loss (for 1 batch) at step 96000: 0.0006\n",
      "Seen so far: 3072032 samples\n",
      "Training loss (for 1 batch) at step 96100: 0.0003\n",
      "Seen so far: 3075232 samples\n",
      "Training loss (for 1 batch) at step 96200: 0.0192\n",
      "Seen so far: 3078432 samples\n",
      "Training loss (for 1 batch) at step 96300: 0.0001\n",
      "Seen so far: 3081632 samples\n",
      "Training loss (for 1 batch) at step 96400: 0.0000\n",
      "Seen so far: 3084832 samples\n",
      "Training loss (for 1 batch) at step 96500: 0.0004\n",
      "Seen so far: 3088032 samples\n",
      "Training loss (for 1 batch) at step 96600: 0.0012\n",
      "Seen so far: 3091232 samples\n",
      "Training loss (for 1 batch) at step 96700: 0.0303\n",
      "Seen so far: 3094432 samples\n",
      "Training loss (for 1 batch) at step 96800: 0.0051\n",
      "Seen so far: 3097632 samples\n",
      "Training loss (for 1 batch) at step 96900: 0.0002\n",
      "Seen so far: 3100832 samples\n",
      "Training loss (for 1 batch) at step 97000: 0.0000\n",
      "Seen so far: 3104032 samples\n",
      "Training loss (for 1 batch) at step 97100: 0.0384\n",
      "Seen so far: 3107232 samples\n",
      "Training loss (for 1 batch) at step 97200: 0.0001\n",
      "Seen so far: 3110432 samples\n",
      "Training loss (for 1 batch) at step 97300: 0.0616\n",
      "Seen so far: 3113632 samples\n",
      "Training loss (for 1 batch) at step 97400: 0.0004\n",
      "Seen so far: 3116832 samples\n",
      "Training loss (for 1 batch) at step 97500: 0.0006\n",
      "Seen so far: 3120032 samples\n",
      "Training loss (for 1 batch) at step 97600: 0.0001\n",
      "Seen so far: 3123232 samples\n",
      "Training loss (for 1 batch) at step 97700: 0.0000\n",
      "Seen so far: 3126432 samples\n",
      "Training loss (for 1 batch) at step 97800: 0.0059\n",
      "Seen so far: 3129632 samples\n",
      "Training loss (for 1 batch) at step 97900: 0.0222\n",
      "Seen so far: 3132832 samples\n",
      "Training loss (for 1 batch) at step 98000: 0.1017\n",
      "Seen so far: 3136032 samples\n",
      "Training loss (for 1 batch) at step 98100: 0.0009\n",
      "Seen so far: 3139232 samples\n",
      "Training loss (for 1 batch) at step 98200: 0.0027\n",
      "Seen so far: 3142432 samples\n",
      "Training loss (for 1 batch) at step 98300: 0.1286\n",
      "Seen so far: 3145632 samples\n",
      "Training loss (for 1 batch) at step 98400: 0.3019\n",
      "Seen so far: 3148832 samples\n",
      "Training loss (for 1 batch) at step 98500: 0.0009\n",
      "Seen so far: 3152032 samples\n",
      "Training loss (for 1 batch) at step 98600: 0.0004\n",
      "Seen so far: 3155232 samples\n",
      "Training loss (for 1 batch) at step 98700: 0.0012\n",
      "Seen so far: 3158432 samples\n",
      "Training loss (for 1 batch) at step 98800: 0.0000\n",
      "Seen so far: 3161632 samples\n",
      "Training loss (for 1 batch) at step 98900: 0.0525\n",
      "Seen so far: 3164832 samples\n",
      "Training loss (for 1 batch) at step 99000: 0.0010\n",
      "Seen so far: 3168032 samples\n",
      "Training loss (for 1 batch) at step 99100: 0.0000\n",
      "Seen so far: 3171232 samples\n",
      "Training loss (for 1 batch) at step 99200: 0.0446\n",
      "Seen so far: 3174432 samples\n",
      "Training loss (for 1 batch) at step 99300: 0.0639\n",
      "Seen so far: 3177632 samples\n",
      "Training loss (for 1 batch) at step 99400: 0.0024\n",
      "Seen so far: 3180832 samples\n",
      "Training loss (for 1 batch) at step 99500: 0.0042\n",
      "Seen so far: 3184032 samples\n",
      "Training loss (for 1 batch) at step 99600: 0.0000\n",
      "Seen so far: 3187232 samples\n",
      "Training loss (for 1 batch) at step 99700: 0.1347\n",
      "Seen so far: 3190432 samples\n",
      "Training loss (for 1 batch) at step 99800: 0.0010\n",
      "Seen so far: 3193632 samples\n",
      "Training loss (for 1 batch) at step 99900: 0.0000\n",
      "Seen so far: 3196832 samples\n",
      "Training loss (for 1 batch) at step 100000: 0.0005\n",
      "Seen so far: 3200032 samples\n",
      "Training loss (for 1 batch) at step 100100: 0.0000\n",
      "Seen so far: 3203232 samples\n",
      "Training loss (for 1 batch) at step 100200: 0.0022\n",
      "Seen so far: 3206432 samples\n",
      "Training loss (for 1 batch) at step 100300: 0.0015\n",
      "Seen so far: 3209632 samples\n",
      "Training loss (for 1 batch) at step 100400: 0.0097\n",
      "Seen so far: 3212832 samples\n",
      "Training loss (for 1 batch) at step 100500: 0.0001\n",
      "Seen so far: 3216032 samples\n",
      "Training loss (for 1 batch) at step 100600: 0.0169\n",
      "Seen so far: 3219232 samples\n",
      "Training loss (for 1 batch) at step 100700: 0.0008\n",
      "Seen so far: 3222432 samples\n",
      "Training loss (for 1 batch) at step 100800: 0.0000\n",
      "Seen so far: 3225632 samples\n",
      "Training loss (for 1 batch) at step 100900: 0.0000\n",
      "Seen so far: 3228832 samples\n",
      "Training loss (for 1 batch) at step 101000: 0.0059\n",
      "Seen so far: 3232032 samples\n",
      "Training loss (for 1 batch) at step 101100: 0.0766\n",
      "Seen so far: 3235232 samples\n",
      "Training loss (for 1 batch) at step 101200: 0.0401\n",
      "Seen so far: 3238432 samples\n",
      "Training loss (for 1 batch) at step 101300: 0.0000\n",
      "Seen so far: 3241632 samples\n",
      "Training loss (for 1 batch) at step 101400: 0.2006\n",
      "Seen so far: 3244832 samples\n",
      "Training loss (for 1 batch) at step 101500: 0.0001\n",
      "Seen so far: 3248032 samples\n",
      "Training loss (for 1 batch) at step 101600: 0.0119\n",
      "Seen so far: 3251232 samples\n",
      "Training loss (for 1 batch) at step 101700: 0.0001\n",
      "Seen so far: 3254432 samples\n",
      "Training loss (for 1 batch) at step 101800: 0.0004\n",
      "Seen so far: 3257632 samples\n",
      "Training loss (for 1 batch) at step 101900: 0.0000\n",
      "Seen so far: 3260832 samples\n",
      "Training loss (for 1 batch) at step 102000: 0.0466\n",
      "Seen so far: 3264032 samples\n",
      "Training loss (for 1 batch) at step 102100: 0.0001\n",
      "Seen so far: 3267232 samples\n",
      "Training loss (for 1 batch) at step 102200: 0.0118\n",
      "Seen so far: 3270432 samples\n",
      "Training loss (for 1 batch) at step 102300: 0.0156\n",
      "Seen so far: 3273632 samples\n",
      "Training loss (for 1 batch) at step 102400: 0.0044\n",
      "Seen so far: 3276832 samples\n",
      "Training loss (for 1 batch) at step 102500: 0.0005\n",
      "Seen so far: 3280032 samples\n",
      "Training loss (for 1 batch) at step 102600: 0.0482\n",
      "Seen so far: 3283232 samples\n",
      "Training loss (for 1 batch) at step 102700: 0.0490\n",
      "Seen so far: 3286432 samples\n",
      "Training loss (for 1 batch) at step 102800: 0.0029\n",
      "Seen so far: 3289632 samples\n",
      "Training loss (for 1 batch) at step 102900: 0.1178\n",
      "Seen so far: 3292832 samples\n",
      "Training loss (for 1 batch) at step 103000: 0.1047\n",
      "Seen so far: 3296032 samples\n",
      "Training loss (for 1 batch) at step 103100: 0.0030\n",
      "Seen so far: 3299232 samples\n",
      "Training loss (for 1 batch) at step 103200: 0.0001\n",
      "Seen so far: 3302432 samples\n",
      "Training loss (for 1 batch) at step 103300: 0.0532\n",
      "Seen so far: 3305632 samples\n",
      "Training loss (for 1 batch) at step 103400: 0.0003\n",
      "Seen so far: 3308832 samples\n",
      "Training loss (for 1 batch) at step 103500: 0.1248\n",
      "Seen so far: 3312032 samples\n",
      "Training loss (for 1 batch) at step 103600: 0.0089\n",
      "Seen so far: 3315232 samples\n",
      "Training loss (for 1 batch) at step 103700: 0.2367\n",
      "Seen so far: 3318432 samples\n",
      "Training loss (for 1 batch) at step 103800: 0.0000\n",
      "Seen so far: 3321632 samples\n",
      "Training loss (for 1 batch) at step 103900: 0.0017\n",
      "Seen so far: 3324832 samples\n",
      "Training loss (for 1 batch) at step 104000: 0.0000\n",
      "Seen so far: 3328032 samples\n",
      "Training loss (for 1 batch) at step 104100: 0.0000\n",
      "Seen so far: 3331232 samples\n",
      "Training loss (for 1 batch) at step 104200: 0.2413\n",
      "Seen so far: 3334432 samples\n",
      "Training loss (for 1 batch) at step 104300: 0.1923\n",
      "Seen so far: 3337632 samples\n",
      "Training loss (for 1 batch) at step 104400: 0.0139\n",
      "Seen so far: 3340832 samples\n",
      "Training loss (for 1 batch) at step 104500: 0.1905\n",
      "Seen so far: 3344032 samples\n",
      "Training loss (for 1 batch) at step 104600: 0.0002\n",
      "Seen so far: 3347232 samples\n",
      "Training loss (for 1 batch) at step 104700: 0.0002\n",
      "Seen so far: 3350432 samples\n",
      "Training loss (for 1 batch) at step 104800: 0.0003\n",
      "Seen so far: 3353632 samples\n",
      "Training loss (for 1 batch) at step 104900: 0.0002\n",
      "Seen so far: 3356832 samples\n",
      "Training loss (for 1 batch) at step 105000: 0.0016\n",
      "Seen so far: 3360032 samples\n",
      "Training loss (for 1 batch) at step 105100: 0.0048\n",
      "Seen so far: 3363232 samples\n",
      "Training loss (for 1 batch) at step 105200: 0.0001\n",
      "Seen so far: 3366432 samples\n",
      "Training loss (for 1 batch) at step 105300: 0.0001\n",
      "Seen so far: 3369632 samples\n",
      "Training loss (for 1 batch) at step 105400: 0.0014\n",
      "Seen so far: 3372832 samples\n",
      "Training loss (for 1 batch) at step 105500: 0.2095\n",
      "Seen so far: 3376032 samples\n",
      "Training loss (for 1 batch) at step 105600: 0.0813\n",
      "Seen so far: 3379232 samples\n",
      "Training loss (for 1 batch) at step 105700: 0.0012\n",
      "Seen so far: 3382432 samples\n",
      "Training loss (for 1 batch) at step 105800: 0.0232\n",
      "Seen so far: 3385632 samples\n",
      "Training loss (for 1 batch) at step 105900: 0.0002\n",
      "Seen so far: 3388832 samples\n",
      "Training loss (for 1 batch) at step 106000: 0.1108\n",
      "Seen so far: 3392032 samples\n",
      "Training loss (for 1 batch) at step 106100: 0.0001\n",
      "Seen so far: 3395232 samples\n",
      "Training loss (for 1 batch) at step 106200: 0.0363\n",
      "Seen so far: 3398432 samples\n",
      "Training loss (for 1 batch) at step 106300: 0.1859\n",
      "Seen so far: 3401632 samples\n",
      "Training loss (for 1 batch) at step 106400: 0.0002\n",
      "Seen so far: 3404832 samples\n",
      "Training loss (for 1 batch) at step 106500: 0.0250\n",
      "Seen so far: 3408032 samples\n",
      "Training loss (for 1 batch) at step 106600: 0.0000\n",
      "Seen so far: 3411232 samples\n",
      "Training loss (for 1 batch) at step 106700: 0.0004\n",
      "Seen so far: 3414432 samples\n",
      "Training loss (for 1 batch) at step 106800: 0.2230\n",
      "Seen so far: 3417632 samples\n",
      "Training loss (for 1 batch) at step 106900: 0.0412\n",
      "Seen so far: 3420832 samples\n",
      "Training loss (for 1 batch) at step 107000: 0.0917\n",
      "Seen so far: 3424032 samples\n",
      "Training loss (for 1 batch) at step 107100: 0.0036\n",
      "Seen so far: 3427232 samples\n",
      "Training loss (for 1 batch) at step 107200: 0.0053\n",
      "Seen so far: 3430432 samples\n",
      "Training loss (for 1 batch) at step 107300: 0.0001\n",
      "Seen so far: 3433632 samples\n",
      "Training loss (for 1 batch) at step 107400: 0.0002\n",
      "Seen so far: 3436832 samples\n",
      "Training loss (for 1 batch) at step 107500: 0.0053\n",
      "Seen so far: 3440032 samples\n",
      "Training loss (for 1 batch) at step 107600: 0.2600\n",
      "Seen so far: 3443232 samples\n",
      "Training loss (for 1 batch) at step 107700: 0.0000\n",
      "Seen so far: 3446432 samples\n",
      "Training loss (for 1 batch) at step 107800: 0.0016\n",
      "Seen so far: 3449632 samples\n",
      "Training loss (for 1 batch) at step 107900: 0.4782\n",
      "Seen so far: 3452832 samples\n",
      "Training loss (for 1 batch) at step 108000: 0.1172\n",
      "Seen so far: 3456032 samples\n",
      "Training loss (for 1 batch) at step 108100: 0.0056\n",
      "Seen so far: 3459232 samples\n",
      "Training loss (for 1 batch) at step 108200: 0.1184\n",
      "Seen so far: 3462432 samples\n",
      "Training loss (for 1 batch) at step 108300: 0.0001\n",
      "Seen so far: 3465632 samples\n",
      "Training loss (for 1 batch) at step 108400: 0.0709\n",
      "Seen so far: 3468832 samples\n",
      "Training loss (for 1 batch) at step 108500: 0.0000\n",
      "Seen so far: 3472032 samples\n",
      "Training loss (for 1 batch) at step 108600: 0.0006\n",
      "Seen so far: 3475232 samples\n",
      "Training loss (for 1 batch) at step 108700: 0.0033\n",
      "Seen so far: 3478432 samples\n",
      "Training loss (for 1 batch) at step 108800: 0.0090\n",
      "Seen so far: 3481632 samples\n",
      "Training loss (for 1 batch) at step 108900: 0.0681\n",
      "Seen so far: 3484832 samples\n",
      "Training loss (for 1 batch) at step 109000: 0.0027\n",
      "Seen so far: 3488032 samples\n",
      "Training loss (for 1 batch) at step 109100: 0.0006\n",
      "Seen so far: 3491232 samples\n",
      "Training loss (for 1 batch) at step 109200: 0.0574\n",
      "Seen so far: 3494432 samples\n",
      "Training loss (for 1 batch) at step 109300: 0.0324\n",
      "Seen so far: 3497632 samples\n",
      "Training loss (for 1 batch) at step 109400: 0.0001\n",
      "Seen so far: 3500832 samples\n",
      "Training loss (for 1 batch) at step 109500: 0.0001\n",
      "Seen so far: 3504032 samples\n",
      "Training loss (for 1 batch) at step 109600: 0.0000\n",
      "Seen so far: 3507232 samples\n",
      "Training loss (for 1 batch) at step 109700: 0.0243\n",
      "Seen so far: 3510432 samples\n",
      "Training loss (for 1 batch) at step 109800: 0.1259\n",
      "Seen so far: 3513632 samples\n",
      "Training loss (for 1 batch) at step 109900: 0.2547\n",
      "Seen so far: 3516832 samples\n",
      "Training loss (for 1 batch) at step 110000: 0.0003\n",
      "Seen so far: 3520032 samples\n",
      "Training loss (for 1 batch) at step 110100: 0.0641\n",
      "Seen so far: 3523232 samples\n",
      "Training loss (for 1 batch) at step 110200: 0.0569\n",
      "Seen so far: 3526432 samples\n",
      "Training loss (for 1 batch) at step 110300: 0.0010\n",
      "Seen so far: 3529632 samples\n",
      "Training loss (for 1 batch) at step 110400: 0.0003\n",
      "Seen so far: 3532832 samples\n",
      "Training loss (for 1 batch) at step 110500: 0.0000\n",
      "Seen so far: 3536032 samples\n",
      "Training loss (for 1 batch) at step 110600: 0.0012\n",
      "Seen so far: 3539232 samples\n",
      "Training loss (for 1 batch) at step 110700: 0.0003\n",
      "Seen so far: 3542432 samples\n",
      "Training loss (for 1 batch) at step 110800: 0.0004\n",
      "Seen so far: 3545632 samples\n",
      "Training loss (for 1 batch) at step 110900: 0.0820\n",
      "Seen so far: 3548832 samples\n",
      "Training loss (for 1 batch) at step 111000: 0.0002\n",
      "Seen so far: 3552032 samples\n",
      "Training loss (for 1 batch) at step 111100: 0.0553\n",
      "Seen so far: 3555232 samples\n",
      "Training loss (for 1 batch) at step 111200: 0.0001\n",
      "Seen so far: 3558432 samples\n",
      "Training loss (for 1 batch) at step 111300: 0.0033\n",
      "Seen so far: 3561632 samples\n",
      "Training loss (for 1 batch) at step 111400: 0.0171\n",
      "Seen so far: 3564832 samples\n",
      "Training loss (for 1 batch) at step 111500: 0.0001\n",
      "Seen so far: 3568032 samples\n",
      "Training loss (for 1 batch) at step 111600: 0.0000\n",
      "Seen so far: 3571232 samples\n",
      "Training loss (for 1 batch) at step 111700: 0.0257\n",
      "Seen so far: 3574432 samples\n",
      "Training loss (for 1 batch) at step 111800: 0.3714\n",
      "Seen so far: 3577632 samples\n",
      "Training loss (for 1 batch) at step 111900: 0.1092\n",
      "Seen so far: 3580832 samples\n",
      "Training loss (for 1 batch) at step 112000: 0.0001\n",
      "Seen so far: 3584032 samples\n",
      "Training loss (for 1 batch) at step 112100: 0.1565\n",
      "Seen so far: 3587232 samples\n",
      "Training loss (for 1 batch) at step 112200: 0.0615\n",
      "Seen so far: 3590432 samples\n",
      "Training loss (for 1 batch) at step 112300: 0.0001\n",
      "Seen so far: 3593632 samples\n",
      "Training loss (for 1 batch) at step 112400: 0.0225\n",
      "Seen so far: 3596832 samples\n",
      "Training loss (for 1 batch) at step 112500: 0.0103\n",
      "Seen so far: 3600032 samples\n",
      "Training loss (for 1 batch) at step 112600: 0.0001\n",
      "Seen so far: 3603232 samples\n",
      "Training loss (for 1 batch) at step 112700: 0.0002\n",
      "Seen so far: 3606432 samples\n",
      "Training loss (for 1 batch) at step 112800: 0.0016\n",
      "Seen so far: 3609632 samples\n",
      "Training loss (for 1 batch) at step 112900: 0.0003\n",
      "Seen so far: 3612832 samples\n",
      "Training loss (for 1 batch) at step 113000: 0.2334\n",
      "Seen so far: 3616032 samples\n",
      "Training loss (for 1 batch) at step 113100: 0.0000\n",
      "Seen so far: 3619232 samples\n",
      "Training loss (for 1 batch) at step 113200: 0.0019\n",
      "Seen so far: 3622432 samples\n",
      "Training loss (for 1 batch) at step 113300: 0.0004\n",
      "Seen so far: 3625632 samples\n",
      "Training loss (for 1 batch) at step 113400: 0.0001\n",
      "Seen so far: 3628832 samples\n",
      "Training loss (for 1 batch) at step 113500: 0.6665\n",
      "Seen so far: 3632032 samples\n",
      "Training loss (for 1 batch) at step 113600: 0.2857\n",
      "Seen so far: 3635232 samples\n",
      "Training loss (for 1 batch) at step 113700: 0.0556\n",
      "Seen so far: 3638432 samples\n",
      "Training loss (for 1 batch) at step 113800: 0.0001\n",
      "Seen so far: 3641632 samples\n",
      "Training loss (for 1 batch) at step 113900: 0.0000\n",
      "Seen so far: 3644832 samples\n",
      "Training loss (for 1 batch) at step 114000: 0.1175\n",
      "Seen so far: 3648032 samples\n",
      "Training loss (for 1 batch) at step 114100: 0.2731\n",
      "Seen so far: 3651232 samples\n",
      "Training loss (for 1 batch) at step 114200: 0.0794\n",
      "Seen so far: 3654432 samples\n",
      "Training loss (for 1 batch) at step 114300: 0.0001\n",
      "Seen so far: 3657632 samples\n",
      "Training loss (for 1 batch) at step 114400: 0.1236\n",
      "Seen so far: 3660832 samples\n",
      "Training loss (for 1 batch) at step 114500: 0.0003\n",
      "Seen so far: 3664032 samples\n",
      "Training loss (for 1 batch) at step 114600: 0.0757\n",
      "Seen so far: 3667232 samples\n",
      "Training loss (for 1 batch) at step 114700: 0.0120\n",
      "Seen so far: 3670432 samples\n",
      "Training loss (for 1 batch) at step 114800: 0.0458\n",
      "Seen so far: 3673632 samples\n",
      "Training loss (for 1 batch) at step 114900: 0.0748\n",
      "Seen so far: 3676832 samples\n",
      "Training loss (for 1 batch) at step 115000: 0.0001\n",
      "Seen so far: 3680032 samples\n",
      "Training loss (for 1 batch) at step 115100: 0.0001\n",
      "Seen so far: 3683232 samples\n",
      "Training loss (for 1 batch) at step 115200: 0.0000\n",
      "Seen so far: 3686432 samples\n",
      "Training loss (for 1 batch) at step 115300: 0.0599\n",
      "Seen so far: 3689632 samples\n",
      "Training loss (for 1 batch) at step 115400: 0.0033\n",
      "Seen so far: 3692832 samples\n",
      "Training loss (for 1 batch) at step 115500: 0.0464\n",
      "Seen so far: 3696032 samples\n",
      "Training loss (for 1 batch) at step 115600: 0.0489\n",
      "Seen so far: 3699232 samples\n",
      "Training loss (for 1 batch) at step 115700: 0.0004\n",
      "Seen so far: 3702432 samples\n",
      "Training loss (for 1 batch) at step 115800: 0.0004\n",
      "Seen so far: 3705632 samples\n",
      "Training loss (for 1 batch) at step 115900: 0.0001\n",
      "Seen so far: 3708832 samples\n",
      "Training loss (for 1 batch) at step 116000: 0.1080\n",
      "Seen so far: 3712032 samples\n",
      "Training loss (for 1 batch) at step 116100: 0.2736\n",
      "Seen so far: 3715232 samples\n",
      "Training loss (for 1 batch) at step 116200: 0.0811\n",
      "Seen so far: 3718432 samples\n",
      "Training loss (for 1 batch) at step 116300: 0.0045\n",
      "Seen so far: 3721632 samples\n",
      "Training loss (for 1 batch) at step 116400: 0.0000\n",
      "Seen so far: 3724832 samples\n",
      "Training loss (for 1 batch) at step 116500: 0.0062\n",
      "Seen so far: 3728032 samples\n",
      "Training loss (for 1 batch) at step 116600: 0.0004\n",
      "Seen so far: 3731232 samples\n",
      "Training loss (for 1 batch) at step 116700: 0.0001\n",
      "Seen so far: 3734432 samples\n",
      "Training loss (for 1 batch) at step 116800: 0.1778\n",
      "Seen so far: 3737632 samples\n",
      "Training loss (for 1 batch) at step 116900: 0.0000\n",
      "Seen so far: 3740832 samples\n",
      "Training loss (for 1 batch) at step 117000: 0.0000\n",
      "Seen so far: 3744032 samples\n",
      "Training loss (for 1 batch) at step 117100: 0.0004\n",
      "Seen so far: 3747232 samples\n",
      "Training loss (for 1 batch) at step 117200: 0.0001\n",
      "Seen so far: 3750432 samples\n",
      "Training loss (for 1 batch) at step 117300: 0.1501\n",
      "Seen so far: 3753632 samples\n",
      "Training loss (for 1 batch) at step 117400: 0.0002\n",
      "Seen so far: 3756832 samples\n",
      "Training loss (for 1 batch) at step 117500: 0.1747\n",
      "Seen so far: 3760032 samples\n",
      "Training loss (for 1 batch) at step 117600: 0.0002\n",
      "Seen so far: 3763232 samples\n",
      "Training loss (for 1 batch) at step 117700: 0.0220\n",
      "Seen so far: 3766432 samples\n",
      "Training loss (for 1 batch) at step 117800: 0.0028\n",
      "Seen so far: 3769632 samples\n",
      "Training loss (for 1 batch) at step 117900: 0.0001\n",
      "Seen so far: 3772832 samples\n",
      "Training loss (for 1 batch) at step 118000: 0.0002\n",
      "Seen so far: 3776032 samples\n",
      "Training loss (for 1 batch) at step 118100: 0.4104\n",
      "Seen so far: 3779232 samples\n",
      "Training loss (for 1 batch) at step 118200: 0.0726\n",
      "Seen so far: 3782432 samples\n",
      "Training loss (for 1 batch) at step 118300: 0.0065\n",
      "Seen so far: 3785632 samples\n",
      "Training loss (for 1 batch) at step 118400: 0.0086\n",
      "Seen so far: 3788832 samples\n",
      "Training loss (for 1 batch) at step 118500: 0.0000\n",
      "Seen so far: 3792032 samples\n",
      "Training loss (for 1 batch) at step 118600: 0.0000\n",
      "Seen so far: 3795232 samples\n",
      "Training loss (for 1 batch) at step 118700: 0.0000\n",
      "Seen so far: 3798432 samples\n",
      "Training loss (for 1 batch) at step 118800: 0.0001\n",
      "Seen so far: 3801632 samples\n",
      "Training loss (for 1 batch) at step 118900: 0.0000\n",
      "Seen so far: 3804832 samples\n",
      "Training loss (for 1 batch) at step 119000: 0.0016\n",
      "Seen so far: 3808032 samples\n",
      "Training loss (for 1 batch) at step 119100: 0.0890\n",
      "Seen so far: 3811232 samples\n",
      "Training loss (for 1 batch) at step 119200: 0.0000\n",
      "Seen so far: 3814432 samples\n",
      "Training loss (for 1 batch) at step 119300: 0.2359\n",
      "Seen so far: 3817632 samples\n",
      "Training loss (for 1 batch) at step 119400: 0.0050\n",
      "Seen so far: 3820832 samples\n",
      "Training loss (for 1 batch) at step 119500: 0.0630\n",
      "Seen so far: 3824032 samples\n",
      "Training loss (for 1 batch) at step 119600: 0.0126\n",
      "Seen so far: 3827232 samples\n",
      "Training loss (for 1 batch) at step 119700: 0.0005\n",
      "Seen so far: 3830432 samples\n",
      "Training loss (for 1 batch) at step 119800: 0.0000\n",
      "Seen so far: 3833632 samples\n",
      "Training loss (for 1 batch) at step 119900: 0.0002\n",
      "Seen so far: 3836832 samples\n",
      "Training loss (for 1 batch) at step 120000: 0.0687\n",
      "Seen so far: 3840032 samples\n",
      "Training loss (for 1 batch) at step 120100: 0.0123\n",
      "Seen so far: 3843232 samples\n",
      "Training loss (for 1 batch) at step 120200: 0.0000\n",
      "Seen so far: 3846432 samples\n",
      "Training loss (for 1 batch) at step 120300: 0.2273\n",
      "Seen so far: 3849632 samples\n",
      "Training loss (for 1 batch) at step 120400: 0.9056\n",
      "Seen so far: 3852832 samples\n",
      "Training loss (for 1 batch) at step 120500: 0.0001\n",
      "Seen so far: 3856032 samples\n",
      "Training loss (for 1 batch) at step 120600: 0.0001\n",
      "Seen so far: 3859232 samples\n",
      "Training loss (for 1 batch) at step 120700: 0.0244\n",
      "Seen so far: 3862432 samples\n",
      "Training loss (for 1 batch) at step 120800: 0.0020\n",
      "Seen so far: 3865632 samples\n",
      "Training loss (for 1 batch) at step 120900: 0.0581\n",
      "Seen so far: 3868832 samples\n",
      "Training loss (for 1 batch) at step 121000: 0.0002\n",
      "Seen so far: 3872032 samples\n",
      "Training loss (for 1 batch) at step 121100: 0.0001\n",
      "Seen so far: 3875232 samples\n",
      "Training loss (for 1 batch) at step 121200: 0.0001\n",
      "Seen so far: 3878432 samples\n",
      "Training loss (for 1 batch) at step 121300: 0.0824\n",
      "Seen so far: 3881632 samples\n",
      "Training loss (for 1 batch) at step 121400: 0.2772\n",
      "Seen so far: 3884832 samples\n",
      "Training loss (for 1 batch) at step 121500: 0.0272\n",
      "Seen so far: 3888032 samples\n",
      "Training loss (for 1 batch) at step 121600: 0.0002\n",
      "Seen so far: 3891232 samples\n",
      "Training loss (for 1 batch) at step 121700: 0.3295\n",
      "Seen so far: 3894432 samples\n",
      "Training loss (for 1 batch) at step 121800: 0.0707\n",
      "Seen so far: 3897632 samples\n",
      "Training loss (for 1 batch) at step 121900: 0.0001\n",
      "Seen so far: 3900832 samples\n",
      "Training loss (for 1 batch) at step 122000: 0.0009\n",
      "Seen so far: 3904032 samples\n",
      "Training loss (for 1 batch) at step 122100: 0.0071\n",
      "Seen so far: 3907232 samples\n",
      "Training loss (for 1 batch) at step 122200: 0.0040\n",
      "Seen so far: 3910432 samples\n",
      "Training loss (for 1 batch) at step 122300: 0.0000\n",
      "Seen so far: 3913632 samples\n",
      "Training loss (for 1 batch) at step 122400: 0.0001\n",
      "Seen so far: 3916832 samples\n",
      "Training loss (for 1 batch) at step 122500: 0.0000\n",
      "Seen so far: 3920032 samples\n",
      "Training loss (for 1 batch) at step 122600: 0.0000\n",
      "Seen so far: 3923232 samples\n",
      "Training loss (for 1 batch) at step 122700: 0.0013\n",
      "Seen so far: 3926432 samples\n",
      "Training loss (for 1 batch) at step 122800: 0.0385\n",
      "Seen so far: 3929632 samples\n",
      "Training loss (for 1 batch) at step 122900: 0.0698\n",
      "Seen so far: 3932832 samples\n",
      "Training loss (for 1 batch) at step 123000: 0.0000\n",
      "Seen so far: 3936032 samples\n",
      "Training loss (for 1 batch) at step 123100: 0.0214\n",
      "Seen so far: 3939232 samples\n",
      "Training loss (for 1 batch) at step 123200: 0.0013\n",
      "Seen so far: 3942432 samples\n",
      "Training loss (for 1 batch) at step 123300: 0.0695\n",
      "Seen so far: 3945632 samples\n",
      "Training loss (for 1 batch) at step 123400: 0.0005\n",
      "Seen so far: 3948832 samples\n",
      "Training loss (for 1 batch) at step 123500: 0.1881\n",
      "Seen so far: 3952032 samples\n",
      "Training loss (for 1 batch) at step 123600: 0.1157\n",
      "Seen so far: 3955232 samples\n",
      "Training loss (for 1 batch) at step 123700: 0.0538\n",
      "Seen so far: 3958432 samples\n",
      "Training loss (for 1 batch) at step 123800: 0.0000\n",
      "Seen so far: 3961632 samples\n",
      "Training loss (for 1 batch) at step 123900: 0.0007\n",
      "Seen so far: 3964832 samples\n",
      "Training loss (for 1 batch) at step 124000: 0.0271\n",
      "Seen so far: 3968032 samples\n",
      "Training loss (for 1 batch) at step 124100: 0.0083\n",
      "Seen so far: 3971232 samples\n",
      "Training loss (for 1 batch) at step 124200: 0.0516\n",
      "Seen so far: 3974432 samples\n",
      "Training loss (for 1 batch) at step 124300: 0.0069\n",
      "Seen so far: 3977632 samples\n",
      "Training loss (for 1 batch) at step 124400: 0.0000\n",
      "Seen so far: 3980832 samples\n",
      "Training loss (for 1 batch) at step 124500: 0.0662\n",
      "Seen so far: 3984032 samples\n",
      "Training loss (for 1 batch) at step 124600: 0.2152\n",
      "Seen so far: 3987232 samples\n",
      "Training loss (for 1 batch) at step 124700: 0.0300\n",
      "Seen so far: 3990432 samples\n",
      "Training loss (for 1 batch) at step 124800: 0.0097\n",
      "Seen so far: 3993632 samples\n",
      "Training loss (for 1 batch) at step 124900: 0.0002\n",
      "Seen so far: 3996832 samples\n",
      "Training loss (for 1 batch) at step 125000: 0.0218\n",
      "Seen so far: 4000032 samples\n",
      "Training loss (for 1 batch) at step 125100: 0.0000\n",
      "Seen so far: 4003232 samples\n",
      "Training loss (for 1 batch) at step 125200: 0.2473\n",
      "Seen so far: 4006432 samples\n",
      "Training loss (for 1 batch) at step 125300: 0.0000\n",
      "Seen so far: 4009632 samples\n",
      "Training loss (for 1 batch) at step 125400: 0.0000\n",
      "Seen so far: 4012832 samples\n",
      "Training loss (for 1 batch) at step 125500: 0.0000\n",
      "Seen so far: 4016032 samples\n",
      "Training loss (for 1 batch) at step 125600: 0.5823\n",
      "Seen so far: 4019232 samples\n",
      "Training loss (for 1 batch) at step 125700: 0.0004\n",
      "Seen so far: 4022432 samples\n",
      "Training loss (for 1 batch) at step 125800: 0.0002\n",
      "Seen so far: 4025632 samples\n",
      "Training loss (for 1 batch) at step 125900: 0.0001\n",
      "Seen so far: 4028832 samples\n",
      "Training loss (for 1 batch) at step 126000: 0.0002\n",
      "Seen so far: 4032032 samples\n",
      "Training loss (for 1 batch) at step 126100: 0.0029\n",
      "Seen so far: 4035232 samples\n",
      "Training loss (for 1 batch) at step 126200: 0.4971\n",
      "Seen so far: 4038432 samples\n",
      "Training loss (for 1 batch) at step 126300: 0.1103\n",
      "Seen so far: 4041632 samples\n",
      "Training loss (for 1 batch) at step 126400: 0.0006\n",
      "Seen so far: 4044832 samples\n",
      "Training loss (for 1 batch) at step 126500: 0.2388\n",
      "Seen so far: 4048032 samples\n",
      "Training loss (for 1 batch) at step 126600: 0.2696\n",
      "Seen so far: 4051232 samples\n",
      "Training loss (for 1 batch) at step 126700: 0.0001\n",
      "Seen so far: 4054432 samples\n",
      "Training loss (for 1 batch) at step 126800: 0.0249\n",
      "Seen so far: 4057632 samples\n",
      "Training loss (for 1 batch) at step 126900: 0.0001\n",
      "Seen so far: 4060832 samples\n",
      "Training loss (for 1 batch) at step 127000: 0.0056\n",
      "Seen so far: 4064032 samples\n",
      "Training loss (for 1 batch) at step 127100: 0.2767\n",
      "Seen so far: 4067232 samples\n",
      "Training loss (for 1 batch) at step 127200: 0.0025\n",
      "Seen so far: 4070432 samples\n",
      "Training loss (for 1 batch) at step 127300: 0.0000\n",
      "Seen so far: 4073632 samples\n",
      "Training loss (for 1 batch) at step 127400: 0.2920\n",
      "Seen so far: 4076832 samples\n",
      "Training loss (for 1 batch) at step 127500: 0.2453\n",
      "Seen so far: 4080032 samples\n",
      "Training loss (for 1 batch) at step 127600: 0.0922\n",
      "Seen so far: 4083232 samples\n",
      "Training loss (for 1 batch) at step 127700: 0.0011\n",
      "Seen so far: 4086432 samples\n",
      "Training loss (for 1 batch) at step 127800: 0.0045\n",
      "Seen so far: 4089632 samples\n",
      "Training loss (for 1 batch) at step 127900: 0.0001\n",
      "Seen so far: 4092832 samples\n",
      "Training loss (for 1 batch) at step 128000: 0.0008\n",
      "Seen so far: 4096032 samples\n",
      "Training loss (for 1 batch) at step 128100: 0.1467\n",
      "Seen so far: 4099232 samples\n",
      "Training loss (for 1 batch) at step 128200: 0.0001\n",
      "Seen so far: 4102432 samples\n",
      "Training loss (for 1 batch) at step 128300: 0.0218\n",
      "Seen so far: 4105632 samples\n",
      "Training loss (for 1 batch) at step 128400: 0.0005\n",
      "Seen so far: 4108832 samples\n",
      "Training loss (for 1 batch) at step 128500: 0.0000\n",
      "Seen so far: 4112032 samples\n",
      "Training loss (for 1 batch) at step 128600: 0.0011\n",
      "Seen so far: 4115232 samples\n",
      "Training loss (for 1 batch) at step 128700: 0.0055\n",
      "Seen so far: 4118432 samples\n",
      "Training loss (for 1 batch) at step 128800: 0.0008\n",
      "Seen so far: 4121632 samples\n",
      "Training loss (for 1 batch) at step 128900: 0.0000\n",
      "Seen so far: 4124832 samples\n",
      "Training loss (for 1 batch) at step 129000: 0.0002\n",
      "Seen so far: 4128032 samples\n",
      "Training loss (for 1 batch) at step 129100: 0.0000\n",
      "Seen so far: 4131232 samples\n",
      "Training loss (for 1 batch) at step 129200: 0.0000\n",
      "Seen so far: 4134432 samples\n",
      "Training loss (for 1 batch) at step 129300: 0.0255\n",
      "Seen so far: 4137632 samples\n",
      "Training loss (for 1 batch) at step 129400: 0.6898\n",
      "Seen so far: 4140832 samples\n",
      "Training loss (for 1 batch) at step 129500: 0.1018\n",
      "Seen so far: 4144032 samples\n",
      "Training loss (for 1 batch) at step 129600: 0.0053\n",
      "Seen so far: 4147232 samples\n",
      "Training loss (for 1 batch) at step 129700: 0.0017\n",
      "Seen so far: 4150432 samples\n",
      "Training loss (for 1 batch) at step 129800: 0.0006\n",
      "Seen so far: 4153632 samples\n",
      "Training loss (for 1 batch) at step 129900: 0.2368\n",
      "Seen so far: 4156832 samples\n",
      "Training loss (for 1 batch) at step 130000: 0.0012\n",
      "Seen so far: 4160032 samples\n",
      "Training loss (for 1 batch) at step 130100: 0.0000\n",
      "Seen so far: 4163232 samples\n",
      "Training loss (for 1 batch) at step 130200: 0.0152\n",
      "Seen so far: 4166432 samples\n",
      "Training loss (for 1 batch) at step 130300: 0.0069\n",
      "Seen so far: 4169632 samples\n",
      "Training loss (for 1 batch) at step 130400: 0.0042\n",
      "Seen so far: 4172832 samples\n",
      "Training loss (for 1 batch) at step 130500: 0.0028\n",
      "Seen so far: 4176032 samples\n",
      "Training loss (for 1 batch) at step 130600: 0.3670\n",
      "Seen so far: 4179232 samples\n",
      "Training loss (for 1 batch) at step 130700: 0.0000\n",
      "Seen so far: 4182432 samples\n",
      "Training loss (for 1 batch) at step 130800: 0.0227\n",
      "Seen so far: 4185632 samples\n",
      "Training loss (for 1 batch) at step 130900: 0.0003\n",
      "Seen so far: 4188832 samples\n",
      "Training loss (for 1 batch) at step 131000: 0.1722\n",
      "Seen so far: 4192032 samples\n",
      "Training loss (for 1 batch) at step 131100: 0.0027\n",
      "Seen so far: 4195232 samples\n",
      "Training loss (for 1 batch) at step 131200: 0.0003\n",
      "Seen so far: 4198432 samples\n",
      "Training loss (for 1 batch) at step 131300: 0.1112\n",
      "Seen so far: 4201632 samples\n",
      "Training loss (for 1 batch) at step 131400: 0.0002\n",
      "Seen so far: 4204832 samples\n",
      "Training loss (for 1 batch) at step 131500: 0.0015\n",
      "Seen so far: 4208032 samples\n",
      "Training loss (for 1 batch) at step 131600: 0.1582\n",
      "Seen so far: 4211232 samples\n",
      "Training loss (for 1 batch) at step 131700: 0.0024\n",
      "Seen so far: 4214432 samples\n",
      "Training loss (for 1 batch) at step 131800: 0.1078\n",
      "Seen so far: 4217632 samples\n",
      "Training loss (for 1 batch) at step 131900: 0.0001\n",
      "Seen so far: 4220832 samples\n",
      "Training loss (for 1 batch) at step 132000: 0.0075\n",
      "Seen so far: 4224032 samples\n",
      "Training loss (for 1 batch) at step 132100: 0.0206\n",
      "Seen so far: 4227232 samples\n",
      "Training loss (for 1 batch) at step 132200: 0.0685\n",
      "Seen so far: 4230432 samples\n",
      "Training loss (for 1 batch) at step 132300: 0.0090\n",
      "Seen so far: 4233632 samples\n",
      "Training loss (for 1 batch) at step 132400: 0.0000\n",
      "Seen so far: 4236832 samples\n",
      "Training loss (for 1 batch) at step 132500: 0.0015\n",
      "Seen so far: 4240032 samples\n",
      "Training loss (for 1 batch) at step 132600: 0.1075\n",
      "Seen so far: 4243232 samples\n",
      "Training loss (for 1 batch) at step 132700: 0.0001\n",
      "Seen so far: 4246432 samples\n",
      "Training loss (for 1 batch) at step 132800: 0.0058\n",
      "Seen so far: 4249632 samples\n",
      "Training loss (for 1 batch) at step 132900: 0.0735\n",
      "Seen so far: 4252832 samples\n",
      "Training loss (for 1 batch) at step 133000: 0.0006\n",
      "Seen so far: 4256032 samples\n",
      "Training loss (for 1 batch) at step 133100: 0.0000\n",
      "Seen so far: 4259232 samples\n",
      "Training loss (for 1 batch) at step 133200: 0.0000\n",
      "Seen so far: 4262432 samples\n",
      "Training loss (for 1 batch) at step 133300: 0.0054\n",
      "Seen so far: 4265632 samples\n",
      "Training loss (for 1 batch) at step 133400: 0.0006\n",
      "Seen so far: 4268832 samples\n",
      "Training loss (for 1 batch) at step 133500: 0.0007\n",
      "Seen so far: 4272032 samples\n",
      "Training loss (for 1 batch) at step 133600: 0.0004\n",
      "Seen so far: 4275232 samples\n",
      "Training loss (for 1 batch) at step 133700: 0.0001\n",
      "Seen so far: 4278432 samples\n",
      "Training loss (for 1 batch) at step 133800: 0.0000\n",
      "Seen so far: 4281632 samples\n",
      "Training loss (for 1 batch) at step 133900: 0.0000\n",
      "Seen so far: 4284832 samples\n",
      "Training loss (for 1 batch) at step 134000: 0.2800\n",
      "Seen so far: 4288032 samples\n",
      "Training loss (for 1 batch) at step 134100: 0.0013\n",
      "Seen so far: 4291232 samples\n",
      "Training loss (for 1 batch) at step 134200: 0.0003\n",
      "Seen so far: 4294432 samples\n",
      "Training loss (for 1 batch) at step 134300: 0.0214\n",
      "Seen so far: 4297632 samples\n",
      "Training loss (for 1 batch) at step 134400: 0.0068\n",
      "Seen so far: 4300832 samples\n",
      "Training loss (for 1 batch) at step 134500: 0.0000\n",
      "Seen so far: 4304032 samples\n",
      "Training loss (for 1 batch) at step 134600: 0.0152\n",
      "Seen so far: 4307232 samples\n",
      "Training loss (for 1 batch) at step 134700: 0.0002\n",
      "Seen so far: 4310432 samples\n",
      "Training loss (for 1 batch) at step 134800: 1.1942\n",
      "Seen so far: 4313632 samples\n",
      "Training loss (for 1 batch) at step 134900: 0.0000\n",
      "Seen so far: 4316832 samples\n",
      "Training loss (for 1 batch) at step 135000: 0.0039\n",
      "Seen so far: 4320032 samples\n",
      "Training loss (for 1 batch) at step 135100: 0.0005\n",
      "Seen so far: 4323232 samples\n",
      "Training loss (for 1 batch) at step 135200: 0.0101\n",
      "Seen so far: 4326432 samples\n",
      "Training loss (for 1 batch) at step 135300: 0.0000\n",
      "Seen so far: 4329632 samples\n",
      "Training loss (for 1 batch) at step 135400: 0.0000\n",
      "Seen so far: 4332832 samples\n",
      "Training loss (for 1 batch) at step 135500: 0.3447\n",
      "Seen so far: 4336032 samples\n",
      "Training loss (for 1 batch) at step 135600: 0.0006\n",
      "Seen so far: 4339232 samples\n",
      "Training loss (for 1 batch) at step 135700: 0.0019\n",
      "Seen so far: 4342432 samples\n",
      "Training loss (for 1 batch) at step 135800: 0.0055\n",
      "Seen so far: 4345632 samples\n",
      "Training loss (for 1 batch) at step 135900: 0.0101\n",
      "Seen so far: 4348832 samples\n",
      "Training loss (for 1 batch) at step 136000: 0.0002\n",
      "Seen so far: 4352032 samples\n",
      "Training loss (for 1 batch) at step 136100: 0.0000\n",
      "Seen so far: 4355232 samples\n",
      "Training loss (for 1 batch) at step 136200: 0.0024\n",
      "Seen so far: 4358432 samples\n",
      "Training loss (for 1 batch) at step 136300: 0.0475\n",
      "Seen so far: 4361632 samples\n",
      "Training loss (for 1 batch) at step 136400: 0.0007\n",
      "Seen so far: 4364832 samples\n",
      "Training loss (for 1 batch) at step 136500: 0.0000\n",
      "Seen so far: 4368032 samples\n",
      "Training loss (for 1 batch) at step 136600: 0.0007\n",
      "Seen so far: 4371232 samples\n",
      "Training loss (for 1 batch) at step 136700: 0.0015\n",
      "Seen so far: 4374432 samples\n",
      "Training loss (for 1 batch) at step 136800: 0.0000\n",
      "Seen so far: 4377632 samples\n",
      "Training loss (for 1 batch) at step 136900: 0.0002\n",
      "Seen so far: 4380832 samples\n",
      "Training loss (for 1 batch) at step 137000: 0.0002\n",
      "Seen so far: 4384032 samples\n",
      "Training loss (for 1 batch) at step 137100: 0.0002\n",
      "Seen so far: 4387232 samples\n",
      "Training loss (for 1 batch) at step 137200: 0.0001\n",
      "Seen so far: 4390432 samples\n",
      "Training loss (for 1 batch) at step 137300: 0.0000\n",
      "Seen so far: 4393632 samples\n",
      "Training loss (for 1 batch) at step 137400: 0.0000\n",
      "Seen so far: 4396832 samples\n",
      "Training loss (for 1 batch) at step 137500: 0.0014\n",
      "Seen so far: 4400032 samples\n",
      "Training loss (for 1 batch) at step 137600: 0.0071\n",
      "Seen so far: 4403232 samples\n",
      "Training loss (for 1 batch) at step 137700: 0.0000\n",
      "Seen so far: 4406432 samples\n",
      "Training loss (for 1 batch) at step 137800: 0.0266\n",
      "Seen so far: 4409632 samples\n",
      "Training loss (for 1 batch) at step 137900: 0.0000\n",
      "Seen so far: 4412832 samples\n",
      "Training loss (for 1 batch) at step 138000: 0.0000\n",
      "Seen so far: 4416032 samples\n",
      "Training loss (for 1 batch) at step 138100: 0.0000\n",
      "Seen so far: 4419232 samples\n",
      "Training loss (for 1 batch) at step 138200: 0.3052\n",
      "Seen so far: 4422432 samples\n",
      "Training loss (for 1 batch) at step 138300: 0.0000\n",
      "Seen so far: 4425632 samples\n",
      "Training loss (for 1 batch) at step 138400: 0.0152\n",
      "Seen so far: 4428832 samples\n",
      "Training loss (for 1 batch) at step 138500: 0.0832\n",
      "Seen so far: 4432032 samples\n",
      "Training loss (for 1 batch) at step 138600: 0.0154\n",
      "Seen so far: 4435232 samples\n",
      "Training loss (for 1 batch) at step 138700: 0.0002\n",
      "Seen so far: 4438432 samples\n",
      "Training loss (for 1 batch) at step 138800: 0.0015\n",
      "Seen so far: 4441632 samples\n",
      "Training loss (for 1 batch) at step 138900: 0.0004\n",
      "Seen so far: 4444832 samples\n",
      "Training loss (for 1 batch) at step 139000: 0.0027\n",
      "Seen so far: 4448032 samples\n",
      "Training loss (for 1 batch) at step 139100: 0.0000\n",
      "Seen so far: 4451232 samples\n",
      "Training loss (for 1 batch) at step 139200: 0.1247\n",
      "Seen so far: 4454432 samples\n",
      "Training loss (for 1 batch) at step 139300: 0.0000\n",
      "Seen so far: 4457632 samples\n",
      "Training loss (for 1 batch) at step 139400: 0.0000\n",
      "Seen so far: 4460832 samples\n",
      "Training loss (for 1 batch) at step 139500: 0.0086\n",
      "Seen so far: 4464032 samples\n",
      "Training loss (for 1 batch) at step 139600: 0.0000\n",
      "Seen so far: 4467232 samples\n",
      "Training loss (for 1 batch) at step 139700: 0.1063\n",
      "Seen so far: 4470432 samples\n",
      "Training loss (for 1 batch) at step 139800: 0.0116\n",
      "Seen so far: 4473632 samples\n",
      "Training loss (for 1 batch) at step 139900: 0.0579\n",
      "Seen so far: 4476832 samples\n",
      "Training loss (for 1 batch) at step 140000: 0.0052\n",
      "Seen so far: 4480032 samples\n",
      "Training loss (for 1 batch) at step 140100: 0.5055\n",
      "Seen so far: 4483232 samples\n",
      "Training loss (for 1 batch) at step 140200: 0.0248\n",
      "Seen so far: 4486432 samples\n",
      "Training loss (for 1 batch) at step 140300: 0.0196\n",
      "Seen so far: 4489632 samples\n",
      "Training loss (for 1 batch) at step 140400: 0.0000\n",
      "Seen so far: 4492832 samples\n",
      "Training loss (for 1 batch) at step 140500: 0.0002\n",
      "Seen so far: 4496032 samples\n",
      "Training loss (for 1 batch) at step 140600: 0.0001\n",
      "Seen so far: 4499232 samples\n",
      "Training loss (for 1 batch) at step 140700: 0.0000\n",
      "Seen so far: 4502432 samples\n",
      "Training loss (for 1 batch) at step 140800: 0.0000\n",
      "Seen so far: 4505632 samples\n",
      "Training loss (for 1 batch) at step 140900: 0.0000\n",
      "Seen so far: 4508832 samples\n",
      "Training loss (for 1 batch) at step 141000: 0.0001\n",
      "Seen so far: 4512032 samples\n",
      "Training loss (for 1 batch) at step 141100: 0.0376\n",
      "Seen so far: 4515232 samples\n",
      "Training loss (for 1 batch) at step 141200: 0.0001\n",
      "Seen so far: 4518432 samples\n",
      "Training loss (for 1 batch) at step 141300: 0.0647\n",
      "Seen so far: 4521632 samples\n",
      "Training loss (for 1 batch) at step 141400: 0.0006\n",
      "Seen so far: 4524832 samples\n",
      "Training loss (for 1 batch) at step 141500: 0.0000\n",
      "Seen so far: 4528032 samples\n",
      "Training loss (for 1 batch) at step 141600: 0.0000\n",
      "Seen so far: 4531232 samples\n",
      "Training loss (for 1 batch) at step 141700: 0.0015\n",
      "Seen so far: 4534432 samples\n",
      "Training loss (for 1 batch) at step 141800: 0.0831\n",
      "Seen so far: 4537632 samples\n",
      "Training loss (for 1 batch) at step 141900: 0.0014\n",
      "Seen so far: 4540832 samples\n",
      "Training loss (for 1 batch) at step 142000: 0.0004\n",
      "Seen so far: 4544032 samples\n",
      "Training loss (for 1 batch) at step 142100: 0.0001\n",
      "Seen so far: 4547232 samples\n",
      "Training loss (for 1 batch) at step 142200: 0.0002\n",
      "Seen so far: 4550432 samples\n",
      "Training loss (for 1 batch) at step 142300: 0.0000\n",
      "Seen so far: 4553632 samples\n",
      "Training loss (for 1 batch) at step 142400: 0.0000\n",
      "Seen so far: 4556832 samples\n",
      "Training loss (for 1 batch) at step 142500: 0.0134\n",
      "Seen so far: 4560032 samples\n",
      "Training loss (for 1 batch) at step 142600: 0.0000\n",
      "Seen so far: 4563232 samples\n",
      "Training loss (for 1 batch) at step 142700: 0.0828\n",
      "Seen so far: 4566432 samples\n",
      "Training loss (for 1 batch) at step 142800: 0.0000\n",
      "Seen so far: 4569632 samples\n",
      "Training loss (for 1 batch) at step 142900: 0.0000\n",
      "Seen so far: 4572832 samples\n",
      "Training loss (for 1 batch) at step 143000: 0.0000\n",
      "Seen so far: 4576032 samples\n",
      "Training loss (for 1 batch) at step 143100: 0.0362\n",
      "Seen so far: 4579232 samples\n",
      "Training loss (for 1 batch) at step 143200: 0.0593\n",
      "Seen so far: 4582432 samples\n",
      "Training loss (for 1 batch) at step 143300: 0.0000\n",
      "Seen so far: 4585632 samples\n",
      "Training loss (for 1 batch) at step 143400: 0.0001\n",
      "Seen so far: 4588832 samples\n",
      "Training loss (for 1 batch) at step 143500: 0.0005\n",
      "Seen so far: 4592032 samples\n",
      "Training loss (for 1 batch) at step 143600: 0.1030\n",
      "Seen so far: 4595232 samples\n",
      "Training loss (for 1 batch) at step 143700: 0.0613\n",
      "Seen so far: 4598432 samples\n",
      "Training loss (for 1 batch) at step 143800: 0.0012\n",
      "Seen so far: 4601632 samples\n",
      "Training loss (for 1 batch) at step 143900: 0.0006\n",
      "Seen so far: 4604832 samples\n",
      "Training loss (for 1 batch) at step 144000: 0.0024\n",
      "Seen so far: 4608032 samples\n",
      "Training loss (for 1 batch) at step 144100: 0.0091\n",
      "Seen so far: 4611232 samples\n",
      "Training loss (for 1 batch) at step 144200: 0.0002\n",
      "Seen so far: 4614432 samples\n",
      "Training loss (for 1 batch) at step 144300: 0.0000\n",
      "Seen so far: 4617632 samples\n",
      "Training loss (for 1 batch) at step 144400: 0.0000\n",
      "Seen so far: 4620832 samples\n",
      "Training loss (for 1 batch) at step 144500: 0.0004\n",
      "Seen so far: 4624032 samples\n",
      "Training loss (for 1 batch) at step 144600: 0.0001\n",
      "Seen so far: 4627232 samples\n",
      "Training loss (for 1 batch) at step 144700: 0.0003\n",
      "Seen so far: 4630432 samples\n",
      "Training loss (for 1 batch) at step 144800: 0.0637\n",
      "Seen so far: 4633632 samples\n",
      "Training loss (for 1 batch) at step 144900: 0.0004\n",
      "Seen so far: 4636832 samples\n",
      "Training loss (for 1 batch) at step 145000: 0.0055\n",
      "Seen so far: 4640032 samples\n",
      "Training loss (for 1 batch) at step 145100: 0.0000\n",
      "Seen so far: 4643232 samples\n",
      "Training loss (for 1 batch) at step 145200: 0.0000\n",
      "Seen so far: 4646432 samples\n",
      "Training loss (for 1 batch) at step 145300: 0.2870\n",
      "Seen so far: 4649632 samples\n",
      "Training loss (for 1 batch) at step 145400: 0.0000\n",
      "Seen so far: 4652832 samples\n",
      "Training loss (for 1 batch) at step 145500: 0.0008\n",
      "Seen so far: 4656032 samples\n",
      "Training loss (for 1 batch) at step 145600: 0.0002\n",
      "Seen so far: 4659232 samples\n",
      "Training loss (for 1 batch) at step 145700: 0.0000\n",
      "Seen so far: 4662432 samples\n",
      "Training loss (for 1 batch) at step 145800: 0.0004\n",
      "Seen so far: 4665632 samples\n",
      "Training loss (for 1 batch) at step 145900: 0.0000\n",
      "Seen so far: 4668832 samples\n",
      "Training loss (for 1 batch) at step 146000: 0.0000\n",
      "Seen so far: 4672032 samples\n",
      "Training loss (for 1 batch) at step 146100: 0.0080\n",
      "Seen so far: 4675232 samples\n",
      "Training loss (for 1 batch) at step 146200: 0.0047\n",
      "Seen so far: 4678432 samples\n",
      "Training loss (for 1 batch) at step 146300: 0.0013\n",
      "Seen so far: 4681632 samples\n",
      "Training loss (for 1 batch) at step 146400: 0.0497\n",
      "Seen so far: 4684832 samples\n",
      "Training loss (for 1 batch) at step 146500: 0.0000\n",
      "Seen so far: 4688032 samples\n",
      "Training loss (for 1 batch) at step 146600: 0.0002\n",
      "Seen so far: 4691232 samples\n",
      "Training loss (for 1 batch) at step 146700: 0.0000\n",
      "Seen so far: 4694432 samples\n",
      "Training loss (for 1 batch) at step 146800: 0.1115\n",
      "Seen so far: 4697632 samples\n",
      "Training loss (for 1 batch) at step 146900: 0.1059\n",
      "Seen so far: 4700832 samples\n",
      "Training loss (for 1 batch) at step 147000: 0.0155\n",
      "Seen so far: 4704032 samples\n",
      "Training loss (for 1 batch) at step 147100: 0.1464\n",
      "Seen so far: 4707232 samples\n",
      "Training loss (for 1 batch) at step 147200: 0.0167\n",
      "Seen so far: 4710432 samples\n",
      "Training loss (for 1 batch) at step 147300: 0.0080\n",
      "Seen so far: 4713632 samples\n",
      "Training loss (for 1 batch) at step 147400: 0.0013\n",
      "Seen so far: 4716832 samples\n",
      "Training loss (for 1 batch) at step 147500: 0.0745\n",
      "Seen so far: 4720032 samples\n",
      "Training loss (for 1 batch) at step 147600: 0.0015\n",
      "Seen so far: 4723232 samples\n",
      "Training loss (for 1 batch) at step 147700: 0.1090\n",
      "Seen so far: 4726432 samples\n",
      "Training loss (for 1 batch) at step 147800: 0.1016\n",
      "Seen so far: 4729632 samples\n",
      "Training loss (for 1 batch) at step 147900: 0.0498\n",
      "Seen so far: 4732832 samples\n",
      "Training loss (for 1 batch) at step 148000: 0.0033\n",
      "Seen so far: 4736032 samples\n",
      "Training loss (for 1 batch) at step 148100: 0.0070\n",
      "Seen so far: 4739232 samples\n",
      "Training loss (for 1 batch) at step 148200: 0.1008\n",
      "Seen so far: 4742432 samples\n",
      "Training loss (for 1 batch) at step 148300: 0.1404\n",
      "Seen so far: 4745632 samples\n",
      "Training loss (for 1 batch) at step 148400: 0.0000\n",
      "Seen so far: 4748832 samples\n",
      "Training loss (for 1 batch) at step 148500: 0.1157\n",
      "Seen so far: 4752032 samples\n",
      "Training loss (for 1 batch) at step 148600: 0.0020\n",
      "Seen so far: 4755232 samples\n",
      "Training loss (for 1 batch) at step 148700: 0.0001\n",
      "Seen so far: 4758432 samples\n",
      "Training loss (for 1 batch) at step 148800: 0.0000\n",
      "Seen so far: 4761632 samples\n",
      "Training loss (for 1 batch) at step 148900: 0.1012\n",
      "Seen so far: 4764832 samples\n",
      "Training loss (for 1 batch) at step 149000: 0.0000\n",
      "Seen so far: 4768032 samples\n",
      "Training loss (for 1 batch) at step 149100: 0.0088\n",
      "Seen so far: 4771232 samples\n",
      "Training loss (for 1 batch) at step 149200: 0.0008\n",
      "Seen so far: 4774432 samples\n",
      "Training loss (for 1 batch) at step 149300: 0.0000\n",
      "Seen so far: 4777632 samples\n",
      "Training loss (for 1 batch) at step 149400: 0.0000\n",
      "Seen so far: 4780832 samples\n",
      "Training loss (for 1 batch) at step 149500: 0.0012\n",
      "Seen so far: 4784032 samples\n",
      "Training loss (for 1 batch) at step 149600: 0.3760\n",
      "Seen so far: 4787232 samples\n",
      "Training loss (for 1 batch) at step 149700: -0.0000\n",
      "Seen so far: 4790432 samples\n",
      "Training loss (for 1 batch) at step 149800: 0.0484\n",
      "Seen so far: 4793632 samples\n",
      "Training loss (for 1 batch) at step 149900: 0.1783\n",
      "Seen so far: 4796832 samples\n",
      "Training loss (for 1 batch) at step 150000: 0.0000\n",
      "Seen so far: 4800032 samples\n",
      "Training loss (for 1 batch) at step 150100: 0.0032\n",
      "Seen so far: 4803232 samples\n",
      "Training loss (for 1 batch) at step 150200: 0.0097\n",
      "Seen so far: 4806432 samples\n",
      "Training loss (for 1 batch) at step 150300: 0.0000\n",
      "Seen so far: 4809632 samples\n",
      "Training loss (for 1 batch) at step 150400: 0.0000\n",
      "Seen so far: 4812832 samples\n",
      "Training loss (for 1 batch) at step 150500: 0.0000\n",
      "Seen so far: 4816032 samples\n",
      "Training loss (for 1 batch) at step 150600: 0.4458\n",
      "Seen so far: 4819232 samples\n",
      "Training loss (for 1 batch) at step 150700: 0.0340\n",
      "Seen so far: 4822432 samples\n",
      "Training loss (for 1 batch) at step 150800: 0.0004\n",
      "Seen so far: 4825632 samples\n",
      "Training loss (for 1 batch) at step 150900: 0.0006\n",
      "Seen so far: 4828832 samples\n",
      "Training loss (for 1 batch) at step 151000: 0.0000\n",
      "Seen so far: 4832032 samples\n",
      "Training loss (for 1 batch) at step 151100: 0.0091\n",
      "Seen so far: 4835232 samples\n",
      "Training loss (for 1 batch) at step 151200: 0.0003\n",
      "Seen so far: 4838432 samples\n",
      "Training loss (for 1 batch) at step 151300: 0.0000\n",
      "Seen so far: 4841632 samples\n",
      "Training loss (for 1 batch) at step 151400: 0.0000\n",
      "Seen so far: 4844832 samples\n",
      "Training loss (for 1 batch) at step 151500: 0.0018\n",
      "Seen so far: 4848032 samples\n",
      "Training loss (for 1 batch) at step 151600: 0.0049\n",
      "Seen so far: 4851232 samples\n",
      "Training loss (for 1 batch) at step 151700: 0.0000\n",
      "Seen so far: 4854432 samples\n",
      "Training loss (for 1 batch) at step 151800: 0.0001\n",
      "Seen so far: 4857632 samples\n",
      "Training loss (for 1 batch) at step 151900: 0.0004\n",
      "Seen so far: 4860832 samples\n",
      "Training loss (for 1 batch) at step 152000: 0.0000\n",
      "Seen so far: 4864032 samples\n",
      "Training loss (for 1 batch) at step 152100: 0.0226\n",
      "Seen so far: 4867232 samples\n",
      "Training loss (for 1 batch) at step 152200: 0.0268\n",
      "Seen so far: 4870432 samples\n",
      "Training loss (for 1 batch) at step 152300: 0.0000\n",
      "Seen so far: 4873632 samples\n",
      "Training loss (for 1 batch) at step 152400: 0.0009\n",
      "Seen so far: 4876832 samples\n",
      "Training loss (for 1 batch) at step 152500: 0.0058\n",
      "Seen so far: 4880032 samples\n",
      "Training loss (for 1 batch) at step 152600: 0.0001\n",
      "Seen so far: 4883232 samples\n",
      "Training loss (for 1 batch) at step 152700: 0.0002\n",
      "Seen so far: 4886432 samples\n",
      "Training loss (for 1 batch) at step 152800: 0.0561\n",
      "Seen so far: 4889632 samples\n",
      "Training loss (for 1 batch) at step 152900: 0.0785\n",
      "Seen so far: 4892832 samples\n",
      "Training loss (for 1 batch) at step 153000: 0.0000\n",
      "Seen so far: 4896032 samples\n",
      "Training loss (for 1 batch) at step 153100: 0.0172\n",
      "Seen so far: 4899232 samples\n",
      "Training loss (for 1 batch) at step 153200: 0.0013\n",
      "Seen so far: 4902432 samples\n",
      "Training loss (for 1 batch) at step 153300: 0.0001\n",
      "Seen so far: 4905632 samples\n",
      "Training loss (for 1 batch) at step 153400: 0.0007\n",
      "Seen so far: 4908832 samples\n",
      "Training loss (for 1 batch) at step 153500: 0.0000\n",
      "Seen so far: 4912032 samples\n",
      "Training loss (for 1 batch) at step 153600: 0.0007\n",
      "Seen so far: 4915232 samples\n",
      "Training loss (for 1 batch) at step 153700: 0.0590\n",
      "Seen so far: 4918432 samples\n",
      "Training loss (for 1 batch) at step 153800: 0.0201\n",
      "Seen so far: 4921632 samples\n",
      "Training loss (for 1 batch) at step 153900: 0.0000\n",
      "Seen so far: 4924832 samples\n",
      "Training loss (for 1 batch) at step 154000: 0.0001\n",
      "Seen so far: 4928032 samples\n",
      "Training loss (for 1 batch) at step 154100: 0.0750\n",
      "Seen so far: 4931232 samples\n",
      "Training loss (for 1 batch) at step 154200: 0.0000\n",
      "Seen so far: 4934432 samples\n",
      "Training loss (for 1 batch) at step 154300: 0.0001\n",
      "Seen so far: 4937632 samples\n",
      "Training loss (for 1 batch) at step 154400: 0.0041\n",
      "Seen so far: 4940832 samples\n",
      "Training loss (for 1 batch) at step 154500: 0.0295\n",
      "Seen so far: 4944032 samples\n",
      "Training loss (for 1 batch) at step 154600: 0.3682\n",
      "Seen so far: 4947232 samples\n",
      "Training loss (for 1 batch) at step 154700: 0.0001\n",
      "Seen so far: 4950432 samples\n",
      "Training loss (for 1 batch) at step 154800: 0.0008\n",
      "Seen so far: 4953632 samples\n",
      "Training loss (for 1 batch) at step 154900: 0.0007\n",
      "Seen so far: 4956832 samples\n",
      "Training loss (for 1 batch) at step 155000: 0.0024\n",
      "Seen so far: 4960032 samples\n",
      "Training loss (for 1 batch) at step 155100: 0.0000\n",
      "Seen so far: 4963232 samples\n",
      "Training loss (for 1 batch) at step 155200: 0.0000\n",
      "Seen so far: 4966432 samples\n",
      "Training loss (for 1 batch) at step 155300: 0.6481\n",
      "Seen so far: 4969632 samples\n",
      "Training loss (for 1 batch) at step 155400: 0.0035\n",
      "Seen so far: 4972832 samples\n",
      "Training loss (for 1 batch) at step 155500: 0.0001\n",
      "Seen so far: 4976032 samples\n",
      "Training loss (for 1 batch) at step 155600: 0.0002\n",
      "Seen so far: 4979232 samples\n",
      "Training loss (for 1 batch) at step 155700: 0.0010\n",
      "Seen so far: 4982432 samples\n",
      "Training loss (for 1 batch) at step 155800: 0.0000\n",
      "Seen so far: 4985632 samples\n",
      "Training loss (for 1 batch) at step 155900: 0.0006\n",
      "Seen so far: 4988832 samples\n",
      "Training loss (for 1 batch) at step 156000: 0.0000\n",
      "Seen so far: 4992032 samples\n",
      "Training loss (for 1 batch) at step 156100: 0.0715\n",
      "Seen so far: 4995232 samples\n",
      "Training loss (for 1 batch) at step 156200: 0.1129\n",
      "Seen so far: 4998432 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 12:17:47.091139: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Build optimizer variables.\n",
    "optimizer.build(model.trainable_variables)\n",
    "\n",
    "trainable_variables = model.trainable_variables\n",
    "non_trainable_variables = model.non_trainable_variables\n",
    "optimizer_variables = optimizer.variables\n",
    "state = trainable_variables, non_trainable_variables, optimizer_variables\n",
    "\n",
    "# Training loop\n",
    "for step, data in enumerate(train_dataset):\n",
    "    data = (data[0].numpy(), data[1].numpy())\n",
    "    loss, state = train_step(state, data)\n",
    "    # Log every 100 batches.\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Training loss (for 1 batch) at step {step}: {float(loss):.4f}\")\n",
    "        print(f\"Seen so far: {(step + 1) * batch_size} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before assign:\n",
      "[[ 0.16190776 -0.9707848  -0.67659634  1.1883662   0.8403462   0.3603685\n",
      "  -1.2950165   0.3685163   1.2046294   0.4716625 ]]\n",
      "after assign:\n",
      "[[ 0.00406094  0.04440082 -0.2361547   0.51957184  0.22549757  0.3074376\n",
      "  -0.8326762  -0.00449392 -0.4559419   0.1872515 ]]\n"
     ]
    }
   ],
   "source": [
    "# 透過Stateless訓練的結果只會儲存在state的變數當中，需要把這些算完的state放回到模型中，\n",
    "# 才能使用keras.model的物件進行操作(例如存檔等等的行為)\n",
    "\n",
    "print(\"before assign:\")\n",
    "print(model(np.ones([1,784])))\n",
    "\n",
    "trainable_variables, non_trainable_variables, optimizer_variables = state\n",
    "for variable, value in zip(model.trainable_variables, trainable_variables):\n",
    "    variable.assign(value)\n",
    "for variable, value in zip(model.non_trainable_variables, non_trainable_variables):\n",
    "    variable.assign(value)\n",
    "    \n",
    "print(\"after assign:\")\n",
    "print(model(np.ones([1,784])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
